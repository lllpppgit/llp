-- Journal begins at Tue 2023-01-17 03:45:46 UTC, ends at Tue 2023-01-17 06:43:28 UTC. --
Jan 17 03:45:58 kind-control-plane systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Jan 17 03:46:04 kind-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Jan 17 03:46:04 kind-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.229571     226 server.go:197] "Warning: For remote container runtime, --pod-infra-container-image is ignored in kubelet, which should be set in that remote runtime instead"
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.940776     226 server.go:440] "Kubelet version" kubeletVersion="v1.21.1"
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.940907     226 server.go:851] "Client rotation is on, will bootstrap in background"
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.950662     226 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:04 kind-control-plane kubelet[226]: E0117 03:46:04.950756     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:07 kind-control-plane kubelet[226]: E0117 03:46:07.111472     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955326     226 container_manager_linux.go:278] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955436     226 container_manager_linux.go:283] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955475     226 topology_manager.go:120] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955492     226 container_manager_linux.go:314] "Initializing Topology Manager" policy="none" scope="container"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955505     226 container_manager_linux.go:319] "Creating device plugin manager" devicePluginEnabled=true
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955783     226 remote_runtime.go:62] parsed scheme: ""
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955802     226 remote_runtime.go:62] scheme "" not registered, fallback to default scheme
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955875     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955896     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958223     226 remote_image.go:50] parsed scheme: ""
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958260     226 remote_image.go:50] scheme "" not registered, fallback to default scheme
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958290     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958304     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958433     226 kubelet.go:404] "Attempting to sync node with API server"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958464     226 kubelet.go:272] "Adding static pod path" path="/etc/kubernetes/manifests"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958517     226 kubelet.go:283] "Adding apiserver pod source"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958552     226 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.959231     226 clientconn.go:897] blockingPicker: the picked transport is not ready, loop back to repick
Jan 17 03:46:09 kind-control-plane kubelet[226]: E0117 03:46:09.986142     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.991700     226 kuberuntime_manager.go:222] "Container runtime initialized" containerRuntime="containerd" version="v1.5.2" apiVersion="v1alpha2"
Jan 17 03:46:09 kind-control-plane kubelet[226]: E0117 03:46:09.992585     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.262547     226 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.
Jan 17 03:46:10 kind-control-plane kubelet[226]:         For verbose messaging see aws.Config.CredentialsChainVerboseErrors
Jan 17 03:46:10 kind-control-plane kubelet[226]: W0117 03:46:10.262922     226 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.263925     226 server.go:1190] "Started kubelet"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.268526     226 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.277011     226 server.go:149] "Starting to listen" address="0.0.0.0" port=10250
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.278412     226 server.go:405] "Adding debug handlers to kubelet server"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.283743     226 volume_manager.go:271] "Starting Kubelet Volume Manager"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.287252     226 desired_state_of_world_populator.go:141] "Desired state populator starts to run"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299364     226 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe47b740c2d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299496     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299530     226 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.305805     226 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv4
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322576     226 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv6
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322599     226 status_manager.go:157] "Starting to sync pod status with apiserver"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322710     226 kubelet.go:1846] "Starting kubelet main sync loop"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.322910     226 kubelet.go:1870] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.325331     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325455     226 client.go:86] parsed scheme: "unix"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325460     226 client.go:86] scheme "unix" not registered, fallback to default scheme
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325472     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325476     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.325594     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.389723     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.390461     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.390931     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392669     226 cpu_manager.go:199] "Starting CPU manager" policy="none"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392676     226 cpu_manager.go:200] "Reconciling" reconcilePeriod="10s"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392689     226 state_mem.go:36] "Initialized new in-memory state store"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.396645     226 policy_none.go:44] "None policy: Start"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.400248     226 manager.go:600] "Failed to retrieve checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.400362     226 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.402219     226 eviction_manager.go:255] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.424435     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.426443     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.429460     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.437594     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.438254     226 status_manager.go:566] "Failed to get status for pod" podUID=24ba8551bcc724a32d591bb02c423d92 pod="kube-system/etcd-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/etcd-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.444270     226 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.449464     226 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.455506     226 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489582     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-ca-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-local-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/69dd939498054a211c3461b2a9cc8d26-kubeconfig\") pod \"kube-scheduler-kind-control-plane\" (UID: \"69dd939498054a211c3461b2a9cc8d26\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-flexvolume-dir\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-ca-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-k8s-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-etc-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489588     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-local-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489619     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489643     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-k8s-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489686     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-certs\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489707     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-data\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489728     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-etc-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489752     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-kubeconfig\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.489777     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.501658     226 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.590691     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.593999     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.595606     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.691215     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.793022     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.852132     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.895477     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.906559     226 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.000626     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: I0117 03:46:11.013012     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.013298     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.117660     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.176438     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.218481     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.320917     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.345236     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.363403     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.421098     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.524061     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.624918     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.712418     226 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.726745     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.827634     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: I0117 03:46:11.865135     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.865514     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.923472     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.930032     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.034605     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.137785     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.238924     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.340370     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.441264     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.543314     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.645352     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.747372     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.849592     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.956957     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.057032     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.157402     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.259120     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.314295     226 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.349441     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.356614     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.360296     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.462252     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: I0117 03:46:13.513234     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.513378     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.562459     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.663724     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.764662     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.866073     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.969181     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.071735     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.102309     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:14 kind-control-plane kubelet[226]: I0117 03:46:14.139790     226 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.175809     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.277366     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.386007     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.488180     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.595182     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.701199     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.806812     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.910211     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.013362     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.117029     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.220087     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.322958     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.424189     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.424243     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.528387     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.628701     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.738897     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.845800     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.946122     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.049325     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.158227     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.264074     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.372807     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.476746     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.581144     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.683026     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: I0117 03:46:16.725422     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.792186     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.896114     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.999121     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.102193     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.207240     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.308211     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.410020     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.513705     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.617161     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.719737     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.819980     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.920943     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.023937     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.124838     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.226505     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.327203     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.428231     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.529196     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.629478     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.731571     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.835125     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.937229     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.039037     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.139732     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.241101     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.342259     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.443206     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.545072     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.647026     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.748233     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.849142     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.950199     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.051711     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.154844     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.256157     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.358174     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.404008     226 eviction_manager.go:255] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.427426     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.461219     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.563911     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.665153     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.766907     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.870113     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.972612     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.076853     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.180623     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.283616     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.383779     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.485194     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.587662     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.693170     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.798867     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.900324     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.005207     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.106338     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.208119     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.309862     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.410990     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.512639     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.614580     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.716613     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.818203     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.919133     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.024041     226 apiserver.go:52] "Watching apiserver"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.024226     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.080518     226 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"kind-control-plane\" not found" node="kind-control-plane"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.108389     226 kubelet_node_status.go:74] "Successfully registered node" node="kind-control-plane"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.124324     226 reconciler.go:157] "Reconciler: start to sync state"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.160319     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe47b740c2d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.225296     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.293060     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.346222     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff38ca", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.401306     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762a24c, ext:6226227818, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.459070     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762ab32, ext:6226230090, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.522050     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff38ca", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762b037, ext:6226231375, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.578801     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe48398db7a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097df477a, ext:6234396562, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097df477a, ext:6234396562, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.640436     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609967fc4e, ext:6260133028, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:24 kind-control-plane kubelet[226]: E0117 03:46:24.024310     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609968234f, ext:6260143023, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:25 kind-control-plane kubelet[226]: E0117 03:46:25.428793     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:26 kind-control-plane systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Jan 17 03:46:26 kind-control-plane kubelet[226]: I0117 03:46:26.025044     226 dynamic_cafile_content.go:182] Shutting down client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:26 kind-control-plane systemd[1]: kubelet.service: Succeeded.
Jan 17 03:46:26 kind-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jan 17 03:46:26 kind-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Jan 17 03:46:26 kind-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.170827     607 server.go:197] "Warning: For remote container runtime, --pod-infra-container-image is ignored in kubelet, which should be set in that remote runtime instead"
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.197414     607 server.go:440] "Kubelet version" kubeletVersion="v1.21.1"
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.197435     607 server.go:851] "Client rotation is on, will bootstrap in background"
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.201318     607 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.203080     607 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.213627     607 container_manager_linux.go:278] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220579     607 container_manager_linux.go:283] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220660     607 topology_manager.go:120] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220674     607 container_manager_linux.go:314] "Initializing Topology Manager" policy="none" scope="container"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220682     607 container_manager_linux.go:319] "Creating device plugin manager" devicePluginEnabled=true
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220850     607 remote_runtime.go:62] parsed scheme: ""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220861     607 remote_runtime.go:62] scheme "" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.224218     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.224218     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225170     607 remote_image.go:50] parsed scheme: ""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225182     607 remote_image.go:50] scheme "" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225216     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225443     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225539     607 kubelet.go:404] "Attempting to sync node with API server"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225587     607 kubelet.go:272] "Adding static pod path" path="/etc/kubernetes/manifests"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225624     607 kubelet.go:283] "Adding apiserver pod source"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225646     607 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.256055     607 kuberuntime_manager.go:222] "Container runtime initialized" containerRuntime="containerd" version="v1.5.2" apiVersion="v1alpha2"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.521808     607 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.
Jan 17 03:46:31 kind-control-plane kubelet[607]:         For verbose messaging see aws.Config.CredentialsChainVerboseErrors
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.522675     607 server.go:1190] "Started kubelet"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.532711     607 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.534954     607 server.go:149] "Starting to listen" address="0.0.0.0" port=10250
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.536565     607 server.go:405] "Adding debug handlers to kubelet server"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.550137     607 volume_manager.go:271] "Starting Kubelet Volume Manager"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.554276     607 desired_state_of_world_populator.go:141] "Desired state populator starts to run"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.579851     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582532     607 client.go:86] parsed scheme: "unix"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582548     607 client.go:86] scheme "unix" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582569     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582577     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.622980     607 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv4
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633668     607 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv6
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633691     607 status_manager.go:157] "Starting to sync pod status with apiserver"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633702     607 kubelet.go:1846] "Starting kubelet main sync loop"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.633728     607 kubelet.go:1870] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.656750     607 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.684330     607 kubelet_node_status.go:109] "Node was previously registered" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.687789     607 kubelet_node_status.go:74] "Successfully registered node" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.744889     607 kubelet.go:1870] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748594     607 cpu_manager.go:199] "Starting CPU manager" policy="none"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748604     607 cpu_manager.go:200] "Reconciling" reconcilePeriod="10s"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748605     607 state_mem.go:36] "Initialized new in-memory state store"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750067     607 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750111     607 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750118     607 policy_none.go:44] "None policy: Start"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750752     607 manager.go:600] "Failed to retrieve checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750939     607 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.946962     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947158     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947223     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947306     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967457     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-flexvolume-dir\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967517     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-k8s-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967559     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-local-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967596     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967634     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/69dd939498054a211c3461b2a9cc8d26-kubeconfig\") pod \"kube-scheduler-kind-control-plane\" (UID: \"69dd939498054a211c3461b2a9cc8d26\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967744     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-data\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967792     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-ca-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967825     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-k8s-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967866     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-etc-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967900     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-certs\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967938     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-ca-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967974     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968008     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-kubeconfig\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968040     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-etc-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968040     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-local-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:32 kind-control-plane kubelet[607]: E0117 03:46:32.022425     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"etcd-kind-control-plane\" already exists" pod="kube-system/etcd-kind-control-plane"
Jan 17 03:46:32 kind-control-plane kubelet[607]: I0117 03:46:32.228019     607 apiserver.go:52] "Watching apiserver"
Jan 17 03:46:32 kind-control-plane kubelet[607]: I0117 03:46:32.473339     607 reconciler.go:157] "Reconciler: start to sync state"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.034040     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"etcd-kind-control-plane\" already exists" pod="kube-system/etcd-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.242086     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-kind-control-plane\" already exists" pod="kube-system/kube-controller-manager-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.447593     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-apiserver-kind-control-plane\" already exists" pod="kube-system/kube-apiserver-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.654737     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-scheduler-kind-control-plane\" already exists" pod="kube-system/kube-scheduler-kind-control-plane"
Jan 17 03:46:36 kind-control-plane kubelet[607]: E0117 03:46:36.751549     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:39 kind-control-plane kubelet[607]: I0117 03:46:39.936175     607 kuberuntime_manager.go:1044] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Jan 17 03:46:39 kind-control-plane kubelet[607]: I0117 03:46:39.937214     607 kubelet_network.go:76] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Jan 17 03:46:39 kind-control-plane kubelet[607]: E0117 03:46:39.937409     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.124530     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.134671     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159400     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-lib-modules\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159449     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/69596075-e3a8-43fd-9a62-69a0aa833fb6-kube-proxy\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159509     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/69596075-e3a8-43fd-9a62-69a0aa833fb6-lib-modules\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159539     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-xtables-lock\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159570     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-cni-cfg\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159608     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6qp9j\" (UniqueName: \"kubernetes.io/projected/e5ced440-70ff-4944-9756-a3d368c86a5d-kube-api-access-6qp9j\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159642     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/69596075-e3a8-43fd-9a62-69a0aa833fb6-xtables-lock\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159673     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pfvbz\" (UniqueName: \"kubernetes.io/projected/69596075-e3a8-43fd-9a62-69a0aa833fb6-kube-api-access-pfvbz\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:41 kind-control-plane kubelet[607]: E0117 03:46:41.809585     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.780370     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: E0117 03:46:55.796608     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "local-path-config" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 03:46:55 kind-control-plane kubelet[607]: E0117 03:46:55.796669     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.814896     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.818441     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841950     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841982     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ptnnn\" (UniqueName: \"kubernetes.io/projected/41df3d8b-173f-407c-91cc-5b0da8567827-kube-api-access-ptnnn\") pod \"coredns-558bd4d5db-tsnk8\" (UID: \"41df3d8b-173f-407c-91cc-5b0da8567827\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841994     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/8ce1e50d-5699-49de-9a31-edc180d85ebe-config-volume\") pod \"coredns-558bd4d5db-7kcfd\" (UID: \"8ce1e50d-5699-49de-9a31-edc180d85ebe\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842004     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-rcffp\" (UniqueName: \"kubernetes.io/projected/8ce1e50d-5699-49de-9a31-edc180d85ebe-kube-api-access-rcffp\") pod \"coredns-558bd4d5db-7kcfd\" (UID: \"8ce1e50d-5699-49de-9a31-edc180d85ebe\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842015     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qctc9\" (UniqueName: \"kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842025     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/41df3d8b-173f-407c-91cc-5b0da8567827-config-volume\") pod \"coredns-558bd4d5db-tsnk8\" (UID: \"41df3d8b-173f-407c-91cc-5b0da8567827\") "
Jan 17 03:46:56 kind-control-plane kubelet[607]: E0117 03:46:56.946180     607 configmap.go:200] Couldn't get configMap local-path-storage/local-path-config: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:56 kind-control-plane kubelet[607]: E0117 03:46:56.946265     607 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume podName:ce7d1ef1-5350-4296-96a1-91e716d7d711 nodeName:}" failed. No retries permitted until 2023-01-17 03:46:57.446243849 +0000 UTC m=+31.379466266 (durationBeforeRetry 500ms). Error: "MountVolume.SetUp failed for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") : failed to sync configmap cache: timed out waiting for the condition"
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 projected.go:293] Couldn't get configMap local-path-storage/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 projected.go:199] Error preparing data for projected volume kube-api-access-qctc9 for pod local-path-storage/local-path-provisioner-547f784dff-78qdn: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9 podName:ce7d1ef1-5350-4296-96a1-91e716d7d711 nodeName:}" failed. No retries permitted until 2023-01-17 03:46:57.56032643 +0000 UTC m=+31.493548849 (durationBeforeRetry 500ms). Error: "MountVolume.SetUp failed for volume \"kube-api-access-qctc9\" (UniqueName: \"kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") : failed to sync configmap cache: timed out waiting for the condition"
Jan 17 05:37:45 kind-control-plane kubelet[607]: I0117 05:37:45.518568     607 scope.go:111] "RemoveContainer" containerID="f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3"
Jan 17 05:37:45 kind-control-plane kubelet[607]: E0117 05:37:45.831678     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 05:37:46 kind-control-plane kubelet[607]: E0117 05:37:46.037942     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 05:37:46 kind-control-plane kubelet[607]: I0117 05:37:46.682024     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:37:49 kind-control-plane kubelet[607]: I0117 05:37:49.069873     607 scope.go:111] "RemoveContainer" containerID="93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809"
Jan 17 05:37:55 kind-control-plane kubelet[607]: W0117 05:37:55.966527     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9 WatchSource:0}: task 3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9 not found: not found
Jan 17 05:39:24 kind-control-plane kubelet[607]: E0117 05:39:24.681911     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 05:39:25 kind-control-plane kubelet[607]: E0117 05:39:25.612414     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 05:39:33 kind-control-plane kubelet[607]: I0117 05:39:33.890704     607 scope.go:111] "RemoveContainer" containerID="f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3"
Jan 17 05:39:33 kind-control-plane kubelet[607]: I0117 05:39:33.897022     607 scope.go:111] "RemoveContainer" containerID="f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5"
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.696712     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.797004     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:53592->172.18.0.2:6443: use of closed network connection
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.834548     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02100c8b8491", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ab009ae8f091, ext:6768384696825, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ab009ae8f091, ext:6768384696825, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53592->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.151153     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.455756     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.456021     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:39:35 kind-control-plane kubelet[607]: E0117 05:39:35.456690     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 05:39:35 kind-control-plane kubelet[607]: E0117 05:39:35.995267     607 controller.go:187] failed to update lease, error: Operation cannot be fulfilled on leases.coordination.k8s.io "kind-control-plane": the object has been modified; please apply your changes to the latest version and try again
Jan 17 05:39:42 kind-control-plane kubelet[607]: I0117 05:39:42.322260     607 scope.go:111] "RemoveContainer" containerID="93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809"
Jan 17 05:39:42 kind-control-plane kubelet[607]: I0117 05:39:42.322502     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:39:42 kind-control-plane kubelet[607]: E0117 05:39:42.322662     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:39:45 kind-control-plane kubelet[607]: I0117 05:39:45.180169     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:39:53 kind-control-plane kubelet[607]: I0117 05:39:53.827307     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:49:12 kind-control-plane kubelet[607]: I0117 05:49:12.879180     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:49:12 kind-control-plane kubelet[607]: I0117 05:49:12.881461     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:12 kind-control-plane kubelet[607]: E0117 05:49:12.881666     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:49:13 kind-control-plane kubelet[607]: I0117 05:49:13.887187     607 scope.go:111] "RemoveContainer" containerID="f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5"
Jan 17 05:49:13 kind-control-plane kubelet[607]: I0117 05:49:13.887478     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:13 kind-control-plane kubelet[607]: E0117 05:49:13.887692     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:20 kind-control-plane kubelet[607]: I0117 05:49:20.636818     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:20 kind-control-plane kubelet[607]: E0117 05:49:20.637815     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:22 kind-control-plane kubelet[607]: I0117 05:49:22.050676     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:22 kind-control-plane kubelet[607]: E0117 05:49:22.060142     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:26 kind-control-plane kubelet[607]: I0117 05:49:26.731472     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:26 kind-control-plane kubelet[607]: E0117 05:49:26.731907     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:49:34 kind-control-plane kubelet[607]: I0117 05:49:34.708756     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:39 kind-control-plane kubelet[607]: I0117 05:49:39.645374     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:42 kind-control-plane kubelet[607]: W0117 05:49:42.379235     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a WatchSource:0}: task cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a not found: not found
Jan 17 05:59:12 kind-control-plane kubelet[607]: E0117 05:59:12.681215     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 05:59:17 kind-control-plane kubelet[607]: I0117 05:59:17.063674     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:17 kind-control-plane kubelet[607]: I0117 05:59:17.134236     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:59:17 kind-control-plane kubelet[607]: E0117 05:59:17.338546     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:18 kind-control-plane kubelet[607]: I0117 05:59:18.682393     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:59:18 kind-control-plane kubelet[607]: I0117 05:59:18.728771     607 scope.go:111] "RemoveContainer" containerID="825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6"
Jan 17 05:59:20 kind-control-plane kubelet[607]: I0117 05:59:20.628775     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:20 kind-control-plane kubelet[607]: E0117 05:59:20.629001     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:22 kind-control-plane kubelet[607]: I0117 05:59:22.051529     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:22 kind-control-plane kubelet[607]: E0117 05:59:22.051770     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.205675     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.206022     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 05:59:35 kind-control-plane kubelet[607]: E0117 05:59:35.206890     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.635607     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:35 kind-control-plane kubelet[607]: E0117 05:59:35.635815     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:46 kind-control-plane kubelet[607]: I0117 05:59:46.635769     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:49 kind-control-plane kubelet[607]: I0117 05:59:49.637854     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 05:59:51 kind-control-plane kubelet[607]: W0117 05:59:51.555774     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46 WatchSource:0}: task bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46 not found: not found
Jan 17 06:19:47 kind-control-plane kubelet[607]: E0117 06:19:47.507285     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:19:47 kind-control-plane kubelet[607]: E0117 06:19:47.875284     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:19:52 kind-control-plane kubelet[607]: I0117 06:19:52.723442     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 06:19:52 kind-control-plane kubelet[607]: I0117 06:19:52.774732     607 scope.go:111] "RemoveContainer" containerID="da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760"
Jan 17 06:19:54 kind-control-plane kubelet[607]: I0117 06:19:54.260906     607 scope.go:111] "RemoveContainer" containerID="825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6"
Jan 17 06:19:54 kind-control-plane kubelet[607]: I0117 06:19:54.264931     607 scope.go:111] "RemoveContainer" containerID="93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4"
Jan 17 06:19:55 kind-control-plane kubelet[607]: I0117 06:19:55.629505     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 06:19:55 kind-control-plane kubelet[607]: I0117 06:19:55.644715     607 scope.go:111] "RemoveContainer" containerID="bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46"
Jan 17 06:19:58 kind-control-plane kubelet[607]: W0117 06:19:58.692207     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605 WatchSource:0}: task 85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605 not found: not found
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933702     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.limit_in_bytes: no such device
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933750     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.memsw.limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.memsw.limit_in_bytes: no such device
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933765     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.soft_limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.soft_limit_in_bytes: no such device
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.723215     607 scope.go:111] "RemoveContainer" containerID="93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4"
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.723649     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:22:47 kind-control-plane kubelet[607]: E0117 06:22:47.728133     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.763255     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:22:47 kind-control-plane kubelet[607]: E0117 06:22:47.763466     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.767508     607 scope.go:111] "RemoveContainer" containerID="bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46"
Jan 17 06:22:55 kind-control-plane kubelet[607]: I0117 06:22:55.217212     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:22:55 kind-control-plane kubelet[607]: E0117 06:22:55.217698     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:22:55 kind-control-plane kubelet[607]: I0117 06:22:55.835189     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:23:02 kind-control-plane kubelet[607]: I0117 06:23:02.634660     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:29:35 kind-control-plane kubelet[607]: I0117 06:29:35.486743     607 trace.go:205] Trace[1629297354]: "iptables ChainExists" (17-Jan-2023 06:29:31.667) (total time: 2638ms):
Jan 17 06:29:35 kind-control-plane kubelet[607]: Trace[1629297354]: [2.638212236s] [2.638212236s] END
Jan 17 06:29:39 kind-control-plane kubelet[607]: E0117 06:29:39.924793     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:29:40 kind-control-plane kubelet[607]: E0117 06:29:39.948923     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:29:44 kind-control-plane kubelet[607]: I0117 06:29:44.252961     607 scope.go:111] "RemoveContainer" containerID="da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760"
Jan 17 06:29:44 kind-control-plane kubelet[607]: I0117 06:29:44.260916     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:29:44 kind-control-plane kubelet[607]: E0117 06:29:44.267580     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:29:45 kind-control-plane kubelet[607]: I0117 06:29:45.291696     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:29:45 kind-control-plane kubelet[607]: I0117 06:29:45.293527     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:45 kind-control-plane kubelet[607]: E0117 06:29:45.294034     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:46 kind-control-plane kubelet[607]: I0117 06:29:46.297351     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:46 kind-control-plane kubelet[607]: E0117 06:29:46.297655     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:47 kind-control-plane kubelet[607]: I0117 06:29:47.309909     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:29:47 kind-control-plane kubelet[607]: I0117 06:29:47.311504     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:29:47 kind-control-plane kubelet[607]: E0117 06:29:47.311674     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:29:50 kind-control-plane kubelet[607]: I0117 06:29:50.623574     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:29:55 kind-control-plane kubelet[607]: I0117 06:29:55.177145     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:55 kind-control-plane kubelet[607]: E0117 06:29:55.177431     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:59 kind-control-plane kubelet[607]: I0117 06:29:59.634650     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:29:59 kind-control-plane kubelet[607]: E0117 06:29:59.634853     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:30:09 kind-control-plane kubelet[607]: I0117 06:30:09.688794     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:30:11 kind-control-plane kubelet[607]: I0117 06:30:11.639675     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:30:46 kind-control-plane kubelet[607]: E0117 06:30:46.826263     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:30:46 kind-control-plane kubelet[607]: E0117 06:30:46.875803     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:30:56 kind-control-plane kubelet[607]: E0117 06:30:56.857846     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:30:57 kind-control-plane kubelet[607]: E0117 06:30:56.906615     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"etcd-kind-control-plane.173b04dd9f6f73a1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"etcd-kind-control-plane", UID:"24ba8551bcc724a32d591bb02c423d92", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{etcd}"}, Reason:"Unhealthy", Message:"Liveness probe failed: HTTP probe failed with statuscode: 503", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae031848fba1, ext:9850340659837, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae031848fba1, ext:9850340659837, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:50656->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:30:57 kind-control-plane kubelet[607]: E0117 06:30:56.906780     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:50656->172.18.0.2:6443: use of closed network connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:30:57 kind-control-plane kubelet[607]: W0117 06:30:56.922214     607 reflector.go:436] object-"local-path-storage"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.152863     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.183200     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:01 kind-control-plane kubelet[607]: E0117 06:31:01.183764     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.626555     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.690583     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:01 kind-control-plane kubelet[607]: E0117 06:31:01.690924     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:02 kind-control-plane kubelet[607]: I0117 06:31:02.652307     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:02 kind-control-plane kubelet[607]: E0117 06:31:02.652552     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:05 kind-control-plane kubelet[607]: I0117 06:31:05.178892     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:05 kind-control-plane kubelet[607]: E0117 06:31:05.180941     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:05 kind-control-plane kubelet[607]: I0117 06:31:05.800004     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:05 kind-control-plane kubelet[607]: E0117 06:31:05.817125     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:10 kind-control-plane kubelet[607]: I0117 06:31:10.621551     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:10 kind-control-plane kubelet[607]: E0117 06:31:10.623834     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:17 kind-control-plane kubelet[607]: I0117 06:31:17.707608     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:17 kind-control-plane kubelet[607]: E0117 06:31:17.707890     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:24 kind-control-plane kubelet[607]: I0117 06:31:24.644389     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:32 kind-control-plane kubelet[607]: I0117 06:31:32.651781     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:32 kind-control-plane kubelet[607]: E0117 06:31:32.890717     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:48 kind-control-plane kubelet[607]: I0117 06:31:48.654886     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:54 kind-control-plane kubelet[607]: W0117 06:31:54.227151     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98 WatchSource:0}: task e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98 not found: not found
Jan 17 06:32:13 kind-control-plane kubelet[607]: E0117 06:32:13.104441     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:32:14 kind-control-plane kubelet[607]: E0117 06:32:14.186314     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.217519     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.268429     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:32:23 kind-control-plane kubelet[607]: I0117 06:32:23.268749     607 status_manager.go:589] "Failed to update status for pod" pod="kube-system/kube-controller-manager-kind-control-plane" err="failed to patch status \"{\\\"metadata\\\":{\\\"uid\\\":\\\"779722c9-072a-4757-8b67-2123c25ed3e6\\\"},\\\"status\\\":{\\\"containerStatuses\\\":[{\\\"containerID\\\":\\\"containerd://e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98\\\",\\\"image\\\":\\\"k8s.gcr.io/kube-controller-manager:v1.21.1\\\",\\\"imageID\\\":\\\"sha256:96a295389d472f96d58764c2ed3e7418d0183f707765c21e6f310c2e163225a9\\\",\\\"lastState\\\":{\\\"terminated\\\":{\\\"containerID\\\":\\\"containerd://813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4\\\",\\\"exitCode\\\":255,\\\"finishedAt\\\":\\\"2023-01-17T06:30:54Z\\\",\\\"reason\\\":\\\"Error\\\",\\\"startedAt\\\":\\\"2023-01-17T06:30:09Z\\\"}},\\\"name\\\":\\\"kube-controller-manager\\\",\\\"ready\\\":false,\\\"restartCount\\\":7,\\\"started\\\":false,\\\"state\\\":{\\\"running\\\":{\\\"startedAt\\\":\\\"2023-01-17T06:31:54Z\\\"}}}]}}\" for pod \"kube-system\"/\"kube-controller-manager-kind-control-plane\": Patch \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane/status\": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection"
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.293815     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.297606     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.297997     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:54968->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.314125     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:54968->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.415789     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.482406     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:55428->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:43 kind-control-plane kubelet[607]: I0117 06:32:43.482449     607 controller.go:114] failed to update lease using latest lease, fallback to ensure lease, err: failed 5 attempts to update lease
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.554029     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:32:53 kind-control-plane kubelet[607]: E0117 06:32:53.862681     607 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067718     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067752     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067827     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:55870->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:04 kind-control-plane kubelet[607]: E0117 06:33:04.079864     607 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:14 kind-control-plane kubelet[607]: E0117 06:33:14.351731     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:14 kind-control-plane kubelet[607]: E0117 06:33:14.692492     607 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:33:25 kind-control-plane kubelet[607]: E0117 06:33:25.455735     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:29 kind-control-plane kubelet[607]: E0117 06:33:29.847572     607 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:31 kind-control-plane kubelet[607]: E0117 06:33:27.406328     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:56448->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:36 kind-control-plane kubelet[607]: E0117 06:33:36.464907     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:33:41 kind-control-plane kubelet[607]: E0117 06:33:41.602511     607 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:46 kind-control-plane kubelet[607]: E0117 06:33:46.496937     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:58358->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:46 kind-control-plane kubelet[607]: E0117 06:33:46.571407     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:55 kind-control-plane kubelet[607]: E0117 06:33:55.123589     607 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.665646     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.665673     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.604093     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:58576->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:59 kind-control-plane kubelet[607]: I0117 06:33:59.709030     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:33:59 kind-control-plane kubelet[607]: I0117 06:33:59.950004     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:00 kind-control-plane kubelet[607]: I0117 06:34:00.159933     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:00 kind-control-plane kubelet[607]: I0117 06:34:00.476162     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: E0117 06:34:01.993911     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034509     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034808     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034957     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.162693     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.163945     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.733226     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.825455     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.866847     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.887532     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.887567     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:34:09 kind-control-plane kubelet[607]: E0117 06:34:09.021906     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681409     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681586     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681701     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:15 kind-control-plane kubelet[607]: I0117 06:34:15.123663     607 scope.go:111] "RemoveContainer" containerID="faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c"
Jan 17 06:34:15 kind-control-plane kubelet[607]: I0117 06:34:15.143468     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:16 kind-control-plane kubelet[607]: E0117 06:34:16.239260     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.210226     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.888872     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906108     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906404     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906542     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906646     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906655     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:34:18 kind-control-plane kubelet[607]: I0117 06:34:18.703776     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:20 kind-control-plane kubelet[607]: I0117 06:34:20.608584     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:22 kind-control-plane kubelet[607]: I0117 06:34:22.376279     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:34:22 kind-control-plane kubelet[607]: I0117 06:34:22.376714     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:22 kind-control-plane kubelet[607]: E0117 06:34:22.376965     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:31 kind-control-plane kubelet[607]: I0117 06:34:31.804316     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:34:33 kind-control-plane kubelet[607]: E0117 06:34:33.327890     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:34:35 kind-control-plane kubelet[607]: I0117 06:34:35.685556     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:35 kind-control-plane kubelet[607]: E0117 06:34:35.685935     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:37 kind-control-plane kubelet[607]: E0117 06:34:37.227309     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:34:37 kind-control-plane kubelet[607]: E0117 06:34:37.934715     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:34:41 kind-control-plane kubelet[607]: I0117 06:34:41.931355     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:34:47 kind-control-plane kubelet[607]: W0117 06:34:47.949771     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.RuntimeClass ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:34:47 kind-control-plane kubelet[607]: E0117 06:34:47.949865     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:34852->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:34:47 kind-control-plane kubelet[607]: W0117 06:34:47.954603     607 reflector.go:436] object-"local-path-storage"/"local-path-config": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"local-path-config": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:34:47 kind-control-plane kubelet[607]: E0117 06:34:47.954644     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:34:48 kind-control-plane kubelet[607]: I0117 06:34:48.650907     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:48 kind-control-plane kubelet[607]: E0117 06:34:48.652486     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:50 kind-control-plane kubelet[607]: E0117 06:34:50.360110     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:34:58 kind-control-plane kubelet[607]: E0117 06:34:58.091391     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:35:02 kind-control-plane kubelet[607]: I0117 06:35:02.730859     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:35:07 kind-control-plane kubelet[607]: E0117 06:35:07.396427     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:35:08 kind-control-plane kubelet[607]: W0117 06:35:08.742751     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d WatchSource:0}: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:08 kind-control-plane kubelet[607]: E0117 06:35:08.786411     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:35:08 kind-control-plane kubelet[607]: E0117 06:35:08.835354     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:35:19 kind-control-plane kubelet[607]: E0117 06:35:19.342708     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:19 kind-control-plane kubelet[607]: E0117 06:35:19.342736     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:35:24 kind-control-plane kubelet[607]: E0117 06:35:24.634607     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:35:30 kind-control-plane kubelet[607]: I0117 06:35:30.484749     607 trace.go:205] Trace[2018775996]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:34:49.406) (total time: 41078ms):
Jan 17 06:35:30 kind-control-plane kubelet[607]: Trace[2018775996]: [41.078241475s] [41.078241475s] END
Jan 17 06:35:30 kind-control-plane kubelet[607]: E0117 06:35:30.484786     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16016": net/http: TLS handshake timeout
Jan 17 06:35:33 kind-control-plane kubelet[607]: I0117 06:35:33.641758     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:35:37 kind-control-plane kubelet[607]: I0117 06:35:37.945664     607 trace.go:205] Trace[2007941272]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:34:48.878) (total time: 48971ms):
Jan 17 06:35:37 kind-control-plane kubelet[607]: Trace[2007941272]: [48.971406005s] [48.971406005s] END
Jan 17 06:35:37 kind-control-plane kubelet[607]: E0117 06:35:37.945714     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16146": net/http: TLS handshake timeout
Jan 17 06:35:39 kind-control-plane kubelet[607]: E0117 06:35:39.471580     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:40 kind-control-plane kubelet[607]: I0117 06:35:40.895941     607 trace.go:205] Trace[294080245]: "iptables ChainExists" (17-Jan-2023 06:35:31.695) (total time: 8743ms):
Jan 17 06:35:40 kind-control-plane kubelet[607]: Trace[294080245]: [8.743759725s] [8.743759725s] END
Jan 17 06:35:40 kind-control-plane kubelet[607]: W0117 06:35:40.895995     607 iptables.go:579] Could not check for iptables canary mangle/KUBE-KUBELET-CANARY: exit status 4
Jan 17 06:35:42 kind-control-plane kubelet[607]: I0117 06:35:42.346634     607 trace.go:205] Trace[1174702308]: "iptables ChainExists" (17-Jan-2023 06:35:31.690) (total time: 8889ms):
Jan 17 06:35:42 kind-control-plane kubelet[607]: Trace[1174702308]: [8.889691644s] [8.889691644s] END
Jan 17 06:35:42 kind-control-plane kubelet[607]: W0117 06:35:42.346704     607 iptables.go:579] Could not check for iptables canary mangle/KUBE-KUBELET-CANARY: exit status 4
Jan 17 06:35:43 kind-control-plane kubelet[607]: E0117 06:35:42.939295     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:35:44 kind-control-plane kubelet[607]: I0117 06:35:44.136465     607 trace.go:205] Trace[2100721423]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:35:32.636) (total time: 11499ms):
Jan 17 06:35:44 kind-control-plane kubelet[607]: Trace[2100721423]: [11.49986088s] [11.49986088s] END
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.136492     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16016": net/http: TLS handshake timeout
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.364717     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.681773     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.681872     607 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04f470d7a27f", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Jan 17 06:35:46 kind-control-plane kubelet[607]: E0117 06:35:46.117559     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:47 kind-control-plane kubelet[607]: I0117 06:35:47.741734     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:35:48 kind-control-plane kubelet[607]: I0117 06:35:48.779868     607 scope.go:111] "RemoveContainer" containerID="faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c"
Jan 17 06:35:48 kind-control-plane kubelet[607]: I0117 06:35:48.787066     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:35:48 kind-control-plane kubelet[607]: E0117 06:35:48.799688     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:35:49 kind-control-plane kubelet[607]: E0117 06:35:49.473537     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-kind-control-plane.173b04f24d18e354", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-controller-manager-kind-control-plane", UID:"46dac9a538838115821dfd9559149484", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-controller-manager}"}, Reason:"Unhealthy", Message:"Startup probe failed: Get \"https://127.0.0.1:10257/healthz\": dial tcp 127.0.0.1:10257: connect: connection refused", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae194d223154, ext:9939153568107, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1bcf0f90ff, ext:9949185902147, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-controller-manager-kind-control-plane.173b04f24d18e354": read tcp 172.18.0.2:37600->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:35:49 kind-control-plane kubelet[607]: E0117 06:35:49.474880     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.660522     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.660682     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.801361     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.801507     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:59 kind-control-plane kubelet[607]: E0117 06:35:59.587676     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:59 kind-control-plane kubelet[607]: E0117 06:35:59.883694     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-kind-control-plane.173b04f24d18e354", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-controller-manager-kind-control-plane", UID:"46dac9a538838115821dfd9559149484", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-controller-manager}"}, Reason:"Unhealthy", Message:"Startup probe failed: Get \"https://127.0.0.1:10257/healthz\": dial tcp 127.0.0.1:10257: connect: connection refused", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae194d223154, ext:9939153568107, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1bcf0f90ff, ext:9949185902147, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-controller-manager-kind-control-plane.173b04f24d18e354": read tcp 172.18.0.2:37890->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:36:00 kind-control-plane kubelet[607]: I0117 06:36:00.538835     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:36:01 kind-control-plane kubelet[607]: E0117 06:36:01.166711     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:36:06 kind-control-plane kubelet[607]: W0117 06:36:06.412797     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/pode5ced440-70ff-4944-9756-a3d368c86a5d/0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a WatchSource:0}: task 0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a not found: not found
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.466015     607 trace.go:205] Trace[164233999]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:35:56.342) (total time: 13123ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[164233999]: [13.123788267s] [13.123788267s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.471726     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.829819     607 trace.go:205] Trace[200181100]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:55.969) (total time: 13860ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[200181100]: ---"Objects listed" 13860ms (06:36:00.829)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[200181100]: [13.860265225s] [13.860265225s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.843857     607 trace.go:205] Trace[1005973061]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:35:55.701) (total time: 14142ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1005973061]: [14.14227732s] [14.14227732s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.843895     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.856849     607 trace.go:205] Trace[64763159]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:35:55.493) (total time: 14362ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[64763159]: [14.362990834s] [14.362990834s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.856877     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.856929     607 trace.go:205] Trace[1815204842]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:35:55.999) (total time: 13857ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1815204842]: [13.857544985s] [13.857544985s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.856935     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.857179     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.857536     607 request.go:1027] Unexpected error when reading response body: read tcp 172.18.0.2:38486->172.18.0.2:6443: use of closed network connection
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.891761     607 trace.go:205] Trace[1994958741]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:56.342) (total time: 13549ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1994958741]: ---"Objects listed" 13549ms (06:36:00.891)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1994958741]: [13.549255152s] [13.549255152s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.891984     607 trace.go:205] Trace[2135630075]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:35:49.948) (total time: 19943ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[2135630075]: [19.943547424s] [19.943547424s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.891998     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: unexpected error when reading response body. Please retry. Original error: read tcp 172.18.0.2:38486->172.18.0.2:6443: use of closed network connection
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.899789     607 trace.go:205] Trace[619753212]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:35:55.800) (total time: 14099ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[619753212]: ---"Objects listed" 14099ms (06:36:00.899)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[619753212]: [14.099437716s] [14.099437716s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.932199     607 trace.go:205] Trace[1038531942]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:41.749) (total time: 28182ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1038531942]: ---"Objects listed" 28177ms (06:36:00.927)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1038531942]: [28.18234687s] [28.18234687s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.932524     607 trace.go:205] Trace[1968695855]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:55.945) (total time: 13986ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1968695855]: ---"Objects listed" 13867ms (06:36:00.813)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1968695855]: [13.9866024s] [13.9866024s] END
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.392773     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.580997     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.692782     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:17 kind-control-plane kubelet[607]: E0117 06:36:17.592592     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:41 kind-control-plane kubelet[607]: E0117 06:36:41.817349     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:36:43 kind-control-plane kubelet[607]: E0117 06:36:43.445265     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:36:44 kind-control-plane kubelet[607]: E0117 06:36:44.876206     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:36:46 kind-control-plane kubelet[607]: E0117 06:36:46.625183     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:53.386592     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:54.390734     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:54.509504     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:38874->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.082913     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:40286->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.085469     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:40320->172.18.0.2:6443: use of closed network connection
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.119551     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.184975     607 remote_runtime.go:253] "StartContainer from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.948359     607 kuberuntime_manager.go:864] container &Container{Name:local-path-provisioner,Image:docker.io/rancher/local-path-provisioner:v0.0.14,Command:[local-path-provisioner --debug start --helper-image k8s.gcr.io/build-image/debian-base:v2.1.0 --config /etc/config/config.json],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:config-volume,ReadOnly:false,MountPath:/etc/config/,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-qctc9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711): RunContainerError: context deadline exceeded
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.954512     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with RunContainerError: \"context deadline exceeded\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:16 kind-control-plane kubelet[607]: E0117 06:37:16.276919     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:16 kind-control-plane kubelet[607]: I0117 06:37:16.463905     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:16 kind-control-plane kubelet[607]: E0117 06:37:16.468830     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:19 kind-control-plane kubelet[607]: I0117 06:37:19.615709     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:19 kind-control-plane kubelet[607]: E0117 06:37:19.616015     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:20 kind-control-plane kubelet[607]: I0117 06:37:20.578034     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:20 kind-control-plane kubelet[607]: E0117 06:37:20.637526     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.597928     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:41092->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.600979     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.600999     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.602628     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:26 kind-control-plane kubelet[607]: I0117 06:37:26.602658     607 controller.go:114] failed to update lease using latest lease, fallback to ensure lease, err: failed 5 attempts to update lease
Jan 17 06:37:33 kind-control-plane kubelet[607]: I0117 06:37:33.024292     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:33 kind-control-plane kubelet[607]: E0117 06:37:33.024709     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:36 kind-control-plane kubelet[607]: E0117 06:37:36.769031     607 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:37 kind-control-plane kubelet[607]: I0117 06:37:37.655551     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:41 kind-control-plane kubelet[607]: E0117 06:37:41.902210     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:37:45 kind-control-plane kubelet[607]: E0117 06:37:45.450589     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.532027     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.578417     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.351934     607 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: TLS handshake timeout
Jan 17 06:37:47 kind-control-plane kubelet[607]: I0117 06:37:47.954013     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:49 kind-control-plane kubelet[607]: I0117 06:37:49.021585     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:49 kind-control-plane kubelet[607]: E0117 06:37:49.024141     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:58 kind-control-plane kubelet[607]: I0117 06:37:58.439450     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": net/http: TLS handshake timeout"
Jan 17 06:37:58 kind-control-plane kubelet[607]: W0117 06:37:58.464131     607 reflector.go:436] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:37:59 kind-control-plane kubelet[607]: E0117 06:37:58.846022     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:59 kind-control-plane kubelet[607]: I0117 06:37:58.876679     607 request.go:668] Waited for 1.279855667s due to client-side throttling, not priority and fairness, request: PATCH:https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1
Jan 17 06:37:59 kind-control-plane kubelet[607]: E0117 06:37:59.455764     607 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:00 kind-control-plane kubelet[607]: I0117 06:38:00.732779     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:00 kind-control-plane kubelet[607]: E0117 06:38:00.887572     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:09 kind-control-plane kubelet[607]: E0117 06:38:09.030966     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:42818->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:38:09 kind-control-plane kubelet[607]: E0117 06:38:09.031800     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:38:10 kind-control-plane kubelet[607]: E0117 06:38:10.339982     607 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:16 kind-control-plane kubelet[607]: I0117 06:38:16.946190     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:17 kind-control-plane kubelet[607]: E0117 06:38:17.206309     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:19 kind-control-plane kubelet[607]: E0117 06:38:19.259736     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:38:22 kind-control-plane kubelet[607]: E0117 06:38:22.118474     607 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.324794     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:43904->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.383686     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.383715     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:38:33 kind-control-plane kubelet[607]: I0117 06:38:33.274592     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:33 kind-control-plane kubelet[607]: E0117 06:38:33.274923     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:35 kind-control-plane kubelet[607]: E0117 06:38:35.391754     607 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:37 kind-control-plane kubelet[607]: E0117 06:38:37.094347     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:38:38 kind-control-plane kubelet[607]: E0117 06:38:38.799914     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:38:40 kind-control-plane kubelet[607]: I0117 06:38:40.415979     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": net/http: TLS handshake timeout"
Jan 17 06:38:41 kind-control-plane kubelet[607]: I0117 06:38:41.741916     607 trace.go:205] Trace[1435387408]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:38:00.222) (total time: 41519ms):
Jan 17 06:38:41 kind-control-plane kubelet[607]: Trace[1435387408]: [41.519520444s] [41.519520444s] END
Jan 17 06:38:41 kind-control-plane kubelet[607]: E0117 06:38:41.742732     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:38:45 kind-control-plane kubelet[607]: I0117 06:38:45.076378     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.452411     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.582371     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.753770     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:38:55 kind-control-plane kubelet[607]: I0117 06:38:55.099378     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:38:56 kind-control-plane kubelet[607]: I0117 06:38:56.024610     607 trace.go:205] Trace[937553544]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:38:43.639) (total time: 11636ms):
Jan 17 06:38:56 kind-control-plane kubelet[607]: Trace[937553544]: [11.63664177s] [11.63664177s] END
Jan 17 06:38:56 kind-control-plane kubelet[607]: E0117 06:38:56.024664     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:38:56 kind-control-plane kubelet[607]: I0117 06:38:56.944370     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:39:01 kind-control-plane kubelet[607]: W0117 06:39:01.930230     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 WatchSource:0}: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:02 kind-control-plane kubelet[607]: E0117 06:39:02.629130     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:39:10 kind-control-plane kubelet[607]: E0117 06:39:10.045321     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:39:14 kind-control-plane kubelet[607]: I0117 06:39:14.432734     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": net/http: TLS handshake timeout"
Jan 17 06:39:14 kind-control-plane kubelet[607]: E0117 06:39:14.937415     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:39:15 kind-control-plane kubelet[607]: I0117 06:39:15.484557     607 trace.go:205] Trace[565735942]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:39:02.228) (total time: 13255ms):
Jan 17 06:39:15 kind-control-plane kubelet[607]: Trace[565735942]: [13.255508623s] [13.255508623s] END
Jan 17 06:39:15 kind-control-plane kubelet[607]: E0117 06:39:15.484610     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:39:15 kind-control-plane kubelet[607]: E0117 06:39:15.598827     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:39:25 kind-control-plane kubelet[607]: E0117 06:39:25.556483     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:25.994468     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:46710->172.18.0.2:6443: read: connection reset by peer'(may retry after sleeping)
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023873     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.Node ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023950     607 reflector.go:436] object-"local-path-storage"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023988     607 reflector.go:436] object-"local-path-storage"/"local-path-config": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"local-path-config": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.024033     607 reflector.go:436] object-"kube-system"/"coredns": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"coredns": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027453     607 reflector.go:436] object-"kube-system"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027507     607 reflector.go:436] object-"kube-system"/"kube-proxy": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"kube-proxy": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027547     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.CSIDriver ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027582     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.Service ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027622     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.RuntimeClass ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566340     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:26.566649     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566718     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566918     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572082     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572316     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572517     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:26.861829     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.024195     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.024220     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.142270     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.226849     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.243989     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.289026     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.294122     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.294225     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.395365     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.567790     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.767408     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:28 kind-control-plane kubelet[607]: E0117 06:39:28.955542     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.011771     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.235880     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.575966     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.727576     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.812442     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.341076     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.554749     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.823617     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.061032     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.061311     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:31 kind-control-plane kubelet[607]: E0117 06:39:31.061564     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.064933     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658399     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658731     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658942     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.703713     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.062795     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.534775     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.574579     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.802364     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.174637     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.318800     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.612646     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.039866     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.064157     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.581413     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.860923     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:36 kind-control-plane kubelet[607]: E0117 06:39:36.061809     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:36 kind-control-plane kubelet[607]: E0117 06:39:36.123962     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.070722     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088005     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088280     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088397     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088497     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088509     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:39:39 kind-control-plane kubelet[607]: E0117 06:39:39.708849     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:40 kind-control-plane kubelet[607]: I0117 06:39:40.127339     607 scope.go:111] "RemoveContainer" containerID="80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1"
Jan 17 06:39:40 kind-control-plane kubelet[607]: I0117 06:39:40.199829     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:40 kind-control-plane kubelet[607]: E0117 06:39:40.611145     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.008566     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.313349     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.313788     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.322652     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.443771     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.888302     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.898838     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.913137     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958479     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958769     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958942     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:42 kind-control-plane kubelet[607]: I0117 06:39:42.652590     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:42 kind-control-plane kubelet[607]: E0117 06:39:42.652883     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:39:42 kind-control-plane kubelet[607]: I0117 06:39:42.671452     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:51 kind-control-plane kubelet[607]: I0117 06:39:51.649614     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:39:51 kind-control-plane kubelet[607]: E0117 06:39:51.724950     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:39:53 kind-control-plane kubelet[607]: I0117 06:39:53.140558     607 trace.go:205] Trace[2083225363]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:39:43.137) (total time: 10002ms):
Jan 17 06:39:53 kind-control-plane kubelet[607]: Trace[2083225363]: [10.002684435s] [10.002684435s] END
Jan 17 06:39:53 kind-control-plane kubelet[607]: E0117 06:39:53.140584     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:53 kind-control-plane kubelet[607]: I0117 06:39:53.326992     607 trace.go:205] Trace[1674044423]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:39:43.311) (total time: 10015ms):
Jan 17 06:39:53 kind-control-plane kubelet[607]: Trace[1674044423]: [10.015535126s] [10.015535126s] END
Jan 17 06:39:53 kind-control-plane kubelet[607]: E0117 06:39:53.327080     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.682790     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.696294     607 trace.go:205] Trace[359120376]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:45.592) (total time: 10104ms):
Jan 17 06:39:55 kind-control-plane kubelet[607]: Trace[359120376]: [10.104123071s] [10.104123071s] END
Jan 17 06:39:55 kind-control-plane kubelet[607]: E0117 06:39:55.696323     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.779445     607 trace.go:205] Trace[306164034]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:39:45.777) (total time: 10002ms):
Jan 17 06:39:55 kind-control-plane kubelet[607]: Trace[306164034]: [10.002204877s] [10.002204877s] END
Jan 17 06:39:55 kind-control-plane kubelet[607]: E0117 06:39:55.779470     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:56 kind-control-plane kubelet[607]: E0117 06:39:56.189135     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:39:56 kind-control-plane kubelet[607]: I0117 06:39:56.720783     607 trace.go:205] Trace[1202646431]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:46.714) (total time: 10006ms):
Jan 17 06:39:56 kind-control-plane kubelet[607]: Trace[1202646431]: [10.006096546s] [10.006096546s] END
Jan 17 06:39:56 kind-control-plane kubelet[607]: E0117 06:39:56.720809     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: I0117 06:39:57.037976     607 trace.go:205] Trace[849438168]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:39:47.035) (total time: 10002ms):
Jan 17 06:39:57 kind-control-plane kubelet[607]: Trace[849438168]: [10.002750533s] [10.002750533s] END
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.038021     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.091520     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:39:57 kind-control-plane kubelet[607]: I0117 06:39:57.158029     607 trace.go:205] Trace[443911200]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:47.144) (total time: 10013ms):
Jan 17 06:39:57 kind-control-plane kubelet[607]: Trace[443911200]: [10.013822076s] [10.013822076s] END
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.158056     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.673752     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:40:01 kind-control-plane kubelet[607]: I0117 06:40:01.952881     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": net/http: TLS handshake timeout"
Jan 17 06:40:04 kind-control-plane kubelet[607]: I0117 06:40:04.654510     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:04 kind-control-plane kubelet[607]: E0117 06:40:04.654936     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.095181     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:50236->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.095249     607 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04facc5eb58c", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.105312     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:14 kind-control-plane kubelet[607]: E0117 06:40:14.750402     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:40:17 kind-control-plane kubelet[607]: E0117 06:40:17.208713     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:40:17 kind-control-plane kubelet[607]: E0117 06:40:17.240748     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:18 kind-control-plane kubelet[607]: I0117 06:40:18.016934     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:18 kind-control-plane kubelet[607]: E0117 06:40:18.016934     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:27 kind-control-plane kubelet[607]: E0117 06:40:27.242570     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:51088->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:40:27 kind-control-plane kubelet[607]: E0117 06:40:27.242826     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:29 kind-control-plane kubelet[607]: I0117 06:40:29.767576     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:29 kind-control-plane kubelet[607]: E0117 06:40:29.767902     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:31 kind-control-plane kubelet[607]: E0117 06:40:31.775923     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:40:36 kind-control-plane kubelet[607]: E0117 06:40:36.478054     607 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubelet/kubepods/burstable/podbd1c21fe1f0ef615e0b5e41299f1be61/712f4efd80bc3c2f50ceaaefaf1e5b134f92a909ff8b96704302535a32203cc6\": RecentStats: unable to find data in memory cache]"
Jan 17 06:40:37 kind-control-plane kubelet[607]: E0117 06:40:37.278233     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:40:37 kind-control-plane kubelet[607]: E0117 06:40:37.278293     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:40:44 kind-control-plane kubelet[607]: I0117 06:40:44.878819     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:44 kind-control-plane kubelet[607]: E0117 06:40:44.974706     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:47 kind-control-plane kubelet[607]: E0117 06:40:47.303379     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:40:48 kind-control-plane kubelet[607]: I0117 06:40:48.617487     607 trace.go:205] Trace[1386534978]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:17.735) (total time: 30882ms):
Jan 17 06:40:48 kind-control-plane kubelet[607]: Trace[1386534978]: [30.88220543s] [30.88220543s] END
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.617536     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:48 kind-control-plane kubelet[607]: I0117 06:40:48.650801     607 trace.go:205] Trace[1856222165]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:40:06.677) (total time: 41973ms):
Jan 17 06:40:48 kind-control-plane kubelet[607]: Trace[1856222165]: [41.973643557s] [41.973643557s] END
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.650841     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.792942     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:40:49 kind-control-plane kubelet[607]: I0117 06:40:49.831547     607 trace.go:205] Trace[234419410]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:40:12.930) (total time: 36901ms):
Jan 17 06:40:49 kind-control-plane kubelet[607]: Trace[234419410]: [36.901313989s] [36.901313989s] END
Jan 17 06:40:49 kind-control-plane kubelet[607]: E0117 06:40:49.831570     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:51 kind-control-plane kubelet[607]: I0117 06:40:51.732861     607 trace.go:205] Trace[2119911038]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:19.205) (total time: 32527ms):
Jan 17 06:40:51 kind-control-plane kubelet[607]: Trace[2119911038]: [32.527129969s] [32.527129969s] END
Jan 17 06:40:51 kind-control-plane kubelet[607]: E0117 06:40:51.732894     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: I0117 06:40:57.043956     607 trace.go:205] Trace[1842200745]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:40:20.037) (total time: 36478ms):
Jan 17 06:40:57 kind-control-plane kubelet[607]: Trace[1842200745]: [36.478638871s] [36.478638871s] END
Jan 17 06:40:57 kind-control-plane kubelet[607]: I0117 06:40:57.110560     607 trace.go:205] Trace[1529820061]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:40:15.108) (total time: 41456ms):
Jan 17 06:40:57 kind-control-plane kubelet[607]: Trace[1529820061]: [41.456124683s] [41.456124683s] END
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.110611     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.251648     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.312774     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:59 kind-control-plane kubelet[607]: I0117 06:40:59.346974     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:59 kind-control-plane kubelet[607]: E0117 06:40:59.796639     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:04 kind-control-plane kubelet[607]: I0117 06:41:04.026646     607 trace.go:205] Trace[1754297056]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:39:58.038) (total time: 65987ms):
Jan 17 06:41:04 kind-control-plane kubelet[607]: Trace[1754297056]: [1m5.987954099s] [1m5.987954099s] END
Jan 17 06:41:04 kind-control-plane kubelet[607]: E0117 06:41:04.026682     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:04 kind-control-plane kubelet[607]: I0117 06:41:04.505719     607 trace.go:205] Trace[1439752824]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:12.634) (total time: 51871ms):
Jan 17 06:41:04 kind-control-plane kubelet[607]: Trace[1439752824]: [51.871380234s] [51.871380234s] END
Jan 17 06:41:04 kind-control-plane kubelet[607]: E0117 06:41:04.505757     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:06 kind-control-plane kubelet[607]: E0117 06:41:06.614210     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:41:07 kind-control-plane kubelet[607]: E0117 06:41:07.542812     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:52696->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:07 kind-control-plane kubelet[607]: E0117 06:41:07.703081     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:41:08 kind-control-plane kubelet[607]: I0117 06:41:08.660756     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: i/o timeout"
Jan 17 06:41:08 kind-control-plane kubelet[607]: I0117 06:41:08.790709     607 trace.go:205] Trace[1391932347]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:40:06.638) (total time: 62152ms):
Jan 17 06:41:08 kind-control-plane kubelet[607]: Trace[1391932347]: [1m2.152481228s] [1m2.152481228s] END
Jan 17 06:41:08 kind-control-plane kubelet[607]: E0117 06:41:08.790737     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:09 kind-control-plane kubelet[607]: I0117 06:41:09.063663     607 trace.go:205] Trace[1065960748]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:59.978) (total time: 69084ms):
Jan 17 06:41:09 kind-control-plane kubelet[607]: Trace[1065960748]: [1m9.084887294s] [1m9.084887294s] END
Jan 17 06:41:09 kind-control-plane kubelet[607]: E0117 06:41:09.063694     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:16 kind-control-plane kubelet[607]: I0117 06:41:16.825261     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:16.990381     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:17.834267     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53332->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:17.894797     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:23 kind-control-plane kubelet[607]: E0117 06:41:23.667752     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:41:28 kind-control-plane kubelet[607]: E0117 06:41:28.414577     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:31 kind-control-plane kubelet[607]: I0117 06:41:31.368873     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:31 kind-control-plane kubelet[607]: E0117 06:41:31.391466     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511217     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53628->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511474     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511493     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:41:40 kind-control-plane kubelet[607]: E0117 06:41:40.935600     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:42 kind-control-plane kubelet[607]: I0117 06:41:42.884242     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:42 kind-control-plane kubelet[607]: E0117 06:41:42.884647     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:50 kind-control-plane kubelet[607]: I0117 06:41:50.025470     607 trace.go:205] Trace[1941401903]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:41:38.909) (total time: 11116ms):
Jan 17 06:41:50 kind-control-plane kubelet[607]: Trace[1941401903]: [11.116146771s] [11.116146771s] END
Jan 17 06:41:50 kind-control-plane kubelet[607]: E0117 06:41:50.025504     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:52 kind-control-plane kubelet[607]: I0117 06:41:52.646975     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:41:54 kind-control-plane kubelet[607]: I0117 06:41:54.232348     607 trace.go:205] Trace[446508473]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:35.230) (total time: 18933ms):
Jan 17 06:41:54 kind-control-plane kubelet[607]: Trace[446508473]: [18.933287782s] [18.933287782s] END
Jan 17 06:41:54 kind-control-plane kubelet[607]: E0117 06:41:54.232386     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:55 kind-control-plane kubelet[607]: I0117 06:41:55.563497     607 trace.go:205] Trace[407658894]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:41:45.261) (total time: 10301ms):
Jan 17 06:41:55 kind-control-plane kubelet[607]: Trace[407658894]: [10.301733541s] [10.301733541s] END
Jan 17 06:41:55 kind-control-plane kubelet[607]: E0117 06:41:55.563559     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:41:56 kind-control-plane kubelet[607]: I0117 06:41:56.375237     607 trace.go:205] Trace[1036307788]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:41:30.730) (total time: 25644ms):
Jan 17 06:41:56 kind-control-plane kubelet[607]: Trace[1036307788]: [25.644416841s] [25.644416841s] END
Jan 17 06:41:56 kind-control-plane kubelet[607]: E0117 06:41:56.375275     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:56 kind-control-plane kubelet[607]: I0117 06:41:56.738843     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:56 kind-control-plane kubelet[607]: E0117 06:41:56.757664     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:58 kind-control-plane kubelet[607]: I0117 06:41:58.015104     607 trace.go:205] Trace[697839201]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:23.171) (total time: 34843ms):
Jan 17 06:41:58 kind-control-plane kubelet[607]: Trace[697839201]: [34.843106216s] [34.843106216s] END
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.015144     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.264526     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.585677     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:59 kind-control-plane kubelet[607]: E0117 06:41:59.722698     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:42:02 kind-control-plane kubelet[607]: I0117 06:42:02.720017     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:42:02 kind-control-plane kubelet[607]: I0117 06:42:02.733541     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:02 kind-control-plane kubelet[607]: E0117 06:42:02.733950     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:04 kind-control-plane kubelet[607]: I0117 06:42:04.144483     607 trace.go:205] Trace[1880481919]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:53.986) (total time: 10127ms):
Jan 17 06:42:04 kind-control-plane kubelet[607]: Trace[1880481919]: [10.127817176s] [10.127817176s] END
Jan 17 06:42:04 kind-control-plane kubelet[607]: E0117 06:42:04.147968     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:04 kind-control-plane kubelet[607]: I0117 06:42:04.722464     607 trace.go:205] Trace[401429468]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:32.128) (total time: 32593ms):
Jan 17 06:42:04 kind-control-plane kubelet[607]: Trace[401429468]: [32.593977255s] [32.593977255s] END
Jan 17 06:42:04 kind-control-plane kubelet[607]: E0117 06:42:04.722487     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:42:05 kind-control-plane kubelet[607]: I0117 06:42:05.924754     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:42:06 kind-control-plane kubelet[607]: I0117 06:42:06.561471     607 trace.go:205] Trace[1158416207]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:41:55.316) (total time: 11244ms):
Jan 17 06:42:06 kind-control-plane kubelet[607]: Trace[1158416207]: [11.244621144s] [11.244621144s] END
Jan 17 06:42:06 kind-control-plane kubelet[607]: E0117 06:42:06.567204     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:08 kind-control-plane kubelet[607]: E0117 06:42:08.592346     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:09 kind-control-plane kubelet[607]: I0117 06:42:09.709517     607 trace.go:205] Trace[1862760334]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:41:32.914) (total time: 36795ms):
Jan 17 06:42:09 kind-control-plane kubelet[607]: Trace[1862760334]: [36.795183618s] [36.795183618s] END
Jan 17 06:42:09 kind-control-plane kubelet[607]: E0117 06:42:09.709576     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:42:09 kind-control-plane kubelet[607]: I0117 06:42:09.709684     607 trace.go:205] Trace[1870699897]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:41:36.794) (total time: 32914ms):
Jan 17 06:42:09 kind-control-plane kubelet[607]: Trace[1870699897]: [32.914749792s] [32.914749792s] END
Jan 17 06:42:09 kind-control-plane kubelet[607]: E0117 06:42:09.709693     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:42:11 kind-control-plane kubelet[607]: I0117 06:42:11.081239     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:42:11 kind-control-plane kubelet[607]: E0117 06:42:11.124574     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:42:15 kind-control-plane kubelet[607]: E0117 06:42:15.278585     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:16 kind-control-plane kubelet[607]: I0117 06:42:16.634602     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:16 kind-control-plane kubelet[607]: E0117 06:42:16.634928     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:18 kind-control-plane kubelet[607]: E0117 06:42:18.599701     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:55436->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:42:18 kind-control-plane kubelet[607]: E0117 06:42:18.600120     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:42:22 kind-control-plane kubelet[607]: I0117 06:42:22.678688     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:42:28 kind-control-plane kubelet[607]: E0117 06:42:28.763619     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:29 kind-control-plane kubelet[607]: I0117 06:42:29.326024     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:30 kind-control-plane kubelet[607]: E0117 06:42:30.631626     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:32 kind-control-plane kubelet[607]: E0117 06:42:32.348486     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:34 kind-control-plane kubelet[607]: W0117 06:42:34.537646     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e WatchSource:0}: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.601991     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.862443     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:56196->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.871938     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.871977     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:42:41 kind-control-plane kubelet[607]: E0117 06:42:41.510015     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:43 kind-control-plane kubelet[607]: I0117 06:42:43.847656     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:49 kind-control-plane kubelet[607]: E0117 06:42:49.518480     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:51 kind-control-plane kubelet[607]: I0117 06:42:51.902489     607 trace.go:205] Trace[1723405815]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:39.739) (total time: 11704ms):
Jan 17 06:42:51 kind-control-plane kubelet[607]: Trace[1723405815]: [11.70427325s] [11.70427325s] END
Jan 17 06:42:51 kind-control-plane kubelet[607]: E0117 06:42:51.902685     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:42:52 kind-control-plane kubelet[607]: I0117 06:42:52.385728     607 trace.go:205] Trace[2073638128]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:42:41.230) (total time: 11155ms):
Jan 17 06:42:52 kind-control-plane kubelet[607]: Trace[2073638128]: [11.155032999s] [11.155032999s] END
Jan 17 06:42:52 kind-control-plane kubelet[607]: E0117 06:42:52.385764     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:55 kind-control-plane kubelet[607]: I0117 06:42:55.463292     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": net/http: TLS handshake timeout"
Jan 17 06:42:56 kind-control-plane kubelet[607]: I0117 06:42:56.955528     607 trace.go:205] Trace[231251389]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:36.647) (total time: 20307ms):
Jan 17 06:42:56 kind-control-plane kubelet[607]: Trace[231251389]: [20.307614114s] [20.307614114s] END
Jan 17 06:42:56 kind-control-plane kubelet[607]: E0117 06:42:56.955609     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:58 kind-control-plane kubelet[607]: E0117 06:42:58.963439     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:43:00 kind-control-plane kubelet[607]: E0117 06:43:00.272830     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.211140     607 trace.go:205] Trace[985241519]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:39.824) (total time: 25386ms):
Jan 17 06:43:05 kind-control-plane kubelet[607]: Trace[985241519]: [25.386362091s] [25.386362091s] END
Jan 17 06:43:05 kind-control-plane kubelet[607]: E0117 06:43:05.211191     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.288158     607 trace.go:205] Trace[1933422461]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:42:35.169) (total time: 30118ms):
Jan 17 06:43:05 kind-control-plane kubelet[607]: Trace[1933422461]: [30.118327269s] [30.118327269s] END
Jan 17 06:43:05 kind-control-plane kubelet[607]: E0117 06:43:05.288181     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.848914     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:43:06 kind-control-plane kubelet[607]: E0117 06:43:06.571019     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: TLS handshake timeout
Jan 17 06:43:06 kind-control-plane kubelet[607]: I0117 06:43:06.892947     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:43:09 kind-control-plane kubelet[607]: E0117 06:43:09.842502     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:43:10 kind-control-plane kubelet[607]: I0117 06:43:10.282934     607 trace.go:205] Trace[1947214130]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:30.137) (total time: 40145ms):
Jan 17 06:43:10 kind-control-plane kubelet[607]: Trace[1947214130]: [40.145843334s] [40.145843334s] END
Jan 17 06:43:10 kind-control-plane kubelet[607]: E0117 06:43:10.282962     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:10 kind-control-plane kubelet[607]: I0117 06:43:10.297624     607 trace.go:205] Trace[189012397]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:42:32.173) (total time: 38124ms):
Jan 17 06:43:10 kind-control-plane kubelet[607]: Trace[189012397]: [38.124036981s] [38.124036981s] END
Jan 17 06:43:10 kind-control-plane kubelet[607]: E0117 06:43:10.297652     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:19 kind-control-plane kubelet[607]: E0117 06:43:19.847256     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:43:19 kind-control-plane kubelet[607]: E0117 06:43:19.879152     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:57864->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:43:23 kind-control-plane kubelet[607]: E0117 06:43:23.843453     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.388824     607 trace.go:205] Trace[603096479]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:43:03.494) (total time: 20889ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[603096479]: [20.889147122s] [20.889147122s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.388867     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.395520     607 trace.go:205] Trace[206747533]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:43:00.852) (total time: 23543ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[206747533]: [23.543211798s] [23.543211798s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.395553     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "local-path-config" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.395616     607 trace.go:205] Trace[326951103]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:43:06.421) (total time: 17973ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[326951103]: [17.97368279s] [17.97368279s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.395622     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object

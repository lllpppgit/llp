-- Journal begins at Tue 2023-01-17 03:45:46 UTC, ends at Tue 2023-01-17 06:43:28 UTC. --
Jan 17 03:45:46 kind-control-plane systemd-journald[180]: Journal started
Jan 17 03:45:46 kind-control-plane systemd-journald[180]: Runtime Journal (/run/log/journal/4c6e41f514f64a8797472a3a30262660) is 8.0M, max 197.5M, 189.5M free.
Jan 17 03:45:46 kind-control-plane systemd-sysusers[188]: Creating group systemd-coredump with gid 999.
Jan 17 03:45:46 kind-control-plane systemd-sysusers[188]: Creating user systemd-coredump (systemd Core Dumper) with uid 999 and gid 999.
Jan 17 03:45:46 kind-control-plane systemd-sysctl[185]: Not setting net/ipv4/conf/all/promote_secondaries (explicit setting exists).
Jan 17 03:45:46 kind-control-plane systemd-sysctl[185]: Not setting net/ipv4/conf/default/promote_secondaries (explicit setting exists).
Jan 17 03:45:46 kind-control-plane systemd-sysctl[185]: Couldn't write 'fq_codel' to 'net/core/default_qdisc', ignoring: No such file or directory
Jan 17 03:45:46 kind-control-plane systemd-sysctl[185]: Couldn't write '1' to 'fs/protected_fifos', ignoring: No such file or directory
Jan 17 03:45:46 kind-control-plane systemd-sysctl[185]: Couldn't write '2' to 'fs/protected_regular', ignoring: No such file or directory
Jan 17 03:45:46 kind-control-plane systemd-journald[180]: Runtime Journal (/run/log/journal/4c6e41f514f64a8797472a3a30262660) is 8.0M, max 197.5M, 189.5M free.
Jan 17 03:45:46 kind-control-plane systemd[1]: Starting Flush Journal to Persistent Storage...
Jan 17 03:45:47 kind-control-plane systemd[1]: Finished Create System Users.
Jan 17 03:45:48 kind-control-plane systemd[1]: Finished Flush Journal to Persistent Storage.
Jan 17 03:45:49 kind-control-plane systemd[1]: Starting Create Static Device Nodes in /dev...
Jan 17 03:45:50 kind-control-plane systemd[1]: Finished Create Static Device Nodes in /dev.
Jan 17 03:45:51 kind-control-plane systemd[1]: Reached target Local File Systems (Pre).
Jan 17 03:45:52 kind-control-plane systemd[1]: Reached target Local File Systems.
Jan 17 03:45:53 kind-control-plane systemd[1]: Condition check resulted in Store a System Token in an EFI Variable being skipped.
Jan 17 03:45:53 kind-control-plane systemd[1]: Condition check resulted in Commit a transient machine-id on disk being skipped.
Jan 17 03:45:53 kind-control-plane systemd[1]: Condition check resulted in Rule-based Manager for Device Events and Files being skipped.
Jan 17 03:45:53 kind-control-plane systemd[1]: Reached target System Initialization.
Jan 17 03:45:54 kind-control-plane systemd[1]: Started Daily Cleanup of Temporary Directories.
Jan 17 03:45:55 kind-control-plane systemd[1]: Reached target Basic System.
Jan 17 03:45:56 kind-control-plane systemd[1]: Reached target Timers.
Jan 17 03:45:57 kind-control-plane systemd[1]: Starting containerd container runtime...
Jan 17 03:45:58 kind-control-plane systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Jan 17 03:45:58 kind-control-plane systemd[1]: Started containerd container runtime.
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.044936635Z" level=info msg="starting containerd" revision=36cc874494a56a253cd181a1a685b44b58a2e34a version=v1.5.2
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.067818123Z" level=info msg="loading plugin \"io.containerd.content.v1.content\"..." type=io.containerd.content.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.067971384Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.aufs\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.068805830Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.aufs\"..." error="aufs is not supported (modprobe aufs failed: exit status 1 \"modprobe: FATAL: Module aufs not found in directory /lib/modules/3.10.0-1160.el7.x86_64\\n\"): skip plugin" type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.068828897Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069499956Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.btrfs (xfs) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069578149Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.devmapper\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069646629Z" level=warning msg="failed to load plugin io.containerd.snapshotter.v1.devmapper" error="devmapper not configured"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069696690Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.native\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069749464Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.overlayfs\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.069855089Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.zfs\"..." type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070056049Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.zfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070090911Z" level=info msg="loading plugin \"io.containerd.metadata.v1.bolt\"..." type=io.containerd.metadata.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070103804Z" level=warning msg="could not use snapshotter devmapper in metadata plugin" error="devmapper not configured"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070109408Z" level=info msg="metadata content store policy set" policy=shared
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070169770Z" level=info msg="loading plugin \"io.containerd.differ.v1.walking\"..." type=io.containerd.differ.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070179139Z" level=info msg="loading plugin \"io.containerd.gc.v1.scheduler\"..." type=io.containerd.gc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070206923Z" level=info msg="loading plugin \"io.containerd.service.v1.introspection-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070225978Z" level=info msg="loading plugin \"io.containerd.service.v1.containers-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070232916Z" level=info msg="loading plugin \"io.containerd.service.v1.content-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070239393Z" level=info msg="loading plugin \"io.containerd.service.v1.diff-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070251036Z" level=info msg="loading plugin \"io.containerd.service.v1.images-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070259338Z" level=info msg="loading plugin \"io.containerd.service.v1.leases-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070267570Z" level=info msg="loading plugin \"io.containerd.service.v1.namespaces-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070274497Z" level=info msg="loading plugin \"io.containerd.service.v1.snapshots-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070280473Z" level=info msg="loading plugin \"io.containerd.runtime.v1.linux\"..." type=io.containerd.runtime.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070308941Z" level=info msg="loading plugin \"io.containerd.runtime.v2.task\"..." type=io.containerd.runtime.v2
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070340058Z" level=info msg="loading plugin \"io.containerd.monitor.v1.cgroups\"..." type=io.containerd.monitor.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070571730Z" level=info msg="loading plugin \"io.containerd.service.v1.tasks-service\"..." type=io.containerd.service.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070586759Z" level=info msg="loading plugin \"io.containerd.internal.v1.restart\"..." type=io.containerd.internal.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070619351Z" level=info msg="loading plugin \"io.containerd.grpc.v1.containers\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070628189Z" level=info msg="loading plugin \"io.containerd.grpc.v1.content\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070640172Z" level=info msg="loading plugin \"io.containerd.grpc.v1.diff\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070647069Z" level=info msg="loading plugin \"io.containerd.grpc.v1.events\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651200Z" level=info msg="loading plugin \"io.containerd.grpc.v1.healthcheck\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651246Z" level=info msg="loading plugin \"io.containerd.grpc.v1.images\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651292Z" level=info msg="loading plugin \"io.containerd.grpc.v1.leases\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651337Z" level=info msg="loading plugin \"io.containerd.grpc.v1.namespaces\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651383Z" level=info msg="loading plugin \"io.containerd.internal.v1.opt\"..." type=io.containerd.internal.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651429Z" level=info msg="loading plugin \"io.containerd.grpc.v1.snapshots\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651474Z" level=info msg="loading plugin \"io.containerd.grpc.v1.tasks\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651520Z" level=info msg="loading plugin \"io.containerd.grpc.v1.version\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651566Z" level=info msg="loading plugin \"io.containerd.grpc.v1.cri\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651611Z" level=info msg="Start cri plugin with config {PluginConfig:{ContainerdConfig:{Snapshotter:overlayfs DefaultRuntimeName:runc DefaultRuntime:{Type: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:} UntrustedWorkloadRuntime:{Type: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:} Runtimes:map[runc:{Type:io.containerd.runc.v2 Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:} test-handler:{Type:io.containerd.runc.v2 Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:}] NoPivot:false DisableSnapshotAnnotations:true DiscardUnpackedLayers:true} CniConfig:{NetworkPluginBinDir:/opt/cni/bin NetworkPluginConfDir:/etc/cni/net.d NetworkPluginMaxConfNum:1 NetworkPluginConfTemplate:} Registry:{ConfigPath: Mirrors:map[] Configs:map[] Auths:map[] Headers:map[]} ImageDecryption:{KeyModel:node} DisableTCPService:true StreamServerAddress:127.0.0.1 StreamServerPort:0 StreamIdleTimeout:4h0m0s EnableSelinux:false SelinuxCategoryRange:1024 SandboxImage:k8s.gcr.io/pause:3.5 StatsCollectPeriod:10 SystemdCgroup:false EnableTLSStreaming:false X509KeyPairStreaming:{TLSCertFile: TLSKeyFile:} MaxContainerLogLineSize:16384 DisableCgroup:false DisableApparmor:false RestrictOOMScoreAdj:false MaxConcurrentDownloads:3 DisableProcMount:false UnsetSeccompProfile: TolerateMissingHugetlbController:true DisableHugetlbController:true IgnoreImageDefinedVolumes:false NetNSMountsUnderStateDir:false} ContainerdRootDir:/var/lib/containerd ContainerdEndpoint:/run/containerd/containerd.sock RootDir:/var/lib/containerd/io.containerd.grpc.v1.cri StateDir:/run/containerd/io.containerd.grpc.v1.cri}"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651703Z" level=info msg="Connect containerd service"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070651748Z" level=info msg="Get image filesystem path \"/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs\""
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070883819Z" level=error msg="failed to load cni during init, please check CRI plugin status before setting up network for pods" error="cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.070901034Z" level=info msg="loading plugin \"io.containerd.grpc.v1.introspection\"..." type=io.containerd.grpc.v1
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.071011119Z" level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.071028622Z" level=info msg=serving... address=/run/containerd/containerd.sock
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.071035618Z" level=info msg="containerd successfully booted in 0.026598s"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.077458429Z" level=info msg="Start subscribing containerd event"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.077495666Z" level=info msg="Start recovering state"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.078054054Z" level=warning msg="The image docker.io/kindest/kindnetd:v20210326-1e038dc5 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.078361500Z" level=warning msg="The image docker.io/rancher/local-path-provisioner:v0.0.14 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.079004959Z" level=warning msg="The image k8s.gcr.io/build-image/debian-base:v2.1.0 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.079321832Z" level=warning msg="The image k8s.gcr.io/coredns/coredns:v1.8.0 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.083352338Z" level=warning msg="The image k8s.gcr.io/etcd:3.4.13-0 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.083846812Z" level=warning msg="The image k8s.gcr.io/kube-apiserver:v1.21.1 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.084108393Z" level=warning msg="The image k8s.gcr.io/kube-controller-manager:v1.21.1 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.084379083Z" level=warning msg="The image k8s.gcr.io/kube-proxy:v1.21.1 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.084857328Z" level=warning msg="The image k8s.gcr.io/kube-scheduler:v1.21.1 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.085415445Z" level=warning msg="The image k8s.gcr.io/pause:3.5 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.086399316Z" level=warning msg="The image sha256:0369cf4303ffdb467dc219990960a9baa8512a54b0ad9283eaf55bd6c0adb934 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.087100717Z" level=warning msg="The image sha256:0e124fb3c695bdbf30fe3328ef81e268a7f884f670e67c016f5e45c2058b2538 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.087414276Z" level=warning msg="The image sha256:1248d2d503d37429342d5e994559f8559f35d80a31b224d4db5324816fff7206 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.087671547Z" level=warning msg="The image sha256:296a6d5035e2d6919249e02709a488d680ddca91357602bd65e605eac967b899 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.088497794Z" level=warning msg="The image sha256:6de166512aa223315ff9cfd49bd4f13aab1591cd8fc57e31270f0e4aa34129cb is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.088842439Z" level=warning msg="The image sha256:94ffe308aeff9fd5602df5fe8bea97dc5b3efe3c53532bb2b0edf26c72d140e3 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.089189263Z" level=warning msg="The image sha256:96a295389d472f96d58764c2ed3e7418d0183f707765c21e6f310c2e163225a9 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.089431272Z" level=warning msg="The image sha256:c7c6c86897b63067b540640b3b47ba46e0587542fc6511eef3bd1f833e1319e1 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.090011707Z" level=warning msg="The image sha256:e422121c9c5f97623245b7e600eeb5e223ee623f21fa04da985ae71057d8d70b is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.092054391Z" level=warning msg="The image sha256:ed210e3e4a5bae1237f1bb44d72a05a2f1e5c6bfe7a7e73da179e2534269c459 is not unpacked."
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.093287663Z" level=info msg="Start event monitor"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.093300992Z" level=info msg="Start snapshots syncer"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.093307197Z" level=info msg="Start cni network conf syncer"
Jan 17 03:45:59 kind-control-plane containerd[197]: time="2023-01-17T03:45:59.093313312Z" level=info msg="Start streaming server"
Jan 17 03:45:59 kind-control-plane systemd[1]: Reached target Multi-User System.
Jan 17 03:46:00 kind-control-plane systemd[1]: Reached target Graphical Interface.
Jan 17 03:46:01 kind-control-plane systemd[1]: Starting Update UTMP about System Runlevel Changes...
Jan 17 03:46:03 kind-control-plane systemd[1]: systemd-update-utmp-runlevel.service: Succeeded.
Jan 17 03:46:03 kind-control-plane systemd[1]: Finished Update UTMP about System Runlevel Changes.
Jan 17 03:46:04 kind-control-plane systemd[1]: Startup finished in 17.508s.
Jan 17 03:46:04 kind-control-plane systemd[1]: Reloading.
Jan 17 03:46:04 kind-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Jan 17 03:46:04 kind-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.229571     226 server.go:197] "Warning: For remote container runtime, --pod-infra-container-image is ignored in kubelet, which should be set in that remote runtime instead"
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane kubelet[226]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:04 kind-control-plane systemd[1]: Started Kubernetes systemd probe.
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.940776     226 server.go:440] "Kubelet version" kubeletVersion="v1.21.1"
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.940907     226 server.go:851] "Client rotation is on, will bootstrap in background"
Jan 17 03:46:04 kind-control-plane kubelet[226]: I0117 03:46:04.950662     226 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:04 kind-control-plane kubelet[226]: E0117 03:46:04.950756     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:07 kind-control-plane kubelet[226]: E0117 03:46:07.111472     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955326     226 container_manager_linux.go:278] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955436     226 container_manager_linux.go:283] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955475     226 topology_manager.go:120] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955492     226 container_manager_linux.go:314] "Initializing Topology Manager" policy="none" scope="container"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955505     226 container_manager_linux.go:319] "Creating device plugin manager" devicePluginEnabled=true
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955783     226 remote_runtime.go:62] parsed scheme: ""
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955802     226 remote_runtime.go:62] scheme "" not registered, fallback to default scheme
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955875     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.955896     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958223     226 remote_image.go:50] parsed scheme: ""
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958260     226 remote_image.go:50] scheme "" not registered, fallback to default scheme
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958290     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958304     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958433     226 kubelet.go:404] "Attempting to sync node with API server"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958464     226 kubelet.go:272] "Adding static pod path" path="/etc/kubernetes/manifests"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958517     226 kubelet.go:283] "Adding apiserver pod source"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.958552     226 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.959231     226 clientconn.go:897] blockingPicker: the picked transport is not ready, loop back to repick
Jan 17 03:46:09 kind-control-plane kubelet[226]: E0117 03:46:09.986142     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:09 kind-control-plane kubelet[226]: I0117 03:46:09.991700     226 kuberuntime_manager.go:222] "Container runtime initialized" containerRuntime="containerd" version="v1.5.2" apiVersion="v1alpha2"
Jan 17 03:46:09 kind-control-plane kubelet[226]: E0117 03:46:09.992585     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.262547     226 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.
Jan 17 03:46:10 kind-control-plane kubelet[226]:         For verbose messaging see aws.Config.CredentialsChainVerboseErrors
Jan 17 03:46:10 kind-control-plane kubelet[226]: W0117 03:46:10.262922     226 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.263925     226 server.go:1190] "Started kubelet"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.268526     226 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.277011     226 server.go:149] "Starting to listen" address="0.0.0.0" port=10250
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.278412     226 server.go:405] "Adding debug handlers to kubelet server"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.283743     226 volume_manager.go:271] "Starting Kubelet Volume Manager"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.287252     226 desired_state_of_world_populator.go:141] "Desired state populator starts to run"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299364     226 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe47b740c2d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299496     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.299530     226 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.305805     226 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv4
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322576     226 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv6
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322599     226 status_manager.go:157] "Starting to sync pod status with apiserver"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.322710     226 kubelet.go:1846] "Starting kubelet main sync loop"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.322910     226 kubelet.go:1870] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.325331     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325455     226 client.go:86] parsed scheme: "unix"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325460     226 client.go:86] scheme "unix" not registered, fallback to default scheme
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325472     226 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.325476     226 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.325594     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.389723     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.390461     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.390931     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392669     226 cpu_manager.go:199] "Starting CPU manager" policy="none"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392676     226 cpu_manager.go:200] "Reconciling" reconcilePeriod="10s"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.392689     226 state_mem.go:36] "Initialized new in-memory state store"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.396645     226 policy_none.go:44] "None policy: Start"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.400248     226 manager.go:600] "Failed to retrieve checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.400362     226 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.402219     226 eviction_manager.go:255] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.424435     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.426443     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.429460     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.437594     226 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.438254     226 status_manager.go:566] "Failed to get status for pod" podUID=24ba8551bcc724a32d591bb02c423d92 pod="kube-system/etcd-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/etcd-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.444270     226 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.449464     226 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.455506     226 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489582     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-ca-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-local-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/69dd939498054a211c3461b2a9cc8d26-kubeconfig\") pod \"kube-scheduler-kind-control-plane\" (UID: \"69dd939498054a211c3461b2a9cc8d26\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-flexvolume-dir\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-ca-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-k8s-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489583     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-etc-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489588     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-local-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489619     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489643     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-k8s-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489686     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-certs\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489707     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-data\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489728     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-etc-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.489752     226 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-kubeconfig\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.489777     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.501658     226 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.590691     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: I0117 03:46:10.593999     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.595606     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.691215     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane containerd[197]: time="2023-01-17T03:46:10.736019760Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:etcd-kind-control-plane,Uid:24ba8551bcc724a32d591bb02c423d92,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:10 kind-control-plane containerd[197]: time="2023-01-17T03:46:10.742242317Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:kube-apiserver-kind-control-plane,Uid:bd1c21fe1f0ef615e0b5e41299f1be61,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:10 kind-control-plane containerd[197]: time="2023-01-17T03:46:10.748772374Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:kube-controller-manager-kind-control-plane,Uid:46dac9a538838115821dfd9559149484,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:10 kind-control-plane containerd[197]: time="2023-01-17T03:46:10.765488492Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:kube-scheduler-kind-control-plane,Uid:69dd939498054a211c3461b2a9cc8d26,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.793022     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount342476718.mount: Succeeded.
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.852132     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount373414082.mount: Succeeded.
Jan 17 03:46:10 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount065561924.mount: Succeeded.
Jan 17 03:46:10 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount306570041.mount: Succeeded.
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.895477     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:10 kind-control-plane kubelet[226]: E0117 03:46:10.906559     226 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:10 kind-control-plane containerd[197]: time="2023-01-17T03:46:10.919228099Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/d474410f89b8f97ae59e293ccecbd5c9a645c81d923e25b37dc5aaada73fa2fc pid=305
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.000626     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: I0117 03:46:11.013012     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.013298     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.030782502Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5 pid=331
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.043330356Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0 pid=348
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.062965648Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:etcd-kind-control-plane,Uid:24ba8551bcc724a32d591bb02c423d92,Namespace:kube-system,Attempt:0,} returns sandbox id \"d474410f89b8f97ae59e293ccecbd5c9a645c81d923e25b37dc5aaada73fa2fc\""
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.070793502Z" level=info msg="CreateContainer within sandbox \"d474410f89b8f97ae59e293ccecbd5c9a645c81d923e25b37dc5aaada73fa2fc\" for container &ContainerMetadata{Name:etcd,Attempt:0,}"
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.073124039Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f pid=358
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.117660     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.176438     226 certificate_manager.go:437] Failed while requesting a signed certificate from the master: cannot create certificate signing request: Post "https://kind-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.202873758Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-controller-manager-kind-control-plane,Uid:46dac9a538838115821dfd9559149484,Namespace:kube-system,Attempt:0,} returns sandbox id \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\""
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.215074734Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:0,}"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.218481     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.292742746Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-scheduler-kind-control-plane,Uid:69dd939498054a211c3461b2a9cc8d26,Namespace:kube-system,Attempt:0,} returns sandbox id \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\""
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.320917     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.345236     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.363403     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.379304594Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-apiserver-kind-control-plane,Uid:bd1c21fe1f0ef615e0b5e41299f1be61,Namespace:kube-system,Attempt:0,} returns sandbox id \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\""
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.421098     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount221825025.mount: Succeeded.
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.488965668Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:0,}"
Jan 17 03:46:11 kind-control-plane containerd[197]: time="2023-01-17T03:46:11.512435141Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for container &ContainerMetadata{Name:kube-apiserver,Attempt:0,}"
Jan 17 03:46:11 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount928489342.mount: Succeeded.
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.524061     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.624918     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.712418     226 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.726745     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.827634     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:11 kind-control-plane kubelet[226]: I0117 03:46:11.865135     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.865514     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.923472     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:11 kind-control-plane kubelet[226]: E0117 03:46:11.930032     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.034605     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.137785     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.238924     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.340370     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.441264     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.543314     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.645352     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.747372     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.849592     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:12 kind-control-plane kubelet[226]: E0117 03:46:12.956957     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.057032     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.157402     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.259120     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.314295     226 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.349441     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.356614     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.360296     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.462252     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.473048469Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:0,} returns container id \"f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3\""
Jan 17 03:46:13 kind-control-plane kubelet[226]: I0117 03:46:13.513234     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.513378     226 kubelet_node_status.go:93] "Unable to register node with API server" err="Post \"https://kind-control-plane:6443/api/v1/nodes\": dial tcp 172.18.0.2:6443: connect: connection refused" node="kind-control-plane"
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.529903661Z" level=info msg="StartContainer for \"f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3\""
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.562459     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.663724     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.764662     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.822509731Z" level=info msg="StartContainer for \"f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3\" returns successfully"
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.866073     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.923141431Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:0,} returns container id \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\""
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.935276668Z" level=info msg="StartContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\""
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.946472204Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for &ContainerMetadata{Name:kube-apiserver,Attempt:0,} returns container id \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\""
Jan 17 03:46:13 kind-control-plane containerd[197]: time="2023-01-17T03:46:13.952902474Z" level=info msg="StartContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\""
Jan 17 03:46:13 kind-control-plane kubelet[226]: E0117 03:46:13.969181     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.071735     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.102309     226 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&limit=500&resourceVersion=0": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 03:46:14 kind-control-plane kubelet[226]: I0117 03:46:14.139790     226 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.175809     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.277366     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane containerd[197]: time="2023-01-17T03:46:14.299032921Z" level=info msg="StartContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\" returns successfully"
Jan 17 03:46:14 kind-control-plane containerd[197]: time="2023-01-17T03:46:14.321635098Z" level=info msg="StartContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\" returns successfully"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.386007     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.488180     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.595182     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.701199     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.806812     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:14 kind-control-plane kubelet[226]: E0117 03:46:14.910211     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.013362     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.117029     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.220087     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.322958     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.424189     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.424243     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.528387     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.628701     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.738897     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.845800     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:15 kind-control-plane kubelet[226]: E0117 03:46:15.946122     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.049325     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.158227     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.264074     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.372807     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.476746     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.581144     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.683026     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: I0117 03:46:16.725422     226 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.792186     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.896114     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:16 kind-control-plane kubelet[226]: E0117 03:46:16.999121     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.102193     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.207240     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.308211     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.410020     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.513705     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.617161     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.719737     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.819980     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:17 kind-control-plane kubelet[226]: E0117 03:46:17.920943     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.023937     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.124838     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.226505     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.327203     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount505664289.mount: Succeeded.
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.428231     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.529196     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.629478     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.731571     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount368120844.mount: Succeeded.
Jan 17 03:46:18 kind-control-plane containerd[197]: time="2023-01-17T03:46:18.812633252Z" level=info msg="CreateContainer within sandbox \"d474410f89b8f97ae59e293ccecbd5c9a645c81d923e25b37dc5aaada73fa2fc\" for &ContainerMetadata{Name:etcd,Attempt:0,} returns container id \"295e0347b9e8dcb18f05eeb5043812f89367e7cc8da7ead5406a491872cd2c6f\""
Jan 17 03:46:18 kind-control-plane containerd[197]: time="2023-01-17T03:46:18.813417553Z" level=info msg="StartContainer for \"295e0347b9e8dcb18f05eeb5043812f89367e7cc8da7ead5406a491872cd2c6f\""
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.835125     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:18 kind-control-plane containerd[197]: time="2023-01-17T03:46:18.867390256Z" level=info msg="StartContainer for \"295e0347b9e8dcb18f05eeb5043812f89367e7cc8da7ead5406a491872cd2c6f\" returns successfully"
Jan 17 03:46:18 kind-control-plane kubelet[226]: E0117 03:46:18.937229     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.039037     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.139732     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.241101     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.342259     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.443206     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.545072     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.647026     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.748233     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.849142     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:19 kind-control-plane kubelet[226]: E0117 03:46:19.950199     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.051711     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.154844     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.256157     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.358174     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.404008     226 eviction_manager.go:255] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.427426     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.461219     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.563911     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.665153     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.766907     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.870113     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:20 kind-control-plane kubelet[226]: E0117 03:46:20.972612     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.076853     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.180623     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.283616     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.383779     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.485194     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.587662     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.693170     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.798867     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:21 kind-control-plane kubelet[226]: E0117 03:46:21.900324     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.005207     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.106338     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.208119     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.309862     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.410990     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.512639     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.614580     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.716613     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.818203     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:22 kind-control-plane kubelet[226]: E0117 03:46:22.919133     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.024041     226 apiserver.go:52] "Watching apiserver"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.024226     226 kubelet.go:2291] "Error getting node" err="node \"kind-control-plane\" not found"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.080518     226 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"kind-control-plane\" not found" node="kind-control-plane"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.108389     226 kubelet_node_status.go:74] "Successfully registered node" node="kind-control-plane"
Jan 17 03:46:23 kind-control-plane kubelet[226]: I0117 03:46:23.124324     226 reconciler.go:157] "Reconciler: start to sync state"
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.160319     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe47b740c2d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4608fba782d, ext:6097766538, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.225296     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.293060     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.346222     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff38ca", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.401306     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762a24c, ext:6226227818, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.459070     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762ab32, ext:6226230090, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.522050     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff38ca", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609745a4ca, ext:6224327906, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609762b037, ext:6226231375, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.578801     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe48398db7a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097df477a, ext:6234396562, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097df477a, ext:6234396562, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:23 kind-control-plane kubelet[226]: E0117 03:46:23.640436     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff2790", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459390, ext:6224323502, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609967fc4e, ext:6260133028, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:24 kind-control-plane kubelet[226]: E0117 03:46:24.024310     226 event.go:264] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-control-plane.173afbe482ff32a3", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-control-plane", UID:"kind-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a46097459ea3, ext:6224326330, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9a4609968234f, ext:6260143023, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Jan 17 03:46:25 kind-control-plane kubelet[226]: E0117 03:46:25.428793     226 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:25 kind-control-plane systemd[1]: Reloading.
Jan 17 03:46:26 kind-control-plane systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Jan 17 03:46:26 kind-control-plane kubelet[226]: I0117 03:46:26.025044     226 dynamic_cafile_content.go:182] Shutting down client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:26 kind-control-plane systemd[1]: kubelet.service: Succeeded.
Jan 17 03:46:26 kind-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jan 17 03:46:26 kind-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Jan 17 03:46:26 kind-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.170827     607 server.go:197] "Warning: For remote container runtime, --pod-infra-container-image is ignored in kubelet, which should be set in that remote runtime instead"
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane kubelet[607]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Jan 17 03:46:26 kind-control-plane systemd[1]: Started Kubernetes systemd probe.
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.197414     607 server.go:440] "Kubelet version" kubeletVersion="v1.21.1"
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.197435     607 server.go:851] "Client rotation is on, will bootstrap in background"
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.201318     607 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Jan 17 03:46:26 kind-control-plane kubelet[607]: I0117 03:46:26.203080     607 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.213627     607 container_manager_linux.go:278] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220579     607 container_manager_linux.go:283] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220660     607 topology_manager.go:120] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220674     607 container_manager_linux.go:314] "Initializing Topology Manager" policy="none" scope="container"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220682     607 container_manager_linux.go:319] "Creating device plugin manager" devicePluginEnabled=true
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220850     607 remote_runtime.go:62] parsed scheme: ""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.220861     607 remote_runtime.go:62] scheme "" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.224218     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.224218     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225170     607 remote_image.go:50] parsed scheme: ""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225182     607 remote_image.go:50] scheme "" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225216     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225443     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225539     607 kubelet.go:404] "Attempting to sync node with API server"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225587     607 kubelet.go:272] "Adding static pod path" path="/etc/kubernetes/manifests"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225624     607 kubelet.go:283] "Adding apiserver pod source"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.225646     607 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.256055     607 kuberuntime_manager.go:222] "Container runtime initialized" containerRuntime="containerd" version="v1.5.2" apiVersion="v1alpha2"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.521808     607 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.
Jan 17 03:46:31 kind-control-plane kubelet[607]:         For verbose messaging see aws.Config.CredentialsChainVerboseErrors
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.522675     607 server.go:1190] "Started kubelet"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.532711     607 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.534954     607 server.go:149] "Starting to listen" address="0.0.0.0" port=10250
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.536565     607 server.go:405] "Adding debug handlers to kubelet server"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.550137     607 volume_manager.go:271] "Starting Kubelet Volume Manager"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.554276     607 desired_state_of_world_populator.go:141] "Desired state populator starts to run"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.579851     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582532     607 client.go:86] parsed scheme: "unix"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582548     607 client.go:86] scheme "unix" not registered, fallback to default scheme
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582569     607 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.582577     607 clientconn.go:948] ClientConn switching balancer to "pick_first"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.622980     607 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv4
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633668     607 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv6
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633691     607 status_manager.go:157] "Starting to sync pod status with apiserver"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.633702     607 kubelet.go:1846] "Starting kubelet main sync loop"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.633728     607 kubelet.go:1870] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.656750     607 kubelet_node_status.go:71] "Attempting to register node" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.684330     607 kubelet_node_status.go:109] "Node was previously registered" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.687789     607 kubelet_node_status.go:74] "Successfully registered node" node="kind-control-plane"
Jan 17 03:46:31 kind-control-plane kubelet[607]: E0117 03:46:31.744889     607 kubelet.go:1870] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748594     607 cpu_manager.go:199] "Starting CPU manager" policy="none"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748604     607 cpu_manager.go:200] "Reconciling" reconcilePeriod="10s"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.748605     607 state_mem.go:36] "Initialized new in-memory state store"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750067     607 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750111     607 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750118     607 policy_none.go:44] "None policy: Start"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750752     607 manager.go:600] "Failed to retrieve checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.750939     607 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.946962     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947158     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947223     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.947306     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967457     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-flexvolume-dir\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967517     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-k8s-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967559     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-local-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967596     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-usr-share-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967634     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/69dd939498054a211c3461b2a9cc8d26-kubeconfig\") pod \"kube-scheduler-kind-control-plane\" (UID: \"69dd939498054a211c3461b2a9cc8d26\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967744     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-data\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967792     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-ca-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967825     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-k8s-certs\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967866     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-etc-ca-certificates\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967900     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/24ba8551bcc724a32d591bb02c423d92-etcd-certs\") pod \"etcd-kind-control-plane\" (UID: \"24ba8551bcc724a32d591bb02c423d92\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967938     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-ca-certs\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.967974     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968008     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/46dac9a538838115821dfd9559149484-kubeconfig\") pod \"kube-controller-manager-kind-control-plane\" (UID: \"46dac9a538838115821dfd9559149484\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968040     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-etc-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:31 kind-control-plane kubelet[607]: I0117 03:46:31.968040     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bd1c21fe1f0ef615e0b5e41299f1be61-usr-local-share-ca-certificates\") pod \"kube-apiserver-kind-control-plane\" (UID: \"bd1c21fe1f0ef615e0b5e41299f1be61\") "
Jan 17 03:46:32 kind-control-plane kubelet[607]: E0117 03:46:32.022425     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"etcd-kind-control-plane\" already exists" pod="kube-system/etcd-kind-control-plane"
Jan 17 03:46:32 kind-control-plane kubelet[607]: I0117 03:46:32.228019     607 apiserver.go:52] "Watching apiserver"
Jan 17 03:46:32 kind-control-plane kubelet[607]: I0117 03:46:32.473339     607 reconciler.go:157] "Reconciler: start to sync state"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.034040     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"etcd-kind-control-plane\" already exists" pod="kube-system/etcd-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.242086     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-kind-control-plane\" already exists" pod="kube-system/kube-controller-manager-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.447593     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-apiserver-kind-control-plane\" already exists" pod="kube-system/kube-apiserver-kind-control-plane"
Jan 17 03:46:33 kind-control-plane kubelet[607]: E0117 03:46:33.654737     607 kubelet.go:1683] "Failed creating a mirror pod for" err="pods \"kube-scheduler-kind-control-plane\" already exists" pod="kube-system/kube-scheduler-kind-control-plane"
Jan 17 03:46:36 kind-control-plane kubelet[607]: E0117 03:46:36.751549     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:39 kind-control-plane kubelet[607]: I0117 03:46:39.936175     607 kuberuntime_manager.go:1044] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Jan 17 03:46:39 kind-control-plane containerd[197]: time="2023-01-17T03:46:39.936877158Z" level=info msg="No cni config template is specified, wait for other system components to drop the config."
Jan 17 03:46:39 kind-control-plane kubelet[607]: I0117 03:46:39.937214     607 kubelet_network.go:76] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Jan 17 03:46:39 kind-control-plane kubelet[607]: E0117 03:46:39.937409     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.124530     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.134671     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159400     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-lib-modules\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159449     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/69596075-e3a8-43fd-9a62-69a0aa833fb6-kube-proxy\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159509     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/69596075-e3a8-43fd-9a62-69a0aa833fb6-lib-modules\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159539     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-xtables-lock\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159570     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/e5ced440-70ff-4944-9756-a3d368c86a5d-cni-cfg\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159608     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6qp9j\" (UniqueName: \"kubernetes.io/projected/e5ced440-70ff-4944-9756-a3d368c86a5d-kube-api-access-6qp9j\") pod \"kindnet-msl5l\" (UID: \"e5ced440-70ff-4944-9756-a3d368c86a5d\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159642     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/69596075-e3a8-43fd-9a62-69a0aa833fb6-xtables-lock\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane kubelet[607]: I0117 03:46:40.159673     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pfvbz\" (UniqueName: \"kubernetes.io/projected/69596075-e3a8-43fd-9a62-69a0aa833fb6-kube-api-access-pfvbz\") pod \"kube-proxy-f6kw6\" (UID: \"69596075-e3a8-43fd-9a62-69a0aa833fb6\") "
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.426635257Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:kindnet-msl5l,Uid:e5ced440-70ff-4944-9756-a3d368c86a5d,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.437553113Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:kube-proxy-f6kw6,Uid:69596075-e3a8-43fd-9a62-69a0aa833fb6,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.482606342Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef pid=703
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.489359125Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/e25dbd89b5707a602e53fc4c704558acac24cf9b0b95b9ff6d158cae96e25b8b pid=713
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.674290985Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-f6kw6,Uid:69596075-e3a8-43fd-9a62-69a0aa833fb6,Namespace:kube-system,Attempt:0,} returns sandbox id \"e25dbd89b5707a602e53fc4c704558acac24cf9b0b95b9ff6d158cae96e25b8b\""
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.676615397Z" level=info msg="CreateContainer within sandbox \"e25dbd89b5707a602e53fc4c704558acac24cf9b0b95b9ff6d158cae96e25b8b\" for container &ContainerMetadata{Name:kube-proxy,Attempt:0,}"
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.688832985Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kindnet-msl5l,Uid:e5ced440-70ff-4944-9756-a3d368c86a5d,Namespace:kube-system,Attempt:0,} returns sandbox id \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\""
Jan 17 03:46:40 kind-control-plane containerd[197]: time="2023-01-17T03:46:40.693122257Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:0,}"
Jan 17 03:46:41 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount334086403.mount: Succeeded.
Jan 17 03:46:41 kind-control-plane kubelet[607]: E0117 03:46:41.809585     607 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Jan 17 03:46:42 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount206775430.mount: Succeeded.
Jan 17 03:46:43 kind-control-plane containerd[197]: time="2023-01-17T03:46:43.061964758Z" level=info msg="CreateContainer within sandbox \"e25dbd89b5707a602e53fc4c704558acac24cf9b0b95b9ff6d158cae96e25b8b\" for &ContainerMetadata{Name:kube-proxy,Attempt:0,} returns container id \"77f5d3de8d9330e072945ae8c8e6677199b7b463a47939244b4bb9404c044f43\""
Jan 17 03:46:43 kind-control-plane containerd[197]: time="2023-01-17T03:46:43.067150238Z" level=info msg="StartContainer for \"77f5d3de8d9330e072945ae8c8e6677199b7b463a47939244b4bb9404c044f43\""
Jan 17 03:46:43 kind-control-plane containerd[197]: time="2023-01-17T03:46:43.223537497Z" level=info msg="StartContainer for \"77f5d3de8d9330e072945ae8c8e6677199b7b463a47939244b4bb9404c044f43\" returns successfully"
Jan 17 03:46:44 kind-control-plane containerd[197]: time="2023-01-17T03:46:44.349665114Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for &ContainerMetadata{Name:kindnet-cni,Attempt:0,} returns container id \"faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c\""
Jan 17 03:46:44 kind-control-plane containerd[197]: time="2023-01-17T03:46:44.350528466Z" level=info msg="StartContainer for \"faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c\""
Jan 17 03:46:44 kind-control-plane containerd[197]: time="2023-01-17T03:46:44.395567711Z" level=info msg="StartContainer for \"faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c\" returns successfully"
Jan 17 03:46:44 kind-control-plane containerd[197]: time="2023-01-17T03:46:44.782467640Z" level=error msg="failed to reload cni configuration after receiving fs change event(\"/etc/cni/net.d/10-kindnet.conflist.temp\": WRITE)" error="cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.780370     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: E0117 03:46:55.796608     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "local-path-config" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 03:46:55 kind-control-plane kubelet[607]: E0117 03:46:55.796669     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.814896     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.818441     607 topology_manager.go:187] "Topology Admit Handler"
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841950     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841982     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ptnnn\" (UniqueName: \"kubernetes.io/projected/41df3d8b-173f-407c-91cc-5b0da8567827-kube-api-access-ptnnn\") pod \"coredns-558bd4d5db-tsnk8\" (UID: \"41df3d8b-173f-407c-91cc-5b0da8567827\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.841994     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/8ce1e50d-5699-49de-9a31-edc180d85ebe-config-volume\") pod \"coredns-558bd4d5db-7kcfd\" (UID: \"8ce1e50d-5699-49de-9a31-edc180d85ebe\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842004     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-rcffp\" (UniqueName: \"kubernetes.io/projected/8ce1e50d-5699-49de-9a31-edc180d85ebe-kube-api-access-rcffp\") pod \"coredns-558bd4d5db-7kcfd\" (UID: \"8ce1e50d-5699-49de-9a31-edc180d85ebe\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842015     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qctc9\" (UniqueName: \"kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") "
Jan 17 03:46:55 kind-control-plane kubelet[607]: I0117 03:46:55.842025     607 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/41df3d8b-173f-407c-91cc-5b0da8567827-config-volume\") pod \"coredns-558bd4d5db-tsnk8\" (UID: \"41df3d8b-173f-407c-91cc-5b0da8567827\") "
Jan 17 03:46:55 kind-control-plane systemd[1]: Starting Cleanup of Temporary Directories...
Jan 17 03:46:56 kind-control-plane systemd[1]: systemd-tmpfiles-clean.service: Succeeded.
Jan 17 03:46:56 kind-control-plane systemd[1]: Finished Cleanup of Temporary Directories.
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.134392351Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:coredns-558bd4d5db-7kcfd,Uid:8ce1e50d-5699-49de-9a31-edc180d85ebe,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.231614883Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/b3466a30f904551736a49c00baf111217b199b08afba3458bc750e0f4e838153 pid=990
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.291582480Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-558bd4d5db-7kcfd,Uid:8ce1e50d-5699-49de-9a31-edc180d85ebe,Namespace:kube-system,Attempt:0,} returns sandbox id \"b3466a30f904551736a49c00baf111217b199b08afba3458bc750e0f4e838153\""
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.293194742Z" level=info msg="CreateContainer within sandbox \"b3466a30f904551736a49c00baf111217b199b08afba3458bc750e0f4e838153\" for container &ContainerMetadata{Name:coredns,Attempt:0,}"
Jan 17 03:46:56 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount768242848.mount: Succeeded.
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.424953273Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:coredns-558bd4d5db-tsnk8,Uid:41df3d8b-173f-407c-91cc-5b0da8567827,Namespace:kube-system,Attempt:0,}"
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.623960856Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/b80742566ebae0f32caaae72bfe790fa016772f374c26cbec4f384c5ea7482fe pid=1047
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.716923848Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-558bd4d5db-tsnk8,Uid:41df3d8b-173f-407c-91cc-5b0da8567827,Namespace:kube-system,Attempt:0,} returns sandbox id \"b80742566ebae0f32caaae72bfe790fa016772f374c26cbec4f384c5ea7482fe\""
Jan 17 03:46:56 kind-control-plane containerd[197]: time="2023-01-17T03:46:56.738863348Z" level=info msg="CreateContainer within sandbox \"b80742566ebae0f32caaae72bfe790fa016772f374c26cbec4f384c5ea7482fe\" for container &ContainerMetadata{Name:coredns,Attempt:0,}"
Jan 17 03:46:56 kind-control-plane kubelet[607]: E0117 03:46:56.946180     607 configmap.go:200] Couldn't get configMap local-path-storage/local-path-config: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:56 kind-control-plane kubelet[607]: E0117 03:46:56.946265     607 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume podName:ce7d1ef1-5350-4296-96a1-91e716d7d711 nodeName:}" failed. No retries permitted until 2023-01-17 03:46:57.446243849 +0000 UTC m=+31.379466266 (durationBeforeRetry 500ms). Error: "MountVolume.SetUp failed for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/ce7d1ef1-5350-4296-96a1-91e716d7d711-config-volume\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") : failed to sync configmap cache: timed out waiting for the condition"
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 projected.go:293] Couldn't get configMap local-path-storage/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 projected.go:199] Error preparing data for projected volume kube-api-access-qctc9 for pod local-path-storage/local-path-provisioner-547f784dff-78qdn: failed to sync configmap cache: timed out waiting for the condition
Jan 17 03:46:57 kind-control-plane kubelet[607]: E0117 03:46:57.060326     607 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9 podName:ce7d1ef1-5350-4296-96a1-91e716d7d711 nodeName:}" failed. No retries permitted until 2023-01-17 03:46:57.56032643 +0000 UTC m=+31.493548849 (durationBeforeRetry 500ms). Error: "MountVolume.SetUp failed for volume \"kube-api-access-qctc9\" (UniqueName: \"kubernetes.io/projected/ce7d1ef1-5350-4296-96a1-91e716d7d711-kube-api-access-qctc9\") pod \"local-path-provisioner-547f784dff-78qdn\" (UID: \"ce7d1ef1-5350-4296-96a1-91e716d7d711\") : failed to sync configmap cache: timed out waiting for the condition"
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.153403260Z" level=info msg="CreateContainer within sandbox \"b3466a30f904551736a49c00baf111217b199b08afba3458bc750e0f4e838153\" for &ContainerMetadata{Name:coredns,Attempt:0,} returns container id \"a3022665854a176e1ee66dba3b501c24242b6db656d8596cc6571d8c9924e397\""
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.156919023Z" level=info msg="StartContainer for \"a3022665854a176e1ee66dba3b501c24242b6db656d8596cc6571d8c9924e397\""
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.273789234Z" level=info msg="StartContainer for \"a3022665854a176e1ee66dba3b501c24242b6db656d8596cc6571d8c9924e397\" returns successfully"
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.501559277Z" level=info msg="CreateContainer within sandbox \"b80742566ebae0f32caaae72bfe790fa016772f374c26cbec4f384c5ea7482fe\" for &ContainerMetadata{Name:coredns,Attempt:0,} returns container id \"00086539eea018a6a9e051b4686bc21bbc5436d7e4652c371c699d23aa1f86ee\""
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.502137518Z" level=info msg="StartContainer for \"00086539eea018a6a9e051b4686bc21bbc5436d7e4652c371c699d23aa1f86ee\""
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.562253816Z" level=info msg="StartContainer for \"00086539eea018a6a9e051b4686bc21bbc5436d7e4652c371c699d23aa1f86ee\" returns successfully"
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.887076567Z" level=info msg="RunPodsandbox for &PodSandboxMetadata{Name:local-path-provisioner-547f784dff-78qdn,Uid:ce7d1ef1-5350-4296-96a1-91e716d7d711,Namespace:local-path-storage,Attempt:0,}"
Jan 17 03:46:57 kind-control-plane containerd[197]: time="2023-01-17T03:46:57.974311061Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85 pid=1170
Jan 17 03:46:58 kind-control-plane containerd[197]: time="2023-01-17T03:46:58.084851106Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:local-path-provisioner-547f784dff-78qdn,Uid:ce7d1ef1-5350-4296-96a1-91e716d7d711,Namespace:local-path-storage,Attempt:0,} returns sandbox id \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\""
Jan 17 03:46:58 kind-control-plane containerd[197]: time="2023-01-17T03:46:58.092325351Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:0,}"
Jan 17 03:46:58 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount142646690.mount: Succeeded.
Jan 17 03:46:58 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount407964150.mount: Succeeded.
Jan 17 03:46:58 kind-control-plane containerd[197]: time="2023-01-17T03:46:58.753485219Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:0,} returns container id \"93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809\""
Jan 17 03:46:58 kind-control-plane containerd[197]: time="2023-01-17T03:46:58.754248516Z" level=info msg="StartContainer for \"93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809\""
Jan 17 03:46:58 kind-control-plane containerd[197]: time="2023-01-17T03:46:58.803498692Z" level=info msg="StartContainer for \"93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809\" returns successfully"
Jan 17 05:37:40 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3-rootfs.mount: Succeeded.
Jan 17 05:37:41 kind-control-plane containerd[197]: time="2023-01-17T05:37:41.995251193Z" level=info msg="shim disconnected" id=f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3
Jan 17 05:37:41 kind-control-plane containerd[197]: time="2023-01-17T05:37:41.995320803Z" level=warning msg="cleaning up after shim disconnected" id=f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3 namespace=k8s.io
Jan 17 05:37:41 kind-control-plane containerd[197]: time="2023-01-17T05:37:41.995339403Z" level=info msg="cleaning up dead shim"
Jan 17 05:37:44 kind-control-plane containerd[197]: time="2023-01-17T05:37:44.151953497Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:37:42Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26055\n"
Jan 17 05:37:44 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b-rootfs.mount: Succeeded.
Jan 17 05:37:45 kind-control-plane containerd[197]: time="2023-01-17T05:37:45.120717063Z" level=info msg="shim disconnected" id=a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b
Jan 17 05:37:45 kind-control-plane containerd[197]: time="2023-01-17T05:37:45.120905149Z" level=warning msg="cleaning up after shim disconnected" id=a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b namespace=k8s.io
Jan 17 05:37:45 kind-control-plane containerd[197]: time="2023-01-17T05:37:45.121031642Z" level=info msg="cleaning up dead shim"
Jan 17 05:37:45 kind-control-plane kubelet[607]: I0117 05:37:45.518568     607 scope.go:111] "RemoveContainer" containerID="f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3"
Jan 17 05:37:45 kind-control-plane containerd[197]: time="2023-01-17T05:37:45.715592602Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:1,}"
Jan 17 05:37:45 kind-control-plane kubelet[607]: E0117 05:37:45.831678     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 05:37:46 kind-control-plane kubelet[607]: E0117 05:37:46.037942     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 05:37:46 kind-control-plane containerd[197]: time="2023-01-17T05:37:46.044770280Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:37:45Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26082\n"
Jan 17 05:37:46 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809-rootfs.mount: Succeeded.
Jan 17 05:37:46 kind-control-plane containerd[197]: time="2023-01-17T05:37:46.537693225Z" level=info msg="shim disconnected" id=93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809
Jan 17 05:37:46 kind-control-plane containerd[197]: time="2023-01-17T05:37:46.537757977Z" level=warning msg="cleaning up after shim disconnected" id=93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809 namespace=k8s.io
Jan 17 05:37:46 kind-control-plane containerd[197]: time="2023-01-17T05:37:46.537766461Z" level=info msg="cleaning up dead shim"
Jan 17 05:37:46 kind-control-plane kubelet[607]: I0117 05:37:46.682024     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:37:46 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount684296763.mount: Succeeded.
Jan 17 05:37:46 kind-control-plane containerd[197]: time="2023-01-17T05:37:46.706229671Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:1,}"
Jan 17 05:37:46 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount295970910.mount: Succeeded.
Jan 17 05:37:47 kind-control-plane containerd[197]: time="2023-01-17T05:37:47.006547365Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:37:46Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26109\n"
Jan 17 05:37:47 kind-control-plane containerd[197]: time="2023-01-17T05:37:47.139350638Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:1,} returns container id \"f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5\""
Jan 17 05:37:47 kind-control-plane containerd[197]: time="2023-01-17T05:37:47.157573402Z" level=info msg="StartContainer for \"f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5\""
Jan 17 05:37:49 kind-control-plane containerd[197]: time="2023-01-17T05:37:49.035370838Z" level=info msg="StartContainer for \"f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5\" returns successfully"
Jan 17 05:37:49 kind-control-plane kubelet[607]: I0117 05:37:49.069873     607 scope.go:111] "RemoveContainer" containerID="93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809"
Jan 17 05:37:50 kind-control-plane containerd[197]: time="2023-01-17T05:37:50.912830207Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:1,}"
Jan 17 05:37:52 kind-control-plane containerd[197]: time="2023-01-17T05:37:52.002837916Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:1,} returns container id \"08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303\""
Jan 17 05:37:52 kind-control-plane containerd[197]: time="2023-01-17T05:37:52.076967766Z" level=info msg="StartContainer for \"08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303\""
Jan 17 05:37:52 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount227853607.mount: Succeeded.
Jan 17 05:37:52 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount326056538.mount: Succeeded.
Jan 17 05:37:52 kind-control-plane containerd[197]: time="2023-01-17T05:37:52.884658774Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:1,} returns container id \"3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9\""
Jan 17 05:37:52 kind-control-plane containerd[197]: time="2023-01-17T05:37:52.946827020Z" level=info msg="StartContainer for \"3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9\""
Jan 17 05:37:53 kind-control-plane containerd[197]: time="2023-01-17T05:37:53.755328430Z" level=info msg="StartContainer for \"08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303\" returns successfully"
Jan 17 05:37:55 kind-control-plane kubelet[607]: W0117 05:37:55.966527     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9 WatchSource:0}: task 3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9 not found: not found
Jan 17 05:38:17 kind-control-plane containerd[197]: time="2023-01-17T05:38:17.239095670Z" level=info msg="StartContainer for \"3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9\" returns successfully"
Jan 17 05:39:24 kind-control-plane kubelet[607]: E0117 05:39:24.681911     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 05:39:25 kind-control-plane kubelet[607]: E0117 05:39:25.612414     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 05:39:25 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5-rootfs.mount: Succeeded.
Jan 17 05:39:26 kind-control-plane containerd[197]: time="2023-01-17T05:39:26.598951245Z" level=info msg="shim disconnected" id=f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5
Jan 17 05:39:26 kind-control-plane containerd[197]: time="2023-01-17T05:39:26.599033060Z" level=warning msg="cleaning up after shim disconnected" id=f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5 namespace=k8s.io
Jan 17 05:39:26 kind-control-plane containerd[197]: time="2023-01-17T05:39:26.600764388Z" level=info msg="cleaning up dead shim"
Jan 17 05:39:27 kind-control-plane containerd[197]: time="2023-01-17T05:39:27.624297826Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:39:26Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26527\n"
Jan 17 05:39:33 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303-rootfs.mount: Succeeded.
Jan 17 05:39:33 kind-control-plane containerd[197]: time="2023-01-17T05:39:33.643309920Z" level=info msg="shim disconnected" id=08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303
Jan 17 05:39:33 kind-control-plane containerd[197]: time="2023-01-17T05:39:33.643364292Z" level=warning msg="cleaning up after shim disconnected" id=08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303 namespace=k8s.io
Jan 17 05:39:33 kind-control-plane containerd[197]: time="2023-01-17T05:39:33.643372849Z" level=info msg="cleaning up dead shim"
Jan 17 05:39:33 kind-control-plane containerd[197]: time="2023-01-17T05:39:33.832298436Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:39:33Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26564\n"
Jan 17 05:39:33 kind-control-plane kubelet[607]: I0117 05:39:33.890704     607 scope.go:111] "RemoveContainer" containerID="f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3"
Jan 17 05:39:33 kind-control-plane kubelet[607]: I0117 05:39:33.897022     607 scope.go:111] "RemoveContainer" containerID="f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5"
Jan 17 05:39:33 kind-control-plane containerd[197]: time="2023-01-17T05:39:33.991430795Z" level=info msg="RemoveContainer for \"f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3\""
Jan 17 05:39:34 kind-control-plane containerd[197]: time="2023-01-17T05:39:34.015948701Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:2,}"
Jan 17 05:39:34 kind-control-plane containerd[197]: time="2023-01-17T05:39:34.094338772Z" level=info msg="RemoveContainer for \"f46f2862de8e032b5bcdc422070fa1e4683a851ceab48cdecfa22a5ff6fd27c3\" returns successfully"
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.696712     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.797004     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:53592->172.18.0.2:6443: use of closed network connection
Jan 17 05:39:34 kind-control-plane kubelet[607]: E0117 05:39:34.834548     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02100c8b8491", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ab009ae8f091, ext:6768384696825, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ab009ae8f091, ext:6768384696825, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53592->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.151153     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:39:35 kind-control-plane containerd[197]: time="2023-01-17T05:39:35.371523660Z" level=info msg="RemoveContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\""
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.455756     607 scope.go:111] "RemoveContainer" containerID="a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b"
Jan 17 05:39:35 kind-control-plane kubelet[607]: I0117 05:39:35.456021     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:39:35 kind-control-plane kubelet[607]: E0117 05:39:35.456690     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 05:39:35 kind-control-plane containerd[197]: time="2023-01-17T05:39:35.458849682Z" level=info msg="RemoveContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\" returns successfully"
Jan 17 05:39:35 kind-control-plane containerd[197]: time="2023-01-17T05:39:35.458987089Z" level=info msg="RemoveContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\""
Jan 17 05:39:35 kind-control-plane containerd[197]: time="2023-01-17T05:39:35.459006094Z" level=info msg="RemoveContainer for \"a62e64383b29c17fb351cfd30bab770fcc38cfbe43ab5abc33de8e15f21a6d8b\" returns successfully"
Jan 17 05:39:35 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount817046850.mount: Succeeded.
Jan 17 05:39:35 kind-control-plane containerd[197]: time="2023-01-17T05:39:35.954607742Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:2,} returns container id \"080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19\""
Jan 17 05:39:35 kind-control-plane kubelet[607]: E0117 05:39:35.995267     607 controller.go:187] failed to update lease, error: Operation cannot be fulfilled on leases.coordination.k8s.io "kind-control-plane": the object has been modified; please apply your changes to the latest version and try again
Jan 17 05:39:36 kind-control-plane containerd[197]: time="2023-01-17T05:39:36.020430616Z" level=info msg="StartContainer for \"080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19\""
Jan 17 05:39:37 kind-control-plane containerd[197]: time="2023-01-17T05:39:37.415491621Z" level=info msg="StartContainer for \"080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19\" returns successfully"
Jan 17 05:39:42 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9-rootfs.mount: Succeeded.
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.263564253Z" level=info msg="shim disconnected" id=3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.263616115Z" level=warning msg="cleaning up after shim disconnected" id=3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9 namespace=k8s.io
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.263624445Z" level=info msg="cleaning up dead shim"
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.309035023Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:39:42Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=26655\n"
Jan 17 05:39:42 kind-control-plane kubelet[607]: I0117 05:39:42.322260     607 scope.go:111] "RemoveContainer" containerID="93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809"
Jan 17 05:39:42 kind-control-plane kubelet[607]: I0117 05:39:42.322502     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:39:42 kind-control-plane kubelet[607]: E0117 05:39:42.322662     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.353736538Z" level=info msg="RemoveContainer for \"93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809\""
Jan 17 05:39:42 kind-control-plane containerd[197]: time="2023-01-17T05:39:42.379644574Z" level=info msg="RemoveContainer for \"93bd380a8d7bf6fc9d07caf421b08487e6e14b25316ce54995f84b156a526809\" returns successfully"
Jan 17 05:39:45 kind-control-plane kubelet[607]: I0117 05:39:45.180169     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:39:45 kind-control-plane containerd[197]: time="2023-01-17T05:39:45.187692752Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:2,}"
Jan 17 05:39:45 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount336196407.mount: Succeeded.
Jan 17 05:39:45 kind-control-plane containerd[197]: time="2023-01-17T05:39:45.711366904Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:2,} returns container id \"825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6\""
Jan 17 05:39:45 kind-control-plane containerd[197]: time="2023-01-17T05:39:45.795296740Z" level=info msg="StartContainer for \"825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6\""
Jan 17 05:39:46 kind-control-plane containerd[197]: time="2023-01-17T05:39:46.408608124Z" level=info msg="StartContainer for \"825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6\" returns successfully"
Jan 17 05:39:53 kind-control-plane kubelet[607]: I0117 05:39:53.827307     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:39:54 kind-control-plane containerd[197]: time="2023-01-17T05:39:54.651379202Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:2,}"
Jan 17 05:39:55 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount624732997.mount: Succeeded.
Jan 17 05:39:55 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount777931232.mount: Succeeded.
Jan 17 05:39:55 kind-control-plane containerd[197]: time="2023-01-17T05:39:55.422243513Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:2,} returns container id \"bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4\""
Jan 17 05:39:55 kind-control-plane containerd[197]: time="2023-01-17T05:39:55.437562056Z" level=info msg="StartContainer for \"bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4\""
Jan 17 05:39:57 kind-control-plane containerd[197]: time="2023-01-17T05:39:57.310063519Z" level=info msg="StartContainer for \"bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4\" returns successfully"
Jan 17 05:49:11 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4-rootfs.mount: Succeeded.
Jan 17 05:49:11 kind-control-plane containerd[197]: time="2023-01-17T05:49:11.263688532Z" level=info msg="shim disconnected" id=bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4
Jan 17 05:49:11 kind-control-plane containerd[197]: time="2023-01-17T05:49:11.478582492Z" level=warning msg="cleaning up after shim disconnected" id=bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4 namespace=k8s.io
Jan 17 05:49:11 kind-control-plane containerd[197]: time="2023-01-17T05:49:11.478602700Z" level=info msg="cleaning up dead shim"
Jan 17 05:49:12 kind-control-plane containerd[197]: time="2023-01-17T05:49:12.007871358Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:49:11Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=29019\n"
Jan 17 05:49:12 kind-control-plane kubelet[607]: I0117 05:49:12.879180     607 scope.go:111] "RemoveContainer" containerID="3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9"
Jan 17 05:49:12 kind-control-plane kubelet[607]: I0117 05:49:12.881461     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:12 kind-control-plane kubelet[607]: E0117 05:49:12.881666     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:49:12 kind-control-plane containerd[197]: time="2023-01-17T05:49:12.906380495Z" level=info msg="RemoveContainer for \"3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9\""
Jan 17 05:49:12 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19-rootfs.mount: Succeeded.
Jan 17 05:49:12 kind-control-plane containerd[197]: time="2023-01-17T05:49:12.960914875Z" level=info msg="shim disconnected" id=080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19
Jan 17 05:49:12 kind-control-plane containerd[197]: time="2023-01-17T05:49:12.963268852Z" level=warning msg="cleaning up after shim disconnected" id=080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19 namespace=k8s.io
Jan 17 05:49:12 kind-control-plane containerd[197]: time="2023-01-17T05:49:12.963379275Z" level=info msg="cleaning up dead shim"
Jan 17 05:49:13 kind-control-plane containerd[197]: time="2023-01-17T05:49:13.033429515Z" level=info msg="RemoveContainer for \"3b09433f53b8dd6639437a1b90f1b71d29b1ea2e9ac0de1d7bb175b16ac5eba9\" returns successfully"
Jan 17 05:49:13 kind-control-plane containerd[197]: time="2023-01-17T05:49:13.090321425Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:49:13Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=29044\n"
Jan 17 05:49:13 kind-control-plane kubelet[607]: I0117 05:49:13.887187     607 scope.go:111] "RemoveContainer" containerID="f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5"
Jan 17 05:49:13 kind-control-plane kubelet[607]: I0117 05:49:13.887478     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:13 kind-control-plane kubelet[607]: E0117 05:49:13.887692     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:13 kind-control-plane containerd[197]: time="2023-01-17T05:49:13.900566168Z" level=info msg="RemoveContainer for \"f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5\""
Jan 17 05:49:13 kind-control-plane containerd[197]: time="2023-01-17T05:49:13.934416847Z" level=info msg="RemoveContainer for \"f9ab9c1d1f614480f911992ad153726ca6ff2028cd1b5173fc0d8aa797c92cb5\" returns successfully"
Jan 17 05:49:20 kind-control-plane kubelet[607]: I0117 05:49:20.636818     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:20 kind-control-plane kubelet[607]: E0117 05:49:20.637815     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:22 kind-control-plane kubelet[607]: I0117 05:49:22.050676     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:22 kind-control-plane kubelet[607]: E0117 05:49:22.060142     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:49:26 kind-control-plane kubelet[607]: I0117 05:49:26.731472     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:26 kind-control-plane kubelet[607]: E0117 05:49:26.731907     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:49:34 kind-control-plane kubelet[607]: I0117 05:49:34.708756     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:49:34 kind-control-plane containerd[197]: time="2023-01-17T05:49:34.733733313Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:3,}"
Jan 17 05:49:35 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount162539917.mount: Succeeded.
Jan 17 05:49:35 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount102906248.mount: Succeeded.
Jan 17 05:49:35 kind-control-plane containerd[197]: time="2023-01-17T05:49:35.290731137Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:3,} returns container id \"8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377\""
Jan 17 05:49:35 kind-control-plane containerd[197]: time="2023-01-17T05:49:35.296154191Z" level=info msg="StartContainer for \"8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377\""
Jan 17 05:49:36 kind-control-plane containerd[197]: time="2023-01-17T05:49:36.923347640Z" level=info msg="StartContainer for \"8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377\" returns successfully"
Jan 17 05:49:39 kind-control-plane kubelet[607]: I0117 05:49:39.645374     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:49:39 kind-control-plane containerd[197]: time="2023-01-17T05:49:39.692734478Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:3,}"
Jan 17 05:49:39 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount675638635.mount: Succeeded.
Jan 17 05:49:39 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount701206478.mount: Succeeded.
Jan 17 05:49:40 kind-control-plane containerd[197]: time="2023-01-17T05:49:40.154269134Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:3,} returns container id \"cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a\""
Jan 17 05:49:40 kind-control-plane containerd[197]: time="2023-01-17T05:49:40.159348748Z" level=info msg="StartContainer for \"cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a\""
Jan 17 05:49:42 kind-control-plane kubelet[607]: W0117 05:49:42.379235     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a WatchSource:0}: task cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a not found: not found
Jan 17 05:49:52 kind-control-plane containerd[197]: time="2023-01-17T05:49:52.924817652Z" level=info msg="StartContainer for \"cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a\" returns successfully"
Jan 17 05:59:12 kind-control-plane kubelet[607]: E0117 05:59:12.681215     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 05:59:13 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377-rootfs.mount: Succeeded.
Jan 17 05:59:13 kind-control-plane containerd[197]: time="2023-01-17T05:59:13.449295782Z" level=info msg="shim disconnected" id=8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377
Jan 17 05:59:13 kind-control-plane containerd[197]: time="2023-01-17T05:59:13.449430848Z" level=warning msg="cleaning up after shim disconnected" id=8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377 namespace=k8s.io
Jan 17 05:59:13 kind-control-plane containerd[197]: time="2023-01-17T05:59:13.449443313Z" level=info msg="cleaning up dead shim"
Jan 17 05:59:14 kind-control-plane containerd[197]: time="2023-01-17T05:59:14.117604786Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:59:13Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=31466\n"
Jan 17 05:59:17 kind-control-plane kubelet[607]: I0117 05:59:17.063674     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:17 kind-control-plane kubelet[607]: I0117 05:59:17.134236     607 scope.go:111] "RemoveContainer" containerID="080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19"
Jan 17 05:59:17 kind-control-plane kubelet[607]: E0117 05:59:17.338546     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:17 kind-control-plane containerd[197]: time="2023-01-17T05:59:17.502322225Z" level=info msg="RemoveContainer for \"080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19\""
Jan 17 05:59:17 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6-rootfs.mount: Succeeded.
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.031914641Z" level=info msg="shim disconnected" id=825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.031969250Z" level=warning msg="cleaning up after shim disconnected" id=825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6 namespace=k8s.io
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.031978293Z" level=info msg="cleaning up dead shim"
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.064864030Z" level=info msg="RemoveContainer for \"080c86edc99598a03bf873e91e4ef1150695d8e132cfab6d5ce8116473049b19\" returns successfully"
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.419209172Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:59:18Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=31506\n"
Jan 17 05:59:18 kind-control-plane kubelet[607]: I0117 05:59:18.682393     607 scope.go:111] "RemoveContainer" containerID="08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303"
Jan 17 05:59:18 kind-control-plane kubelet[607]: I0117 05:59:18.728771     607 scope.go:111] "RemoveContainer" containerID="825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6"
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.917840635Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:3,}"
Jan 17 05:59:18 kind-control-plane containerd[197]: time="2023-01-17T05:59:18.958455787Z" level=info msg="RemoveContainer for \"08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303\""
Jan 17 05:59:19 kind-control-plane containerd[197]: time="2023-01-17T05:59:19.617559883Z" level=info msg="RemoveContainer for \"08ff044708c0082d0aed49e09f0efd445fff5b5a05f376de59e43a5bc2407303\" returns successfully"
Jan 17 05:59:20 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount823097971.mount: Succeeded.
Jan 17 05:59:20 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount661430070.mount: Succeeded.
Jan 17 05:59:20 kind-control-plane kubelet[607]: I0117 05:59:20.628775     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:20 kind-control-plane kubelet[607]: E0117 05:59:20.629001     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:20 kind-control-plane containerd[197]: time="2023-01-17T05:59:20.757347032Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:3,} returns container id \"93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4\""
Jan 17 05:59:20 kind-control-plane containerd[197]: time="2023-01-17T05:59:20.758613091Z" level=info msg="StartContainer for \"93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4\""
Jan 17 05:59:21 kind-control-plane containerd[197]: time="2023-01-17T05:59:21.444593106Z" level=info msg="StartContainer for \"93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4\" returns successfully"
Jan 17 05:59:22 kind-control-plane kubelet[607]: I0117 05:59:22.051529     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:22 kind-control-plane kubelet[607]: E0117 05:59:22.051770     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:34 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a-rootfs.mount: Succeeded.
Jan 17 05:59:34 kind-control-plane containerd[197]: time="2023-01-17T05:59:34.135556641Z" level=info msg="shim disconnected" id=cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a
Jan 17 05:59:34 kind-control-plane containerd[197]: time="2023-01-17T05:59:34.135691900Z" level=warning msg="cleaning up after shim disconnected" id=cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a namespace=k8s.io
Jan 17 05:59:34 kind-control-plane containerd[197]: time="2023-01-17T05:59:34.135719115Z" level=info msg="cleaning up dead shim"
Jan 17 05:59:34 kind-control-plane containerd[197]: time="2023-01-17T05:59:34.325706595Z" level=warning msg="cleanup warnings time=\"2023-01-17T05:59:34Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=31632\n"
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.205675     607 scope.go:111] "RemoveContainer" containerID="bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4"
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.206022     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 05:59:35 kind-control-plane kubelet[607]: E0117 05:59:35.206890     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 05:59:35 kind-control-plane containerd[197]: time="2023-01-17T05:59:35.213283396Z" level=info msg="RemoveContainer for \"bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4\""
Jan 17 05:59:35 kind-control-plane containerd[197]: time="2023-01-17T05:59:35.278073517Z" level=info msg="RemoveContainer for \"bbb1d0aa22d40613604c62d7523ee68e0eebf000cb97b9e4174a6a2654d15cb4\" returns successfully"
Jan 17 05:59:35 kind-control-plane kubelet[607]: I0117 05:59:35.635607     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:35 kind-control-plane kubelet[607]: E0117 05:59:35.635815     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 05:59:46 kind-control-plane kubelet[607]: I0117 05:59:46.635769     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 05:59:46 kind-control-plane containerd[197]: time="2023-01-17T05:59:46.644516415Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:4,}"
Jan 17 05:59:46 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount162430604.mount: Succeeded.
Jan 17 05:59:46 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount623744123.mount: Succeeded.
Jan 17 05:59:46 kind-control-plane containerd[197]: time="2023-01-17T05:59:46.941640481Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:4,} returns container id \"da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760\""
Jan 17 05:59:46 kind-control-plane containerd[197]: time="2023-01-17T05:59:46.960743167Z" level=info msg="StartContainer for \"da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760\""
Jan 17 05:59:47 kind-control-plane containerd[197]: time="2023-01-17T05:59:47.381511373Z" level=info msg="StartContainer for \"da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760\" returns successfully"
Jan 17 05:59:49 kind-control-plane kubelet[607]: I0117 05:59:49.637854     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 05:59:49 kind-control-plane containerd[197]: time="2023-01-17T05:59:49.649812208Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:4,}"
Jan 17 05:59:49 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount632170418.mount: Succeeded.
Jan 17 05:59:49 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount620873577.mount: Succeeded.
Jan 17 05:59:49 kind-control-plane containerd[197]: time="2023-01-17T05:59:49.779959367Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:4,} returns container id \"bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46\""
Jan 17 05:59:49 kind-control-plane containerd[197]: time="2023-01-17T05:59:49.780469182Z" level=info msg="StartContainer for \"bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46\""
Jan 17 05:59:51 kind-control-plane kubelet[607]: W0117 05:59:51.555774     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46 WatchSource:0}: task bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46 not found: not found
Jan 17 05:59:56 kind-control-plane containerd[197]: time="2023-01-17T05:59:56.440535373Z" level=info msg="StartContainer for \"bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46\" returns successfully"
Jan 17 06:19:47 kind-control-plane kubelet[607]: E0117 06:19:47.507285     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:19:47 kind-control-plane kubelet[607]: E0117 06:19:47.875284     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:19:49 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760-rootfs.mount: Succeeded.
Jan 17 06:19:50 kind-control-plane containerd[197]: time="2023-01-17T06:19:50.002786415Z" level=info msg="shim disconnected" id=da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760
Jan 17 06:19:50 kind-control-plane containerd[197]: time="2023-01-17T06:19:50.002886151Z" level=warning msg="cleaning up after shim disconnected" id=da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760 namespace=k8s.io
Jan 17 06:19:50 kind-control-plane containerd[197]: time="2023-01-17T06:19:50.002898637Z" level=info msg="cleaning up dead shim"
Jan 17 06:19:50 kind-control-plane containerd[197]: time="2023-01-17T06:19:50.593616722Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:19:50Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=36526\n"
Jan 17 06:19:52 kind-control-plane kubelet[607]: I0117 06:19:52.723442     607 scope.go:111] "RemoveContainer" containerID="8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377"
Jan 17 06:19:52 kind-control-plane kubelet[607]: I0117 06:19:52.774732     607 scope.go:111] "RemoveContainer" containerID="da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760"
Jan 17 06:19:52 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4-rootfs.mount: Succeeded.
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.090745878Z" level=info msg="RemoveContainer for \"8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377\""
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.176306119Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:5,}"
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.240119172Z" level=info msg="shim disconnected" id=93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.240172043Z" level=warning msg="cleaning up after shim disconnected" id=93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4 namespace=k8s.io
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.240180298Z" level=info msg="cleaning up dead shim"
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.674956196Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:19:53Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=36580\n"
Jan 17 06:19:53 kind-control-plane containerd[197]: time="2023-01-17T06:19:53.799874729Z" level=info msg="RemoveContainer for \"8302624fa27de5a9f0ce938d2f6a27cb0e929eb5b3110ab920c524a0f6849377\" returns successfully"
Jan 17 06:19:54 kind-control-plane kubelet[607]: I0117 06:19:54.260906     607 scope.go:111] "RemoveContainer" containerID="825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6"
Jan 17 06:19:54 kind-control-plane kubelet[607]: I0117 06:19:54.264931     607 scope.go:111] "RemoveContainer" containerID="93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4"
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.418415827Z" level=info msg="RemoveContainer for \"825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6\""
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.448280486Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:4,}"
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.722012636Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:5,} returns container id \"bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82\""
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.744784013Z" level=info msg="StartContainer for \"bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82\""
Jan 17 06:19:54 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount981632922.mount: Succeeded.
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.854751990Z" level=info msg="RemoveContainer for \"825a5c3c77a1e8cbe61ac984c5cbd6683c79df7ba25b58b491a0660b0aa74cc6\" returns successfully"
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.938282941Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:4,} returns container id \"c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245\""
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.946819783Z" level=info msg="StartContainer for \"c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245\""
Jan 17 06:19:54 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46-rootfs.mount: Succeeded.
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.975079507Z" level=info msg="shim disconnected" id=bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.975126746Z" level=warning msg="cleaning up after shim disconnected" id=bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46 namespace=k8s.io
Jan 17 06:19:54 kind-control-plane containerd[197]: time="2023-01-17T06:19:54.975134723Z" level=info msg="cleaning up dead shim"
Jan 17 06:19:55 kind-control-plane containerd[197]: time="2023-01-17T06:19:55.443780777Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:19:55Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=36637\n"
Jan 17 06:19:55 kind-control-plane kubelet[607]: I0117 06:19:55.629505     607 scope.go:111] "RemoveContainer" containerID="cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a"
Jan 17 06:19:55 kind-control-plane kubelet[607]: I0117 06:19:55.644715     607 scope.go:111] "RemoveContainer" containerID="bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46"
Jan 17 06:19:55 kind-control-plane containerd[197]: time="2023-01-17T06:19:55.737230754Z" level=info msg="StartContainer for \"bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82\" returns successfully"
Jan 17 06:19:55 kind-control-plane containerd[197]: time="2023-01-17T06:19:55.738324624Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:5,}"
Jan 17 06:19:55 kind-control-plane containerd[197]: time="2023-01-17T06:19:55.762237057Z" level=info msg="RemoveContainer for \"cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a\""
Jan 17 06:19:56 kind-control-plane containerd[197]: time="2023-01-17T06:19:55.996073882Z" level=info msg="RemoveContainer for \"cc96e45acb16610ef3abcb2a4553324b07941f0c2af177f0c16a3981fa48004a\" returns successfully"
Jan 17 06:19:56 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount102579414.mount: Succeeded.
Jan 17 06:19:56 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount631175229.mount: Succeeded.
Jan 17 06:19:56 kind-control-plane containerd[197]: time="2023-01-17T06:19:56.469997887Z" level=info msg="StartContainer for \"c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245\" returns successfully"
Jan 17 06:19:56 kind-control-plane containerd[197]: time="2023-01-17T06:19:56.529287442Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:5,} returns container id \"85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605\""
Jan 17 06:19:56 kind-control-plane containerd[197]: time="2023-01-17T06:19:56.529869929Z" level=info msg="StartContainer for \"85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605\""
Jan 17 06:19:58 kind-control-plane kubelet[607]: W0117 06:19:58.692207     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605 WatchSource:0}: task 85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605 not found: not found
Jan 17 06:20:31 kind-control-plane containerd[197]: time="2023-01-17T06:20:31.617433578Z" level=info msg="StartContainer for \"85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605\" returns successfully"
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933702     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.limit_in_bytes: no such device
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933750     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.memsw.limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.memsw.limit_in_bytes: no such device
Jan 17 06:22:45 kind-control-plane kubelet[607]: W0117 06:22:45.933765     607 helpers.go:220] readString: Failed to read "/sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.soft_limit_in_bytes": read /sys/fs/cgroup/memory/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245/memory.soft_limit_in_bytes: no such device
Jan 17 06:22:46 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245-rootfs.mount: Succeeded.
Jan 17 06:22:46 kind-control-plane containerd[197]: time="2023-01-17T06:22:46.233962968Z" level=info msg="shim disconnected" id=c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245
Jan 17 06:22:46 kind-control-plane containerd[197]: time="2023-01-17T06:22:46.348659320Z" level=warning msg="cleaning up after shim disconnected" id=c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245 namespace=k8s.io
Jan 17 06:22:46 kind-control-plane containerd[197]: time="2023-01-17T06:22:46.348686715Z" level=info msg="cleaning up dead shim"
Jan 17 06:22:46 kind-control-plane containerd[197]: time="2023-01-17T06:22:46.921349660Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:22:46Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=37347\n"
Jan 17 06:22:47 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605-rootfs.mount: Succeeded.
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.243727526Z" level=info msg="shim disconnected" id=85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.243784487Z" level=warning msg="cleaning up after shim disconnected" id=85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605 namespace=k8s.io
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.243793056Z" level=info msg="cleaning up dead shim"
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.256903171Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:22:47Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=37413\n"
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.723215     607 scope.go:111] "RemoveContainer" containerID="93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4"
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.723649     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:22:47 kind-control-plane kubelet[607]: E0117 06:22:47.728133     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.747603023Z" level=info msg="RemoveContainer for \"93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4\""
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.763255     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:22:47 kind-control-plane kubelet[607]: E0117 06:22:47.763466     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.767215645Z" level=info msg="RemoveContainer for \"93d28a2975d70c4fd1ce5a317544130e927ad7aefc7ada954e40bb91e96743f4\" returns successfully"
Jan 17 06:22:47 kind-control-plane kubelet[607]: I0117 06:22:47.767508     607 scope.go:111] "RemoveContainer" containerID="bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46"
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.782783079Z" level=info msg="RemoveContainer for \"bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46\""
Jan 17 06:22:47 kind-control-plane containerd[197]: time="2023-01-17T06:22:47.846172704Z" level=info msg="RemoveContainer for \"bf3266f265d6c095be61cb687c5b7f32f81d7b99df2e25b0f20dcfe23b844f46\" returns successfully"
Jan 17 06:22:55 kind-control-plane kubelet[607]: I0117 06:22:55.217212     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:22:55 kind-control-plane kubelet[607]: E0117 06:22:55.217698     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:22:55 kind-control-plane kubelet[607]: I0117 06:22:55.835189     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:22:55 kind-control-plane containerd[197]: time="2023-01-17T06:22:55.878070978Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:5,}"
Jan 17 06:22:55 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount926790533.mount: Succeeded.
Jan 17 06:22:55 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount506969376.mount: Succeeded.
Jan 17 06:22:55 kind-control-plane containerd[197]: time="2023-01-17T06:22:55.928591159Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:5,} returns container id \"9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36\""
Jan 17 06:22:55 kind-control-plane containerd[197]: time="2023-01-17T06:22:55.929987516Z" level=info msg="StartContainer for \"9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36\""
Jan 17 06:22:56 kind-control-plane containerd[197]: time="2023-01-17T06:22:56.059733430Z" level=info msg="StartContainer for \"9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36\" returns successfully"
Jan 17 06:23:02 kind-control-plane kubelet[607]: I0117 06:23:02.634660     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:23:02 kind-control-plane containerd[197]: time="2023-01-17T06:23:02.637515589Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:6,}"
Jan 17 06:23:02 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount200408995.mount: Succeeded.
Jan 17 06:23:02 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount189928102.mount: Succeeded.
Jan 17 06:23:02 kind-control-plane containerd[197]: time="2023-01-17T06:23:02.687657485Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:6,} returns container id \"96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3\""
Jan 17 06:23:02 kind-control-plane containerd[197]: time="2023-01-17T06:23:02.688517531Z" level=info msg="StartContainer for \"96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3\""
Jan 17 06:23:02 kind-control-plane containerd[197]: time="2023-01-17T06:23:02.835384721Z" level=info msg="StartContainer for \"96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3\" returns successfully"
Jan 17 06:29:35 kind-control-plane kubelet[607]: I0117 06:29:35.486743     607 trace.go:205] Trace[1629297354]: "iptables ChainExists" (17-Jan-2023 06:29:31.667) (total time: 2638ms):
Jan 17 06:29:35 kind-control-plane kubelet[607]: Trace[1629297354]: [2.638212236s] [2.638212236s] END
Jan 17 06:29:39 kind-control-plane kubelet[607]: E0117 06:29:39.924793     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:29:40 kind-control-plane kubelet[607]: E0117 06:29:39.948923     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:29:43 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82-rootfs.mount: Succeeded.
Jan 17 06:29:43 kind-control-plane containerd[197]: time="2023-01-17T06:29:43.345353369Z" level=info msg="shim disconnected" id=bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82
Jan 17 06:29:43 kind-control-plane containerd[197]: time="2023-01-17T06:29:43.345470954Z" level=warning msg="cleaning up after shim disconnected" id=bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82 namespace=k8s.io
Jan 17 06:29:43 kind-control-plane containerd[197]: time="2023-01-17T06:29:43.345515727Z" level=info msg="cleaning up dead shim"
Jan 17 06:29:43 kind-control-plane containerd[197]: time="2023-01-17T06:29:43.670843516Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:29:43Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=39034\n"
Jan 17 06:29:44 kind-control-plane kubelet[607]: I0117 06:29:44.252961     607 scope.go:111] "RemoveContainer" containerID="da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760"
Jan 17 06:29:44 kind-control-plane kubelet[607]: I0117 06:29:44.260916     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:29:44 kind-control-plane kubelet[607]: E0117 06:29:44.267580     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.296139388Z" level=info msg="RemoveContainer for \"da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760\""
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.372075142Z" level=info msg="RemoveContainer for \"da9d530aa50480ece5f8d378d87ec701efc6f94bfe0253ded9dfb22f129c2760\" returns successfully"
Jan 17 06:29:44 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36-rootfs.mount: Succeeded.
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.607861853Z" level=info msg="shim disconnected" id=9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.607934053Z" level=warning msg="cleaning up after shim disconnected" id=9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36 namespace=k8s.io
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.607945885Z" level=info msg="cleaning up dead shim"
Jan 17 06:29:44 kind-control-plane containerd[197]: time="2023-01-17T06:29:44.839233754Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:29:44Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=39063\n"
Jan 17 06:29:45 kind-control-plane kubelet[607]: I0117 06:29:45.291696     607 scope.go:111] "RemoveContainer" containerID="c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245"
Jan 17 06:29:45 kind-control-plane kubelet[607]: I0117 06:29:45.293527     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:45 kind-control-plane kubelet[607]: E0117 06:29:45.294034     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:45 kind-control-plane containerd[197]: time="2023-01-17T06:29:45.320656535Z" level=info msg="RemoveContainer for \"c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245\""
Jan 17 06:29:45 kind-control-plane containerd[197]: time="2023-01-17T06:29:45.571429941Z" level=info msg="RemoveContainer for \"c87e478e6dbc9d62311e4fed9db04a8ebd3490ae08f6e782aa9f718f77901245\" returns successfully"
Jan 17 06:29:46 kind-control-plane kubelet[607]: I0117 06:29:46.297351     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:46 kind-control-plane kubelet[607]: E0117 06:29:46.297655     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:46 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3-rootfs.mount: Succeeded.
Jan 17 06:29:46 kind-control-plane containerd[197]: time="2023-01-17T06:29:46.545907694Z" level=info msg="shim disconnected" id=96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3
Jan 17 06:29:46 kind-control-plane containerd[197]: time="2023-01-17T06:29:46.545960632Z" level=warning msg="cleaning up after shim disconnected" id=96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3 namespace=k8s.io
Jan 17 06:29:46 kind-control-plane containerd[197]: time="2023-01-17T06:29:46.545969190Z" level=info msg="cleaning up dead shim"
Jan 17 06:29:46 kind-control-plane containerd[197]: time="2023-01-17T06:29:46.604732327Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:29:46Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=39091\n"
Jan 17 06:29:47 kind-control-plane kubelet[607]: I0117 06:29:47.309909     607 scope.go:111] "RemoveContainer" containerID="85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605"
Jan 17 06:29:47 kind-control-plane kubelet[607]: I0117 06:29:47.311504     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:29:47 kind-control-plane kubelet[607]: E0117 06:29:47.311674     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:29:47 kind-control-plane containerd[197]: time="2023-01-17T06:29:47.315180136Z" level=info msg="RemoveContainer for \"85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605\""
Jan 17 06:29:47 kind-control-plane containerd[197]: time="2023-01-17T06:29:47.341449125Z" level=info msg="RemoveContainer for \"85f66aab612c3cab8e3f07e5f598d6d4c1750fd65ff1734d79242e7792e19605\" returns successfully"
Jan 17 06:29:50 kind-control-plane kubelet[607]: I0117 06:29:50.623574     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:29:50 kind-control-plane containerd[197]: time="2023-01-17T06:29:50.643012307Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:6,}"
Jan 17 06:29:50 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount647041294.mount: Succeeded.
Jan 17 06:29:50 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount374253333.mount: Succeeded.
Jan 17 06:29:50 kind-control-plane containerd[197]: time="2023-01-17T06:29:50.809955775Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:6,} returns container id \"660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1\""
Jan 17 06:29:50 kind-control-plane containerd[197]: time="2023-01-17T06:29:50.810952880Z" level=info msg="StartContainer for \"660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1\""
Jan 17 06:29:51 kind-control-plane containerd[197]: time="2023-01-17T06:29:51.004532527Z" level=info msg="StartContainer for \"660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1\" returns successfully"
Jan 17 06:29:55 kind-control-plane kubelet[607]: I0117 06:29:55.177145     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:29:55 kind-control-plane kubelet[607]: E0117 06:29:55.177431     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:29:59 kind-control-plane kubelet[607]: I0117 06:29:59.634650     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:29:59 kind-control-plane kubelet[607]: E0117 06:29:59.634853     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:30:09 kind-control-plane kubelet[607]: I0117 06:30:09.688794     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:30:09 kind-control-plane containerd[197]: time="2023-01-17T06:30:09.697032558Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:6,}"
Jan 17 06:30:09 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount945040292.mount: Succeeded.
Jan 17 06:30:09 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount217884851.mount: Succeeded.
Jan 17 06:30:09 kind-control-plane containerd[197]: time="2023-01-17T06:30:09.765868797Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:6,} returns container id \"813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4\""
Jan 17 06:30:09 kind-control-plane containerd[197]: time="2023-01-17T06:30:09.766857774Z" level=info msg="StartContainer for \"813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4\""
Jan 17 06:30:09 kind-control-plane containerd[197]: time="2023-01-17T06:30:09.908821898Z" level=info msg="StartContainer for \"813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4\" returns successfully"
Jan 17 06:30:11 kind-control-plane kubelet[607]: I0117 06:30:11.639675     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:30:11 kind-control-plane containerd[197]: time="2023-01-17T06:30:11.663435129Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:7,}"
Jan 17 06:30:11 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount112804874.mount: Succeeded.
Jan 17 06:30:11 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount209587681.mount: Succeeded.
Jan 17 06:30:11 kind-control-plane containerd[197]: time="2023-01-17T06:30:11.999015559Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:7,} returns container id \"28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae\""
Jan 17 06:30:12 kind-control-plane containerd[197]: time="2023-01-17T06:30:12.023812461Z" level=info msg="StartContainer for \"28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae\""
Jan 17 06:30:12 kind-control-plane containerd[197]: time="2023-01-17T06:30:12.777011346Z" level=info msg="StartContainer for \"28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae\" returns successfully"
Jan 17 06:30:46 kind-control-plane kubelet[607]: E0117 06:30:46.826263     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:30:46 kind-control-plane kubelet[607]: E0117 06:30:46.875803     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:30:55 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4-rootfs.mount: Succeeded.
Jan 17 06:30:56 kind-control-plane containerd[197]: time="2023-01-17T06:30:56.375424188Z" level=info msg="shim disconnected" id=813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4
Jan 17 06:30:56 kind-control-plane containerd[197]: time="2023-01-17T06:30:56.410748004Z" level=warning msg="cleaning up after shim disconnected" id=813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4 namespace=k8s.io
Jan 17 06:30:56 kind-control-plane containerd[197]: time="2023-01-17T06:30:56.410762737Z" level=info msg="cleaning up dead shim"
Jan 17 06:30:56 kind-control-plane kubelet[607]: E0117 06:30:56.857846     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:30:57 kind-control-plane kubelet[607]: E0117 06:30:56.906615     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"etcd-kind-control-plane.173b04dd9f6f73a1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"etcd-kind-control-plane", UID:"24ba8551bcc724a32d591bb02c423d92", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{etcd}"}, Reason:"Unhealthy", Message:"Liveness probe failed: HTTP probe failed with statuscode: 503", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae031848fba1, ext:9850340659837, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae031848fba1, ext:9850340659837, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:50656->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:30:57 kind-control-plane kubelet[607]: E0117 06:30:56.906780     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:50656->172.18.0.2:6443: use of closed network connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:30:57 kind-control-plane kubelet[607]: W0117 06:30:56.922214     607 reflector.go:436] object-"local-path-storage"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:30:57 kind-control-plane containerd[197]: time="2023-01-17T06:30:57.328527728Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:30:56Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=39445\n"
Jan 17 06:31:00 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1-rootfs.mount: Succeeded.
Jan 17 06:31:00 kind-control-plane containerd[197]: time="2023-01-17T06:31:00.390322135Z" level=info msg="shim disconnected" id=660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1
Jan 17 06:31:00 kind-control-plane containerd[197]: time="2023-01-17T06:31:00.390442187Z" level=warning msg="cleaning up after shim disconnected" id=660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1 namespace=k8s.io
Jan 17 06:31:00 kind-control-plane containerd[197]: time="2023-01-17T06:31:00.390452410Z" level=info msg="cleaning up dead shim"
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.152863     607 scope.go:111] "RemoveContainer" containerID="9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36"
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.183200     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:01 kind-control-plane kubelet[607]: E0117 06:31:01.183764     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:01 kind-control-plane containerd[197]: time="2023-01-17T06:31:01.398067206Z" level=info msg="RemoveContainer for \"9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36\""
Jan 17 06:31:01 kind-control-plane containerd[197]: time="2023-01-17T06:31:01.545755141Z" level=info msg="RemoveContainer for \"9a02dc56c4473a306e13296a93030eeb6cc61003a4addbfbef4dfabff15d5a36\" returns successfully"
Jan 17 06:31:01 kind-control-plane containerd[197]: time="2023-01-17T06:31:01.576500758Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:31:01Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=39475\n"
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.626555     607 scope.go:111] "RemoveContainer" containerID="bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82"
Jan 17 06:31:01 kind-control-plane containerd[197]: time="2023-01-17T06:31:01.627907424Z" level=info msg="RemoveContainer for \"bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82\""
Jan 17 06:31:01 kind-control-plane kubelet[607]: I0117 06:31:01.690583     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:01 kind-control-plane kubelet[607]: E0117 06:31:01.690924     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:01 kind-control-plane containerd[197]: time="2023-01-17T06:31:01.753926749Z" level=info msg="RemoveContainer for \"bdde817dfbe58d11ebe45cb5b5face11312537a83ef64f688bd826e21121fe82\" returns successfully"
Jan 17 06:31:02 kind-control-plane kubelet[607]: I0117 06:31:02.652307     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:02 kind-control-plane kubelet[607]: E0117 06:31:02.652552     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:05 kind-control-plane kubelet[607]: I0117 06:31:05.178892     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:05 kind-control-plane kubelet[607]: E0117 06:31:05.180941     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:05 kind-control-plane kubelet[607]: I0117 06:31:05.800004     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:05 kind-control-plane kubelet[607]: E0117 06:31:05.817125     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:10 kind-control-plane kubelet[607]: I0117 06:31:10.621551     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:10 kind-control-plane kubelet[607]: E0117 06:31:10.623834     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-scheduler\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kube-scheduler pod=kube-scheduler-kind-control-plane_kube-system(69dd939498054a211c3461b2a9cc8d26)\"" pod="kube-system/kube-scheduler-kind-control-plane" podUID=69dd939498054a211c3461b2a9cc8d26
Jan 17 06:31:17 kind-control-plane kubelet[607]: I0117 06:31:17.707608     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:17 kind-control-plane kubelet[607]: E0117 06:31:17.707890     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:24 kind-control-plane kubelet[607]: I0117 06:31:24.644389     607 scope.go:111] "RemoveContainer" containerID="660cb6390cff13559bb8b86496c790c07d99cc7fef927bdc1f67afcf020bf9f1"
Jan 17 06:31:24 kind-control-plane containerd[197]: time="2023-01-17T06:31:24.692854891Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:7,}"
Jan 17 06:31:25 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount853888242.mount: Succeeded.
Jan 17 06:31:25 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount992523177.mount: Succeeded.
Jan 17 06:31:25 kind-control-plane containerd[197]: time="2023-01-17T06:31:25.271758115Z" level=info msg="CreateContainer within sandbox \"69a2282ca05fc4b66ab8d3d98c4c38aeae89c4cbb43e440df00ea106206aecc0\" for &ContainerMetadata{Name:kube-scheduler,Attempt:7,} returns container id \"cbdc7ab1d21b3ebbb57ad2d939c242d8694e7a7eb4514f18791fcdee88757a91\""
Jan 17 06:31:25 kind-control-plane containerd[197]: time="2023-01-17T06:31:25.290779648Z" level=info msg="StartContainer for \"cbdc7ab1d21b3ebbb57ad2d939c242d8694e7a7eb4514f18791fcdee88757a91\""
Jan 17 06:31:26 kind-control-plane containerd[197]: time="2023-01-17T06:31:26.897831745Z" level=info msg="StartContainer for \"cbdc7ab1d21b3ebbb57ad2d939c242d8694e7a7eb4514f18791fcdee88757a91\" returns successfully"
Jan 17 06:31:32 kind-control-plane kubelet[607]: I0117 06:31:32.651781     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:32 kind-control-plane kubelet[607]: E0117 06:31:32.890717     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kube-controller-manager pod=kube-controller-manager-kind-control-plane_kube-system(46dac9a538838115821dfd9559149484)\"" pod="kube-system/kube-controller-manager-kind-control-plane" podUID=46dac9a538838115821dfd9559149484
Jan 17 06:31:48 kind-control-plane kubelet[607]: I0117 06:31:48.654886     607 scope.go:111] "RemoveContainer" containerID="813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4"
Jan 17 06:31:49 kind-control-plane containerd[197]: time="2023-01-17T06:31:49.084372808Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:7,}"
Jan 17 06:31:50 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount900655976.mount: Succeeded.
Jan 17 06:31:51 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount312252839.mount: Succeeded.
Jan 17 06:31:51 kind-control-plane containerd[197]: time="2023-01-17T06:31:51.228576799Z" level=info msg="CreateContainer within sandbox \"8264510e6c6867d1d1d9b47dd9ca04e738803e3b7f2021c0512cf6c484dc74e5\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:7,} returns container id \"e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98\""
Jan 17 06:31:51 kind-control-plane containerd[197]: time="2023-01-17T06:31:51.247873467Z" level=info msg="StartContainer for \"e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98\""
Jan 17 06:31:54 kind-control-plane kubelet[607]: W0117 06:31:54.227151     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/burstable/pod46dac9a538838115821dfd9559149484/e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98 WatchSource:0}: task e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98 not found: not found
Jan 17 06:31:55 kind-control-plane containerd[197]: time="2023-01-17T06:31:55.037250510Z" level=info msg="StartContainer for \"e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98\" returns successfully"
Jan 17 06:32:13 kind-control-plane kubelet[607]: E0117 06:32:13.104441     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:32:14 kind-control-plane kubelet[607]: E0117 06:32:14.186314     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.217519     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.268429     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:32:23 kind-control-plane kubelet[607]: I0117 06:32:23.268749     607 status_manager.go:589] "Failed to update status for pod" pod="kube-system/kube-controller-manager-kind-control-plane" err="failed to patch status \"{\\\"metadata\\\":{\\\"uid\\\":\\\"779722c9-072a-4757-8b67-2123c25ed3e6\\\"},\\\"status\\\":{\\\"containerStatuses\\\":[{\\\"containerID\\\":\\\"containerd://e9f4ee683730cf42dfbf98526b9c3757d653a7758a81ebb2ac9206673ba9fd98\\\",\\\"image\\\":\\\"k8s.gcr.io/kube-controller-manager:v1.21.1\\\",\\\"imageID\\\":\\\"sha256:96a295389d472f96d58764c2ed3e7418d0183f707765c21e6f310c2e163225a9\\\",\\\"lastState\\\":{\\\"terminated\\\":{\\\"containerID\\\":\\\"containerd://813defdfeaf30e45d3bec93585df1294f43143222d91a8c179352f67257aa3a4\\\",\\\"exitCode\\\":255,\\\"finishedAt\\\":\\\"2023-01-17T06:30:54Z\\\",\\\"reason\\\":\\\"Error\\\",\\\"startedAt\\\":\\\"2023-01-17T06:30:09Z\\\"}},\\\"name\\\":\\\"kube-controller-manager\\\",\\\"ready\\\":false,\\\"restartCount\\\":7,\\\"started\\\":false,\\\"state\\\":{\\\"running\\\":{\\\"startedAt\\\":\\\"2023-01-17T06:31:54Z\\\"}}}]}}\" for pod \"kube-system\"/\"kube-controller-manager-kind-control-plane\": Patch \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane/status\": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection"
Jan 17 06:32:23 kind-control-plane kubelet[607]: E0117 06:32:23.293815     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:52250->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.297606     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.297997     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:54968->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:33 kind-control-plane kubelet[607]: E0117 06:32:33.314125     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:54968->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.415789     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.482406     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:55428->172.18.0.2:6443: use of closed network connection
Jan 17 06:32:43 kind-control-plane kubelet[607]: I0117 06:32:43.482449     607 controller.go:114] failed to update lease using latest lease, fallback to ensure lease, err: failed 5 attempts to update lease
Jan 17 06:32:43 kind-control-plane kubelet[607]: E0117 06:32:43.554029     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:32:53 kind-control-plane kubelet[607]: E0117 06:32:53.862681     607 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067718     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067752     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:32:54 kind-control-plane kubelet[607]: E0117 06:32:54.067827     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:55870->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:04 kind-control-plane kubelet[607]: E0117 06:33:04.079864     607 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:14 kind-control-plane kubelet[607]: E0117 06:33:14.351731     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:14 kind-control-plane kubelet[607]: E0117 06:33:14.692492     607 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:33:25 kind-control-plane kubelet[607]: E0117 06:33:25.455735     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:29 kind-control-plane kubelet[607]: E0117 06:33:29.847572     607 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:31 kind-control-plane kubelet[607]: E0117 06:33:27.406328     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:56448->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:36 kind-control-plane kubelet[607]: E0117 06:33:36.464907     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:33:41 kind-control-plane kubelet[607]: E0117 06:33:41.602511     607 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:43 kind-control-plane containerd[197]: time="2023-01-17T06:33:43.844411980Z" level=info msg="StopContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\" with timeout 30 (s)"
Jan 17 06:33:44 kind-control-plane containerd[197]: time="2023-01-17T06:33:44.013807610Z" level=info msg="Stop container \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\" with signal terminated"
Jan 17 06:33:46 kind-control-plane kubelet[607]: E0117 06:33:46.496937     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:58358->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:46 kind-control-plane kubelet[607]: E0117 06:33:46.571407     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:33:55 kind-control-plane kubelet[607]: E0117 06:33:55.123589     607 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.665646     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.665673     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:33:56 kind-control-plane kubelet[607]: E0117 06:33:56.604093     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:58576->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:33:59 kind-control-plane kubelet[607]: I0117 06:33:59.709030     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:33:59 kind-control-plane kubelet[607]: I0117 06:33:59.950004     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:00 kind-control-plane kubelet[607]: I0117 06:34:00.159933     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:00 kind-control-plane kubelet[607]: I0117 06:34:00.476162     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: E0117 06:34:01.993911     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034509     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034808     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:02 kind-control-plane kubelet[607]: I0117 06:34:02.034957     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.162693     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.163945     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.733226     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.825455     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.866847     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.887532     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:07 kind-control-plane kubelet[607]: E0117 06:34:07.887567     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:34:09 kind-control-plane kubelet[607]: E0117 06:34:09.021906     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681409     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681586     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:11 kind-control-plane kubelet[607]: I0117 06:34:11.681701     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:13 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c-rootfs.mount: Succeeded.
Jan 17 06:34:13 kind-control-plane containerd[197]: time="2023-01-17T06:34:13.932173381Z" level=info msg="shim disconnected" id=faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c
Jan 17 06:34:13 kind-control-plane containerd[197]: time="2023-01-17T06:34:13.932252322Z" level=warning msg="cleaning up after shim disconnected" id=faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c namespace=k8s.io
Jan 17 06:34:13 kind-control-plane containerd[197]: time="2023-01-17T06:34:13.952695458Z" level=info msg="cleaning up dead shim"
Jan 17 06:34:14 kind-control-plane containerd[197]: time="2023-01-17T06:34:14.149280697Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:34:14Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40021\n"
Jan 17 06:34:15 kind-control-plane kubelet[607]: I0117 06:34:15.123663     607 scope.go:111] "RemoveContainer" containerID="faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c"
Jan 17 06:34:15 kind-control-plane kubelet[607]: I0117 06:34:15.143468     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:15 kind-control-plane containerd[197]: time="2023-01-17T06:34:15.223423670Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:1,}"
Jan 17 06:34:15 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount665866805.mount: Succeeded.
Jan 17 06:34:15 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount661059600.mount: Succeeded.
Jan 17 06:34:15 kind-control-plane containerd[197]: time="2023-01-17T06:34:15.768831485Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for &ContainerMetadata{Name:kindnet-cni,Attempt:1,} returns container id \"7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15\""
Jan 17 06:34:15 kind-control-plane containerd[197]: time="2023-01-17T06:34:15.769509657Z" level=info msg="StartContainer for \"7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15\""
Jan 17 06:34:16 kind-control-plane kubelet[607]: E0117 06:34:16.239260     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:34:16 kind-control-plane containerd[197]: time="2023-01-17T06:34:16.276440991Z" level=info msg="Kill container \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\""
Jan 17 06:34:16 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1-rootfs.mount: Succeeded.
Jan 17 06:34:16 kind-control-plane containerd[197]: time="2023-01-17T06:34:16.974349255Z" level=info msg="shim disconnected" id=80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1
Jan 17 06:34:16 kind-control-plane containerd[197]: time="2023-01-17T06:34:16.974414191Z" level=warning msg="cleaning up after shim disconnected" id=80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1 namespace=k8s.io
Jan 17 06:34:16 kind-control-plane containerd[197]: time="2023-01-17T06:34:16.974425321Z" level=info msg="cleaning up dead shim"
Jan 17 06:34:17 kind-control-plane containerd[197]: time="2023-01-17T06:34:17.145616033Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:34:17Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40073\n"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.210226     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:34:17 kind-control-plane containerd[197]: time="2023-01-17T06:34:17.213280751Z" level=info msg="StopContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\" returns successfully"
Jan 17 06:34:17 kind-control-plane containerd[197]: time="2023-01-17T06:34:17.226869834Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for container &ContainerMetadata{Name:kube-apiserver,Attempt:1,}"
Jan 17 06:34:17 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount974030547.mount: Succeeded.
Jan 17 06:34:17 kind-control-plane containerd[197]: time="2023-01-17T06:34:17.813015534Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for &ContainerMetadata{Name:kube-apiserver,Attempt:1,} returns container id \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\""
Jan 17 06:34:17 kind-control-plane containerd[197]: time="2023-01-17T06:34:17.834703758Z" level=info msg="StartContainer for \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\""
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.888872     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906108     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906404     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906542     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906646     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:17 kind-control-plane kubelet[607]: E0117 06:34:17.906655     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:34:18 kind-control-plane containerd[197]: time="2023-01-17T06:34:18.214822657Z" level=info msg="StartContainer for \"7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15\" returns successfully"
Jan 17 06:34:18 kind-control-plane kubelet[607]: I0117 06:34:18.703776     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:18 kind-control-plane containerd[197]: time="2023-01-17T06:34:18.816351506Z" level=info msg="StartContainer for \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\" returns successfully"
Jan 17 06:34:18 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae-rootfs.mount: Succeeded.
Jan 17 06:34:19 kind-control-plane containerd[197]: time="2023-01-17T06:34:19.255572275Z" level=info msg="shim disconnected" id=28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae
Jan 17 06:34:19 kind-control-plane containerd[197]: time="2023-01-17T06:34:19.255710091Z" level=warning msg="cleaning up after shim disconnected" id=28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae namespace=k8s.io
Jan 17 06:34:19 kind-control-plane containerd[197]: time="2023-01-17T06:34:19.255724725Z" level=info msg="cleaning up dead shim"
Jan 17 06:34:19 kind-control-plane containerd[197]: time="2023-01-17T06:34:19.402333917Z" level=error msg="collecting metrics for 28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae" error="ttrpc: closed: unknown"
Jan 17 06:34:20 kind-control-plane containerd[197]: time="2023-01-17T06:34:20.415628169Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:34:19Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40141\n"
Jan 17 06:34:20 kind-control-plane kubelet[607]: I0117 06:34:20.608584     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:34:22 kind-control-plane kubelet[607]: I0117 06:34:22.376279     607 scope.go:111] "RemoveContainer" containerID="96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3"
Jan 17 06:34:22 kind-control-plane kubelet[607]: I0117 06:34:22.376714     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:22 kind-control-plane kubelet[607]: E0117 06:34:22.376965     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:22 kind-control-plane containerd[197]: time="2023-01-17T06:34:22.569394314Z" level=info msg="RemoveContainer for \"96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3\""
Jan 17 06:34:22 kind-control-plane containerd[197]: time="2023-01-17T06:34:22.677231469Z" level=info msg="RemoveContainer for \"96c1fba048fc65e5ff02a67ba776ea620defbf88a9b0050ddbb422a4f7d7d0a3\" returns successfully"
Jan 17 06:34:31 kind-control-plane kubelet[607]: I0117 06:34:31.804316     607 status_manager.go:566] "Failed to get status for pod" podUID=46dac9a538838115821dfd9559149484 pod="kube-system/kube-controller-manager-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:34:33 kind-control-plane kubelet[607]: E0117 06:34:33.327890     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:34:35 kind-control-plane kubelet[607]: I0117 06:34:35.685556     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:35 kind-control-plane kubelet[607]: E0117 06:34:35.685935     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:37 kind-control-plane kubelet[607]: E0117 06:34:37.227309     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:34:37 kind-control-plane kubelet[607]: E0117 06:34:37.934715     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:34:41 kind-control-plane kubelet[607]: I0117 06:34:41.931355     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:34:47 kind-control-plane kubelet[607]: W0117 06:34:47.949771     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.RuntimeClass ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:34:47 kind-control-plane kubelet[607]: E0117 06:34:47.949865     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": read tcp 172.18.0.2:34852->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:34:47 kind-control-plane kubelet[607]: W0117 06:34:47.954603     607 reflector.go:436] object-"local-path-storage"/"local-path-config": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"local-path-config": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:34:47 kind-control-plane kubelet[607]: E0117 06:34:47.954644     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:34:48 kind-control-plane kubelet[607]: I0117 06:34:48.650907     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:34:48 kind-control-plane kubelet[607]: E0117 06:34:48.652486     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:34:50 kind-control-plane kubelet[607]: E0117 06:34:50.360110     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:34:58 kind-control-plane kubelet[607]: E0117 06:34:58.091391     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:35:02 kind-control-plane kubelet[607]: I0117 06:35:02.730859     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:35:03 kind-control-plane containerd[197]: time="2023-01-17T06:35:03.079323699Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:8,}"
Jan 17 06:35:03 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount139086555.mount: Succeeded.
Jan 17 06:35:03 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount813743230.mount: Succeeded.
Jan 17 06:35:04 kind-control-plane containerd[197]: time="2023-01-17T06:35:04.120346079Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:8,} returns container id \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\""
Jan 17 06:35:04 kind-control-plane containerd[197]: time="2023-01-17T06:35:04.190720914Z" level=info msg="StartContainer for \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\""
Jan 17 06:35:07 kind-control-plane kubelet[607]: E0117 06:35:07.396427     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:35:08 kind-control-plane kubelet[607]: W0117 06:35:08.742751     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d WatchSource:0}: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:08 kind-control-plane kubelet[607]: E0117 06:35:08.786411     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:35:08 kind-control-plane kubelet[607]: E0117 06:35:08.835354     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:35:19 kind-control-plane kubelet[607]: E0117 06:35:19.342708     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:19 kind-control-plane kubelet[607]: E0117 06:35:19.342736     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:35:24 kind-control-plane kubelet[607]: E0117 06:35:24.634607     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:35:30 kind-control-plane kubelet[607]: I0117 06:35:30.484749     607 trace.go:205] Trace[2018775996]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:34:49.406) (total time: 41078ms):
Jan 17 06:35:30 kind-control-plane kubelet[607]: Trace[2018775996]: [41.078241475s] [41.078241475s] END
Jan 17 06:35:30 kind-control-plane kubelet[607]: E0117 06:35:30.484786     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16016": net/http: TLS handshake timeout
Jan 17 06:35:33 kind-control-plane kubelet[607]: I0117 06:35:33.641758     607 status_manager.go:566] "Failed to get status for pod" podUID=69dd939498054a211c3461b2a9cc8d26 pod="kube-system/kube-scheduler-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:35:37 kind-control-plane kubelet[607]: I0117 06:35:37.945664     607 trace.go:205] Trace[2007941272]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:34:48.878) (total time: 48971ms):
Jan 17 06:35:37 kind-control-plane kubelet[607]: Trace[2007941272]: [48.971406005s] [48.971406005s] END
Jan 17 06:35:37 kind-control-plane kubelet[607]: E0117 06:35:37.945714     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16146": net/http: TLS handshake timeout
Jan 17 06:35:39 kind-control-plane kubelet[607]: E0117 06:35:39.471580     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:40 kind-control-plane kubelet[607]: I0117 06:35:40.895941     607 trace.go:205] Trace[294080245]: "iptables ChainExists" (17-Jan-2023 06:35:31.695) (total time: 8743ms):
Jan 17 06:35:40 kind-control-plane kubelet[607]: Trace[294080245]: [8.743759725s] [8.743759725s] END
Jan 17 06:35:40 kind-control-plane kubelet[607]: W0117 06:35:40.895995     607 iptables.go:579] Could not check for iptables canary mangle/KUBE-KUBELET-CANARY: exit status 4
Jan 17 06:35:42 kind-control-plane kubelet[607]: I0117 06:35:42.346634     607 trace.go:205] Trace[1174702308]: "iptables ChainExists" (17-Jan-2023 06:35:31.690) (total time: 8889ms):
Jan 17 06:35:42 kind-control-plane kubelet[607]: Trace[1174702308]: [8.889691644s] [8.889691644s] END
Jan 17 06:35:42 kind-control-plane kubelet[607]: W0117 06:35:42.346704     607 iptables.go:579] Could not check for iptables canary mangle/KUBE-KUBELET-CANARY: exit status 4
Jan 17 06:35:43 kind-control-plane kubelet[607]: E0117 06:35:42.939295     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:35:44 kind-control-plane kubelet[607]: I0117 06:35:44.136465     607 trace.go:205] Trace[2100721423]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:35:32.636) (total time: 11499ms):
Jan 17 06:35:44 kind-control-plane kubelet[607]: Trace[2100721423]: [11.49986088s] [11.49986088s] END
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.136492     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16016": net/http: TLS handshake timeout
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.364717     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.681773     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b02138c94785e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"11837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809530769, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b02138c94785e": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:35:44 kind-control-plane kubelet[607]: E0117 06:35:44.681872     607 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04f470d7a27f", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": context deadline exceeded", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1b986fd67f, ext:9948343206425, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Jan 17 06:35:46 kind-control-plane kubelet[607]: E0117 06:35:46.117559     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:35:47 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15-rootfs.mount: Succeeded.
Jan 17 06:35:47 kind-control-plane kubelet[607]: I0117 06:35:47.741734     607 scope.go:111] "RemoveContainer" containerID="28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae"
Jan 17 06:35:47 kind-control-plane containerd[197]: time="2023-01-17T06:35:47.883354013Z" level=info msg="shim disconnected" id=7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15
Jan 17 06:35:47 kind-control-plane containerd[197]: time="2023-01-17T06:35:47.883457491Z" level=warning msg="cleaning up after shim disconnected" id=7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15 namespace=k8s.io
Jan 17 06:35:47 kind-control-plane containerd[197]: time="2023-01-17T06:35:47.883474893Z" level=info msg="cleaning up dead shim"
Jan 17 06:35:48 kind-control-plane containerd[197]: time="2023-01-17T06:35:48.051545585Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:35:47Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40460\n"
Jan 17 06:35:48 kind-control-plane containerd[197]: time="2023-01-17T06:35:48.108342785Z" level=info msg="RemoveContainer for \"28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae\""
Jan 17 06:35:48 kind-control-plane containerd[197]: time="2023-01-17T06:35:48.222701944Z" level=info msg="RemoveContainer for \"28db187a7189c2ef72f9b35c621711c7996a7eb99a9ba5c2c0c151ce2cedf8ae\" returns successfully"
Jan 17 06:35:48 kind-control-plane kubelet[607]: I0117 06:35:48.779868     607 scope.go:111] "RemoveContainer" containerID="faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c"
Jan 17 06:35:48 kind-control-plane kubelet[607]: I0117 06:35:48.787066     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:35:48 kind-control-plane kubelet[607]: E0117 06:35:48.799688     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 10s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:35:48 kind-control-plane containerd[197]: time="2023-01-17T06:35:48.852858034Z" level=info msg="RemoveContainer for \"faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c\""
Jan 17 06:35:48 kind-control-plane containerd[197]: time="2023-01-17T06:35:48.912335924Z" level=info msg="RemoveContainer for \"faa53a94048f1252f8bfb21a94dbb87a45ce1d8634228461e80f42c8c9a7338c\" returns successfully"
Jan 17 06:35:49 kind-control-plane kubelet[607]: E0117 06:35:49.473537     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-kind-control-plane.173b04f24d18e354", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-controller-manager-kind-control-plane", UID:"46dac9a538838115821dfd9559149484", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-controller-manager}"}, Reason:"Unhealthy", Message:"Startup probe failed: Get \"https://127.0.0.1:10257/healthz\": dial tcp 127.0.0.1:10257: connect: connection refused", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae194d223154, ext:9939153568107, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1bcf0f90ff, ext:9949185902147, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-controller-manager-kind-control-plane.173b04f24d18e354": read tcp 172.18.0.2:37600->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:35:49 kind-control-plane kubelet[607]: E0117 06:35:49.474880     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.660522     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.660682     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.801361     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:54 kind-control-plane kubelet[607]: E0117 06:35:54.801507     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jan 17 06:35:59 kind-control-plane kubelet[607]: E0117 06:35:59.587676     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:35:59 kind-control-plane kubelet[607]: E0117 06:35:59.883694     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-kind-control-plane.173b04f24d18e354", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-controller-manager-kind-control-plane", UID:"46dac9a538838115821dfd9559149484", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-controller-manager}"}, Reason:"Unhealthy", Message:"Startup probe failed: Get \"https://127.0.0.1:10257/healthz\": dial tcp 127.0.0.1:10257: connect: connection refused", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae194d223154, ext:9939153568107, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae1bcf0f90ff, ext:9949185902147, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-controller-manager-kind-control-plane.173b04f24d18e354": read tcp 172.18.0.2:37890->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:36:00 kind-control-plane kubelet[607]: I0117 06:36:00.538835     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:36:01 kind-control-plane kubelet[607]: E0117 06:36:01.166711     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:36:01 kind-control-plane containerd[197]: time="2023-01-17T06:36:01.432514885Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:2,}"
Jan 17 06:36:02 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount863037129.mount: Succeeded.
Jan 17 06:36:02 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount424125844.mount: Succeeded.
Jan 17 06:36:02 kind-control-plane containerd[197]: time="2023-01-17T06:36:02.698269972Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for &ContainerMetadata{Name:kindnet-cni,Attempt:2,} returns container id \"0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a\""
Jan 17 06:36:02 kind-control-plane containerd[197]: time="2023-01-17T06:36:02.710336850Z" level=info msg="StartContainer for \"0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a\""
Jan 17 06:36:06 kind-control-plane kubelet[607]: W0117 06:36:06.412797     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/pode5ced440-70ff-4944-9756-a3d368c86a5d/0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a WatchSource:0}: task 0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a not found: not found
Jan 17 06:36:07 kind-control-plane containerd[197]: time="2023-01-17T06:36:07.578474867Z" level=info msg="StartContainer for \"0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a\" returns successfully"
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.466015     607 trace.go:205] Trace[164233999]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:35:56.342) (total time: 13123ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[164233999]: [13.123788267s] [13.123788267s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.471726     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.829819     607 trace.go:205] Trace[200181100]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:55.969) (total time: 13860ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[200181100]: ---"Objects listed" 13860ms (06:36:00.829)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[200181100]: [13.860265225s] [13.860265225s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.843857     607 trace.go:205] Trace[1005973061]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:35:55.701) (total time: 14142ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1005973061]: [14.14227732s] [14.14227732s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.843895     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.856849     607 trace.go:205] Trace[64763159]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:35:55.493) (total time: 14362ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[64763159]: [14.362990834s] [14.362990834s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.856877     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.856929     607 trace.go:205] Trace[1815204842]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:35:55.999) (total time: 13857ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1815204842]: [13.857544985s] [13.857544985s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.856935     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.857179     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.857536     607 request.go:1027] Unexpected error when reading response body: read tcp 172.18.0.2:38486->172.18.0.2:6443: use of closed network connection
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.891761     607 trace.go:205] Trace[1994958741]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:56.342) (total time: 13549ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1994958741]: ---"Objects listed" 13549ms (06:36:00.891)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1994958741]: [13.549255152s] [13.549255152s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.891984     607 trace.go:205] Trace[2135630075]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:35:49.948) (total time: 19943ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[2135630075]: [19.943547424s] [19.943547424s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: E0117 06:36:09.891998     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: unexpected error when reading response body. Please retry. Original error: read tcp 172.18.0.2:38486->172.18.0.2:6443: use of closed network connection
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.899789     607 trace.go:205] Trace[619753212]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:35:55.800) (total time: 14099ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[619753212]: ---"Objects listed" 14099ms (06:36:00.899)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[619753212]: [14.099437716s] [14.099437716s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.932199     607 trace.go:205] Trace[1038531942]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:41.749) (total time: 28182ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1038531942]: ---"Objects listed" 28177ms (06:36:00.927)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1038531942]: [28.18234687s] [28.18234687s] END
Jan 17 06:36:09 kind-control-plane kubelet[607]: I0117 06:36:09.932524     607 trace.go:205] Trace[1968695855]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:35:55.945) (total time: 13986ms):
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1968695855]: ---"Objects listed" 13867ms (06:36:00.813)
Jan 17 06:36:09 kind-control-plane kubelet[607]: Trace[1968695855]: [13.9866024s] [13.9866024s] END
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.392773     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.580997     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:14 kind-control-plane kubelet[607]: E0117 06:36:14.692782     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:17 kind-control-plane kubelet[607]: E0117 06:36:17.592592     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:36:41 kind-control-plane kubelet[607]: E0117 06:36:41.817349     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Jan 17 06:36:43 kind-control-plane kubelet[607]: E0117 06:36:43.445265     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:36:44 kind-control-plane kubelet[607]: E0117 06:36:44.876206     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:36:46 kind-control-plane kubelet[607]: E0117 06:36:46.625183     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:53.386592     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:54.390734     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:36:54 kind-control-plane kubelet[607]: E0117 06:36:54.509504     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:38874->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:04 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d-rootfs.mount: Succeeded.
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.082913     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:40286->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.085469     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": read tcp 172.18.0.2:40320->172.18.0.2:6443: use of closed network connection
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.119551     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.184975     607 remote_runtime.go:253] "StartContainer from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.948359     607 kuberuntime_manager.go:864] container &Container{Name:local-path-provisioner,Image:docker.io/rancher/local-path-provisioner:v0.0.14,Command:[local-path-provisioner --debug start --helper-image k8s.gcr.io/build-image/debian-base:v2.1.0 --config /etc/config/config.json],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:config-volume,ReadOnly:false,MountPath:/etc/config/,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-qctc9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711): RunContainerError: context deadline exceeded
Jan 17 06:37:05 kind-control-plane kubelet[607]: E0117 06:37:05.954512     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with RunContainerError: \"context deadline exceeded\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:07 kind-control-plane containerd[197]: time="2023-01-17T06:37:07.339826865Z" level=info msg="shim disconnected" id=ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d
Jan 17 06:37:07 kind-control-plane containerd[197]: time="2023-01-17T06:37:07.339935497Z" level=warning msg="cleaning up after shim disconnected" id=ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d namespace=k8s.io
Jan 17 06:37:07 kind-control-plane containerd[197]: time="2023-01-17T06:37:07.339955477Z" level=info msg="cleaning up dead shim"
Jan 17 06:37:15 kind-control-plane containerd[197]: time="2023-01-17T06:37:14.802836863Z" level=error msg="Failed to pipe stdout of container \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\"" error="reading from a closed fifo"
Jan 17 06:37:15 kind-control-plane containerd[197]: time="2023-01-17T06:37:15.477555377Z" level=error msg="Failed to pipe stderr of container \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\"" error="reading from a closed fifo"
Jan 17 06:37:15 kind-control-plane containerd[197]: time="2023-01-17T06:37:15.964429026Z" level=error msg="StartContainer for \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\" failed" error="failed to create containerd task: failed to create shim: context deadline exceeded: unknown"
Jan 17 06:37:16 kind-control-plane containerd[197]: time="2023-01-17T06:37:16.059697528Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:37:08Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40659\n"
Jan 17 06:37:16 kind-control-plane kubelet[607]: E0117 06:37:16.276919     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:16 kind-control-plane kubelet[607]: I0117 06:37:16.463905     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:16 kind-control-plane kubelet[607]: E0117 06:37:16.468830     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:19 kind-control-plane kubelet[607]: I0117 06:37:19.615709     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:19 kind-control-plane kubelet[607]: E0117 06:37:19.616015     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:20 kind-control-plane kubelet[607]: I0117 06:37:20.578034     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:20 kind-control-plane kubelet[607]: E0117 06:37:20.637526     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.597928     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:41092->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.600979     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.600999     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:37:26 kind-control-plane kubelet[607]: E0117 06:37:26.602628     607 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:26 kind-control-plane kubelet[607]: I0117 06:37:26.602658     607 controller.go:114] failed to update lease using latest lease, fallback to ensure lease, err: failed 5 attempts to update lease
Jan 17 06:37:33 kind-control-plane kubelet[607]: I0117 06:37:33.024292     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:33 kind-control-plane kubelet[607]: E0117 06:37:33.024709     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:36 kind-control-plane kubelet[607]: E0117 06:37:36.769031     607 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:37:37 kind-control-plane kubelet[607]: I0117 06:37:37.655551     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:41 kind-control-plane kubelet[607]: E0117 06:37:41.902210     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:37:45 kind-control-plane kubelet[607]: E0117 06:37:45.450589     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.532027     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.578417     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:37:47 kind-control-plane kubelet[607]: E0117 06:37:47.351934     607 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: TLS handshake timeout
Jan 17 06:37:47 kind-control-plane kubelet[607]: I0117 06:37:47.954013     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:37:49 kind-control-plane kubelet[607]: I0117 06:37:49.021585     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:37:49 kind-control-plane kubelet[607]: E0117 06:37:49.024141     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:37:58 kind-control-plane kubelet[607]: I0117 06:37:58.439450     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": net/http: TLS handshake timeout"
Jan 17 06:37:58 kind-control-plane kubelet[607]: W0117 06:37:58.464131     607 reflector.go:436] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: watch of *v1.Pod ended with: very short watch: k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:37:59 kind-control-plane kubelet[607]: E0117 06:37:58.846022     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:37:59 kind-control-plane kubelet[607]: I0117 06:37:58.876679     607 request.go:668] Waited for 1.279855667s due to client-side throttling, not priority and fairness, request: PATCH:https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1
Jan 17 06:37:59 kind-control-plane kubelet[607]: E0117 06:37:59.455764     607 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:00 kind-control-plane kubelet[607]: I0117 06:38:00.732779     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:00 kind-control-plane kubelet[607]: E0117 06:38:00.887572     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:09 kind-control-plane kubelet[607]: E0117 06:38:09.030966     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:42818->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:38:09 kind-control-plane kubelet[607]: E0117 06:38:09.031800     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:38:10 kind-control-plane kubelet[607]: E0117 06:38:10.339982     607 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:16 kind-control-plane kubelet[607]: I0117 06:38:16.946190     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:17 kind-control-plane kubelet[607]: E0117 06:38:17.206309     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:19 kind-control-plane kubelet[607]: E0117 06:38:19.259736     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:38:22 kind-control-plane kubelet[607]: E0117 06:38:22.118474     607 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.324794     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:43904->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.383686     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:38:29 kind-control-plane kubelet[607]: E0117 06:38:29.383715     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:38:33 kind-control-plane kubelet[607]: I0117 06:38:33.274592     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:33 kind-control-plane kubelet[607]: E0117 06:38:33.274923     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:38:35 kind-control-plane kubelet[607]: E0117 06:38:35.391754     607 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:38:37 kind-control-plane kubelet[607]: E0117 06:38:37.094347     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:38:38 kind-control-plane kubelet[607]: E0117 06:38:38.799914     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d: task ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d not found: not found
Jan 17 06:38:40 kind-control-plane kubelet[607]: I0117 06:38:40.415979     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": net/http: TLS handshake timeout"
Jan 17 06:38:41 kind-control-plane kubelet[607]: I0117 06:38:41.741916     607 trace.go:205] Trace[1435387408]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:38:00.222) (total time: 41519ms):
Jan 17 06:38:41 kind-control-plane kubelet[607]: Trace[1435387408]: [41.519520444s] [41.519520444s] END
Jan 17 06:38:41 kind-control-plane kubelet[607]: E0117 06:38:41.742732     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:38:45 kind-control-plane kubelet[607]: I0117 06:38:45.076378     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:38:46 kind-control-plane containerd[197]: time="2023-01-17T06:38:46.126416661Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:9,}"
Jan 17 06:38:48 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount941693562.mount: Succeeded.
Jan 17 06:38:48 kind-control-plane containerd[197]: time="2023-01-17T06:38:48.591256331Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:9,} returns container id \"d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80\""
Jan 17 06:38:49 kind-control-plane containerd[197]: time="2023-01-17T06:38:49.675906784Z" level=info msg="StartContainer for \"d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80\""
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.452411     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": context deadline exceeded"
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.582371     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:38:52 kind-control-plane kubelet[607]: E0117 06:38:52.753770     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:38:55 kind-control-plane kubelet[607]: I0117 06:38:55.099378     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:38:56 kind-control-plane kubelet[607]: I0117 06:38:56.024610     607 trace.go:205] Trace[937553544]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:38:43.639) (total time: 11636ms):
Jan 17 06:38:56 kind-control-plane kubelet[607]: Trace[937553544]: [11.63664177s] [11.63664177s] END
Jan 17 06:38:56 kind-control-plane kubelet[607]: E0117 06:38:56.024664     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:38:56 kind-control-plane kubelet[607]: I0117 06:38:56.944370     607 scope.go:111] "RemoveContainer" containerID="ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d"
Jan 17 06:39:00 kind-control-plane containerd[197]: time="2023-01-17T06:39:00.383508787Z" level=info msg="RemoveContainer for \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\""
Jan 17 06:39:01 kind-control-plane containerd[197]: time="2023-01-17T06:39:01.275576954Z" level=info msg="RemoveContainer for \"ed340a4d1cd855908c3ff1753fdc98d0f022aabcedafc48d292e7ca68ec40a0d\" returns successfully"
Jan 17 06:39:01 kind-control-plane kubelet[607]: W0117 06:39:01.930230     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 WatchSource:0}: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:02 kind-control-plane kubelet[607]: E0117 06:39:02.629130     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:39:06 kind-control-plane containerd[197]: time="2023-01-17T06:39:06.662205370Z" level=info msg="StopContainer for \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\" with timeout 30 (s)"
Jan 17 06:39:07 kind-control-plane containerd[197]: time="2023-01-17T06:39:07.250817845Z" level=info msg="Stop container \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\" with signal terminated"
Jan 17 06:39:10 kind-control-plane kubelet[607]: E0117 06:39:10.045321     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:39:14 kind-control-plane kubelet[607]: I0117 06:39:14.432734     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": net/http: TLS handshake timeout"
Jan 17 06:39:14 kind-control-plane kubelet[607]: E0117 06:39:14.937415     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:39:15 kind-control-plane kubelet[607]: I0117 06:39:15.484557     607 trace.go:205] Trace[565735942]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:39:02.228) (total time: 13255ms):
Jan 17 06:39:15 kind-control-plane kubelet[607]: Trace[565735942]: [13.255508623s] [13.255508623s] END
Jan 17 06:39:15 kind-control-plane kubelet[607]: E0117 06:39:15.484610     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:39:15 kind-control-plane kubelet[607]: E0117 06:39:15.598827     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:39:25 kind-control-plane kubelet[607]: E0117 06:39:25.556483     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:25.994468     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:46710->172.18.0.2:6443: read: connection reset by peer'(may retry after sleeping)
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023873     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.Node ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023950     607 reflector.go:436] object-"local-path-storage"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.023988     607 reflector.go:436] object-"local-path-storage"/"local-path-config": watch of *v1.ConfigMap ended with: very short watch: object-"local-path-storage"/"local-path-config": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.024033     607 reflector.go:436] object-"kube-system"/"coredns": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"coredns": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027453     607 reflector.go:436] object-"kube-system"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"kube-root-ca.crt": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027507     607 reflector.go:436] object-"kube-system"/"kube-proxy": watch of *v1.ConfigMap ended with: very short watch: object-"kube-system"/"kube-proxy": Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027547     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.CSIDriver ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027582     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.Service ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: W0117 06:39:26.027622     607 reflector.go:436] k8s.io/client-go/informers/factory.go:134: watch of *v1.RuntimeClass ended with: very short watch: k8s.io/client-go/informers/factory.go:134: Unexpected watch close - watch lasted less than a second and no items received
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566340     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:26.566649     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566718     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.566918     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572082     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572316     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: I0117 06:39:26.572517     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:26 kind-control-plane kubelet[607]: E0117 06:39:26.861829     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.024195     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.024220     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.142270     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.226849     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.243989     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.289026     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.294122     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.294225     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.395365     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.567790     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:27 kind-control-plane kubelet[607]: E0117 06:39:27.767408     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:28 kind-control-plane kubelet[607]: E0117 06:39:28.955542     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.011771     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.235880     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.575966     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.727576     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane kubelet[607]: E0117 06:39:29.812442     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:29 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a-rootfs.mount: Succeeded.
Jan 17 06:39:30 kind-control-plane containerd[197]: time="2023-01-17T06:39:30.040455622Z" level=info msg="shim disconnected" id=0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a
Jan 17 06:39:30 kind-control-plane containerd[197]: time="2023-01-17T06:39:30.040539254Z" level=warning msg="cleaning up after shim disconnected" id=0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a namespace=k8s.io
Jan 17 06:39:30 kind-control-plane containerd[197]: time="2023-01-17T06:39:30.040554489Z" level=info msg="cleaning up dead shim"
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.341076     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:30 kind-control-plane containerd[197]: time="2023-01-17T06:39:30.420845227Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:39:30Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=40941\n"
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.554749     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:30 kind-control-plane kubelet[607]: E0117 06:39:30.823617     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.061032     607 scope.go:111] "RemoveContainer" containerID="7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.061311     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:31 kind-control-plane kubelet[607]: E0117 06:39:31.061564     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.064933     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane containerd[197]: time="2023-01-17T06:39:31.072861384Z" level=info msg="RemoveContainer for \"7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15\""
Jan 17 06:39:31 kind-control-plane containerd[197]: time="2023-01-17T06:39:31.165808132Z" level=info msg="RemoveContainer for \"7e20c3b079a44f33ace2f89dff481774aaad7e5ea7bc539e0c050a22c7519a15\" returns successfully"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658399     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658731     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.658942     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:31 kind-control-plane kubelet[607]: I0117 06:39:31.703713     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.062795     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.534775     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.574579     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:33 kind-control-plane kubelet[607]: E0117 06:39:33.802364     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.174637     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.318800     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:34 kind-control-plane kubelet[607]: E0117 06:39:34.612646     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.039866     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.064157     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80: task d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 not found: not found
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.581413     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:35 kind-control-plane kubelet[607]: E0117 06:39:35.860923     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:36 kind-control-plane kubelet[607]: E0117 06:39:36.061809     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:36 kind-control-plane kubelet[607]: E0117 06:39:36.123962     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": dial tcp 172.18.0.2:6443: connect: connection refused'(may retry after sleeping)
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.070722     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088005     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088280     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088397     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088497     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:37 kind-control-plane kubelet[607]: E0117 06:39:37.088509     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:39:38 kind-control-plane containerd[197]: time="2023-01-17T06:39:38.269847707Z" level=info msg="Kill container \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\""
Jan 17 06:39:39 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8-rootfs.mount: Succeeded.
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.239077205Z" level=info msg="shim disconnected" id=4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.239150303Z" level=warning msg="cleaning up after shim disconnected" id=4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8 namespace=k8s.io
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.239159787Z" level=info msg="cleaning up dead shim"
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.523982650Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:39:39Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=41008\n"
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.677742463Z" level=info msg="StopContainer for \"4bc343b38f3fbd1777fd0cff9db4bf7c33963b76588bc2cd17bbf1d131e207f8\" returns successfully"
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.708240979Z" level=info msg="StartContainer for \"d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80\" returns successfully"
Jan 17 06:39:39 kind-control-plane kubelet[607]: E0117 06:39:39.708849     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:39 kind-control-plane containerd[197]: time="2023-01-17T06:39:39.834619118Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for container &ContainerMetadata{Name:kube-apiserver,Attempt:2,}"
Jan 17 06:39:40 kind-control-plane kubelet[607]: I0117 06:39:40.127339     607 scope.go:111] "RemoveContainer" containerID="80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1"
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.164265523Z" level=info msg="RemoveContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\""
Jan 17 06:39:40 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80-rootfs.mount: Succeeded.
Jan 17 06:39:40 kind-control-plane kubelet[607]: I0117 06:39:40.199829     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.217492706Z" level=info msg="shim disconnected" id=d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.217567862Z" level=warning msg="cleaning up after shim disconnected" id=d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80 namespace=k8s.io
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.217577835Z" level=info msg="cleaning up dead shim"
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.303555018Z" level=info msg="RemoveContainer for \"80c0a5fa621f9801f9d6431933e3a5129833dadbf5ffa48d0573ad040ca574a1\" returns successfully"
Jan 17 06:39:40 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount482412898.mount: Succeeded.
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.423088475Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:39:40Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=41045\n"
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.436119911Z" level=info msg="CreateContainer within sandbox \"9a736ed0ae506d1e97a92196adbf7f315cd7090fc6af9ba4d34cf3f9d6bc563f\" for &ContainerMetadata{Name:kube-apiserver,Attempt:2,} returns container id \"712f4efd80bc3c2f50ceaaefaf1e5b134f92a909ff8b96704302535a32203cc6\""
Jan 17 06:39:40 kind-control-plane containerd[197]: time="2023-01-17T06:39:40.436840991Z" level=info msg="StartContainer for \"712f4efd80bc3c2f50ceaaefaf1e5b134f92a909ff8b96704302535a32203cc6\""
Jan 17 06:39:40 kind-control-plane kubelet[607]: E0117 06:39:40.611145     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.008566     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane containerd[197]: time="2023-01-17T06:39:41.233299036Z" level=info msg="StartContainer for \"712f4efd80bc3c2f50ceaaefaf1e5b134f92a909ff8b96704302535a32203cc6\" returns successfully"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.313349     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.313788     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.322652     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.443771     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.888302     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.898838     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: E0117 06:39:41.913137     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: connect: connection refused
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958479     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958769     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:41 kind-control-plane kubelet[607]: I0117 06:39:41.958942     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:42 kind-control-plane kubelet[607]: I0117 06:39:42.652590     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:42 kind-control-plane kubelet[607]: E0117 06:39:42.652883     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 20s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:39:42 kind-control-plane kubelet[607]: I0117 06:39:42.671452     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": dial tcp 172.18.0.2:6443: connect: connection refused"
Jan 17 06:39:51 kind-control-plane kubelet[607]: I0117 06:39:51.649614     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:39:51 kind-control-plane kubelet[607]: E0117 06:39:51.724950     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:39:53 kind-control-plane kubelet[607]: I0117 06:39:53.140558     607 trace.go:205] Trace[2083225363]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:39:43.137) (total time: 10002ms):
Jan 17 06:39:53 kind-control-plane kubelet[607]: Trace[2083225363]: [10.002684435s] [10.002684435s] END
Jan 17 06:39:53 kind-control-plane kubelet[607]: E0117 06:39:53.140584     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:53 kind-control-plane kubelet[607]: I0117 06:39:53.326992     607 trace.go:205] Trace[1674044423]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:39:43.311) (total time: 10015ms):
Jan 17 06:39:53 kind-control-plane kubelet[607]: Trace[1674044423]: [10.015535126s] [10.015535126s] END
Jan 17 06:39:53 kind-control-plane kubelet[607]: E0117 06:39:53.327080     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.682790     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.696294     607 trace.go:205] Trace[359120376]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:45.592) (total time: 10104ms):
Jan 17 06:39:55 kind-control-plane kubelet[607]: Trace[359120376]: [10.104123071s] [10.104123071s] END
Jan 17 06:39:55 kind-control-plane kubelet[607]: E0117 06:39:55.696323     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:55 kind-control-plane kubelet[607]: I0117 06:39:55.779445     607 trace.go:205] Trace[306164034]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:39:45.777) (total time: 10002ms):
Jan 17 06:39:55 kind-control-plane kubelet[607]: Trace[306164034]: [10.002204877s] [10.002204877s] END
Jan 17 06:39:55 kind-control-plane kubelet[607]: E0117 06:39:55.779470     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:55 kind-control-plane containerd[197]: time="2023-01-17T06:39:55.799575217Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:3,}"
Jan 17 06:39:56 kind-control-plane kubelet[607]: E0117 06:39:56.189135     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:39:56 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount184647639.mount: Succeeded.
Jan 17 06:39:56 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount139542858.mount: Succeeded.
Jan 17 06:39:56 kind-control-plane containerd[197]: time="2023-01-17T06:39:56.479458774Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for &ContainerMetadata{Name:kindnet-cni,Attempt:3,} returns container id \"f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703\""
Jan 17 06:39:56 kind-control-plane containerd[197]: time="2023-01-17T06:39:56.480401345Z" level=info msg="StartContainer for \"f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703\""
Jan 17 06:39:56 kind-control-plane kubelet[607]: I0117 06:39:56.720783     607 trace.go:205] Trace[1202646431]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:46.714) (total time: 10006ms):
Jan 17 06:39:56 kind-control-plane kubelet[607]: Trace[1202646431]: [10.006096546s] [10.006096546s] END
Jan 17 06:39:56 kind-control-plane kubelet[607]: E0117 06:39:56.720809     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: I0117 06:39:57.037976     607 trace.go:205] Trace[849438168]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:39:47.035) (total time: 10002ms):
Jan 17 06:39:57 kind-control-plane kubelet[607]: Trace[849438168]: [10.002750533s] [10.002750533s] END
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.038021     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.091520     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:39:57 kind-control-plane kubelet[607]: I0117 06:39:57.158029     607 trace.go:205] Trace[443911200]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:47.144) (total time: 10013ms):
Jan 17 06:39:57 kind-control-plane kubelet[607]: Trace[443911200]: [10.013822076s] [10.013822076s] END
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.158056     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:39:57 kind-control-plane kubelet[607]: E0117 06:39:57.673752     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:39:58 kind-control-plane containerd[197]: time="2023-01-17T06:39:58.184513342Z" level=info msg="StartContainer for \"f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703\" returns successfully"
Jan 17 06:40:01 kind-control-plane kubelet[607]: I0117 06:40:01.952881     607 status_manager.go:566] "Failed to get status for pod" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d pod="kube-system/kindnet-msl5l" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kindnet-msl5l\": net/http: TLS handshake timeout"
Jan 17 06:40:04 kind-control-plane kubelet[607]: I0117 06:40:04.654510     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:04 kind-control-plane kubelet[607]: E0117 06:40:04.654936     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.095181     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04d10e3697f1", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"16329", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63809533782, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:3, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/kube-apiserver-kind-control-plane.173b04d10e3697f1": read tcp 172.18.0.2:50236->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.095249     607 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04facc5eb58c", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://172.18.0.2:6443/livez\": net/http: TLS handshake timeout", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae226aa39b8c, ext:9975648588540, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Jan 17 06:40:07 kind-control-plane kubelet[607]: E0117 06:40:07.105312     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:14 kind-control-plane kubelet[607]: E0117 06:40:14.750402     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:40:17 kind-control-plane kubelet[607]: E0117 06:40:17.208713     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:40:17 kind-control-plane kubelet[607]: E0117 06:40:17.240748     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:18 kind-control-plane kubelet[607]: I0117 06:40:18.016934     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:18 kind-control-plane kubelet[607]: E0117 06:40:18.016934     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:27 kind-control-plane kubelet[607]: E0117 06:40:27.242570     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:51088->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:40:27 kind-control-plane kubelet[607]: E0117 06:40:27.242826     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:29 kind-control-plane kubelet[607]: I0117 06:40:29.767576     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:29 kind-control-plane kubelet[607]: E0117 06:40:29.767902     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:31 kind-control-plane kubelet[607]: E0117 06:40:31.775923     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:40:36 kind-control-plane kubelet[607]: E0117 06:40:36.478054     607 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubelet/kubepods/burstable/podbd1c21fe1f0ef615e0b5e41299f1be61/712f4efd80bc3c2f50ceaaefaf1e5b134f92a909ff8b96704302535a32203cc6\": RecentStats: unable to find data in memory cache]"
Jan 17 06:40:37 kind-control-plane kubelet[607]: E0117 06:40:37.278233     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:40:37 kind-control-plane kubelet[607]: E0117 06:40:37.278293     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:40:44 kind-control-plane kubelet[607]: I0117 06:40:44.878819     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:44 kind-control-plane kubelet[607]: E0117 06:40:44.974706     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:40:47 kind-control-plane kubelet[607]: E0117 06:40:47.303379     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:40:48 kind-control-plane kubelet[607]: I0117 06:40:48.617487     607 trace.go:205] Trace[1386534978]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:17.735) (total time: 30882ms):
Jan 17 06:40:48 kind-control-plane kubelet[607]: Trace[1386534978]: [30.88220543s] [30.88220543s] END
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.617536     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:48 kind-control-plane kubelet[607]: I0117 06:40:48.650801     607 trace.go:205] Trace[1856222165]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:40:06.677) (total time: 41973ms):
Jan 17 06:40:48 kind-control-plane kubelet[607]: Trace[1856222165]: [41.973643557s] [41.973643557s] END
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.650841     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:40:48 kind-control-plane kubelet[607]: E0117 06:40:48.792942     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:40:49 kind-control-plane kubelet[607]: I0117 06:40:49.831547     607 trace.go:205] Trace[234419410]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:40:12.930) (total time: 36901ms):
Jan 17 06:40:49 kind-control-plane kubelet[607]: Trace[234419410]: [36.901313989s] [36.901313989s] END
Jan 17 06:40:49 kind-control-plane kubelet[607]: E0117 06:40:49.831570     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:51 kind-control-plane kubelet[607]: I0117 06:40:51.732861     607 trace.go:205] Trace[2119911038]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:19.205) (total time: 32527ms):
Jan 17 06:40:51 kind-control-plane kubelet[607]: Trace[2119911038]: [32.527129969s] [32.527129969s] END
Jan 17 06:40:51 kind-control-plane kubelet[607]: E0117 06:40:51.732894     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: I0117 06:40:57.043956     607 trace.go:205] Trace[1842200745]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:40:20.037) (total time: 36478ms):
Jan 17 06:40:57 kind-control-plane kubelet[607]: Trace[1842200745]: [36.478638871s] [36.478638871s] END
Jan 17 06:40:57 kind-control-plane kubelet[607]: I0117 06:40:57.110560     607 trace.go:205] Trace[1529820061]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:40:15.108) (total time: 41456ms):
Jan 17 06:40:57 kind-control-plane kubelet[607]: Trace[1529820061]: [41.456124683s] [41.456124683s] END
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.110611     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.251648     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:40:57 kind-control-plane kubelet[607]: E0117 06:40:57.312774     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:40:59 kind-control-plane kubelet[607]: I0117 06:40:59.346974     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:40:59 kind-control-plane kubelet[607]: E0117 06:40:59.796639     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:04 kind-control-plane kubelet[607]: I0117 06:41:04.026646     607 trace.go:205] Trace[1754297056]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:39:58.038) (total time: 65987ms):
Jan 17 06:41:04 kind-control-plane kubelet[607]: Trace[1754297056]: [1m5.987954099s] [1m5.987954099s] END
Jan 17 06:41:04 kind-control-plane kubelet[607]: E0117 06:41:04.026682     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:04 kind-control-plane kubelet[607]: I0117 06:41:04.505719     607 trace.go:205] Trace[1439752824]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:40:12.634) (total time: 51871ms):
Jan 17 06:41:04 kind-control-plane kubelet[607]: Trace[1439752824]: [51.871380234s] [51.871380234s] END
Jan 17 06:41:04 kind-control-plane kubelet[607]: E0117 06:41:04.505757     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:06 kind-control-plane kubelet[607]: E0117 06:41:06.614210     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:41:07 kind-control-plane kubelet[607]: E0117 06:41:07.542812     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:52696->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:07 kind-control-plane kubelet[607]: E0117 06:41:07.703081     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:41:08 kind-control-plane kubelet[607]: I0117 06:41:08.660756     607 status_manager.go:566] "Failed to get status for pod" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711 pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/pods/local-path-provisioner-547f784dff-78qdn\": dial tcp 172.18.0.2:6443: i/o timeout"
Jan 17 06:41:08 kind-control-plane kubelet[607]: I0117 06:41:08.790709     607 trace.go:205] Trace[1391932347]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:40:06.638) (total time: 62152ms):
Jan 17 06:41:08 kind-control-plane kubelet[607]: Trace[1391932347]: [1m2.152481228s] [1m2.152481228s] END
Jan 17 06:41:08 kind-control-plane kubelet[607]: E0117 06:41:08.790737     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:09 kind-control-plane kubelet[607]: I0117 06:41:09.063663     607 trace.go:205] Trace[1065960748]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:39:59.978) (total time: 69084ms):
Jan 17 06:41:09 kind-control-plane kubelet[607]: Trace[1065960748]: [1m9.084887294s] [1m9.084887294s] END
Jan 17 06:41:09 kind-control-plane kubelet[607]: E0117 06:41:09.063694     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:16 kind-control-plane kubelet[607]: I0117 06:41:16.825261     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:16.990381     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:17.834267     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53332->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:17 kind-control-plane kubelet[607]: E0117 06:41:17.894797     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:23 kind-control-plane kubelet[607]: E0117 06:41:23.667752     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:41:28 kind-control-plane kubelet[607]: E0117 06:41:28.414577     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:31 kind-control-plane kubelet[607]: I0117 06:41:31.368873     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:31 kind-control-plane kubelet[607]: E0117 06:41:31.391466     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511217     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:53628->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511474     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:38 kind-control-plane kubelet[607]: E0117 06:41:38.511493     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:41:40 kind-control-plane kubelet[607]: E0117 06:41:40.935600     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:41:42 kind-control-plane kubelet[607]: I0117 06:41:42.884242     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:42 kind-control-plane kubelet[607]: E0117 06:41:42.884647     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:50 kind-control-plane kubelet[607]: I0117 06:41:50.025470     607 trace.go:205] Trace[1941401903]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:41:38.909) (total time: 11116ms):
Jan 17 06:41:50 kind-control-plane kubelet[607]: Trace[1941401903]: [11.116146771s] [11.116146771s] END
Jan 17 06:41:50 kind-control-plane kubelet[607]: E0117 06:41:50.025504     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:52 kind-control-plane kubelet[607]: I0117 06:41:52.646975     607 status_manager.go:566] "Failed to get status for pod" podUID=8ce1e50d-5699-49de-9a31-edc180d85ebe pod="kube-system/coredns-558bd4d5db-7kcfd" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-7kcfd\": net/http: TLS handshake timeout"
Jan 17 06:41:54 kind-control-plane kubelet[607]: I0117 06:41:54.232348     607 trace.go:205] Trace[446508473]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:35.230) (total time: 18933ms):
Jan 17 06:41:54 kind-control-plane kubelet[607]: Trace[446508473]: [18.933287782s] [18.933287782s] END
Jan 17 06:41:54 kind-control-plane kubelet[607]: E0117 06:41:54.232386     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:55 kind-control-plane kubelet[607]: I0117 06:41:55.563497     607 trace.go:205] Trace[407658894]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:41:45.261) (total time: 10301ms):
Jan 17 06:41:55 kind-control-plane kubelet[607]: Trace[407658894]: [10.301733541s] [10.301733541s] END
Jan 17 06:41:55 kind-control-plane kubelet[607]: E0117 06:41:55.563559     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": net/http: TLS handshake timeout
Jan 17 06:41:56 kind-control-plane kubelet[607]: I0117 06:41:56.375237     607 trace.go:205] Trace[1036307788]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:41:30.730) (total time: 25644ms):
Jan 17 06:41:56 kind-control-plane kubelet[607]: Trace[1036307788]: [25.644416841s] [25.644416841s] END
Jan 17 06:41:56 kind-control-plane kubelet[607]: E0117 06:41:56.375275     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:56 kind-control-plane kubelet[607]: I0117 06:41:56.738843     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:41:56 kind-control-plane kubelet[607]: E0117 06:41:56.757664     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:41:58 kind-control-plane kubelet[607]: I0117 06:41:58.015104     607 trace.go:205] Trace[697839201]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:23.171) (total time: 34843ms):
Jan 17 06:41:58 kind-control-plane kubelet[607]: Trace[697839201]: [34.843106216s] [34.843106216s] END
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.015144     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.264526     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Jan 17 06:41:58 kind-control-plane kubelet[607]: E0117 06:41:58.585677     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:41:59 kind-control-plane kubelet[607]: E0117 06:41:59.722698     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:42:01 kind-control-plane systemd[1]: run-containerd-io.containerd.runtime.v2.task-k8s.io-f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703-rootfs.mount: Succeeded.
Jan 17 06:42:01 kind-control-plane containerd[197]: time="2023-01-17T06:42:01.749708906Z" level=info msg="shim disconnected" id=f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703
Jan 17 06:42:01 kind-control-plane containerd[197]: time="2023-01-17T06:42:01.854427635Z" level=warning msg="cleaning up after shim disconnected" id=f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703 namespace=k8s.io
Jan 17 06:42:01 kind-control-plane containerd[197]: time="2023-01-17T06:42:01.854452815Z" level=info msg="cleaning up dead shim"
Jan 17 06:42:02 kind-control-plane containerd[197]: time="2023-01-17T06:42:02.325410745Z" level=warning msg="cleanup warnings time=\"2023-01-17T06:42:01Z\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=41432\n"
Jan 17 06:42:02 kind-control-plane kubelet[607]: I0117 06:42:02.720017     607 scope.go:111] "RemoveContainer" containerID="0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a"
Jan 17 06:42:02 kind-control-plane kubelet[607]: I0117 06:42:02.733541     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:02 kind-control-plane kubelet[607]: E0117 06:42:02.733950     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:02 kind-control-plane containerd[197]: time="2023-01-17T06:42:02.755760292Z" level=info msg="RemoveContainer for \"0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a\""
Jan 17 06:42:02 kind-control-plane containerd[197]: time="2023-01-17T06:42:02.875696131Z" level=info msg="RemoveContainer for \"0e96f8e89ded187ab46498ca965b0931844630693d999f63039440fede4d615a\" returns successfully"
Jan 17 06:42:04 kind-control-plane kubelet[607]: I0117 06:42:04.144483     607 trace.go:205] Trace[1880481919]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:53.986) (total time: 10127ms):
Jan 17 06:42:04 kind-control-plane kubelet[607]: Trace[1880481919]: [10.127817176s] [10.127817176s] END
Jan 17 06:42:04 kind-control-plane kubelet[607]: E0117 06:42:04.147968     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:04 kind-control-plane kubelet[607]: I0117 06:42:04.722464     607 trace.go:205] Trace[401429468]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:41:32.128) (total time: 32593ms):
Jan 17 06:42:04 kind-control-plane kubelet[607]: Trace[401429468]: [32.593977255s] [32.593977255s] END
Jan 17 06:42:04 kind-control-plane kubelet[607]: E0117 06:42:04.722487     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:42:05 kind-control-plane kubelet[607]: I0117 06:42:05.924754     607 status_manager.go:566] "Failed to get status for pod" podUID=bd1c21fe1f0ef615e0b5e41299f1be61 pod="kube-system/kube-apiserver-kind-control-plane" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-kind-control-plane\": net/http: TLS handshake timeout"
Jan 17 06:42:06 kind-control-plane kubelet[607]: I0117 06:42:06.561471     607 trace.go:205] Trace[1158416207]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:41:55.316) (total time: 11244ms):
Jan 17 06:42:06 kind-control-plane kubelet[607]: Trace[1158416207]: [11.244621144s] [11.244621144s] END
Jan 17 06:42:06 kind-control-plane kubelet[607]: E0117 06:42:06.567204     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:08 kind-control-plane kubelet[607]: E0117 06:42:08.592346     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:09 kind-control-plane kubelet[607]: I0117 06:42:09.709517     607 trace.go:205] Trace[1862760334]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:41:32.914) (total time: 36795ms):
Jan 17 06:42:09 kind-control-plane kubelet[607]: Trace[1862760334]: [36.795183618s] [36.795183618s] END
Jan 17 06:42:09 kind-control-plane kubelet[607]: E0117 06:42:09.709576     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:42:09 kind-control-plane kubelet[607]: I0117 06:42:09.709684     607 trace.go:205] Trace[1870699897]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:41:36.794) (total time: 32914ms):
Jan 17 06:42:09 kind-control-plane kubelet[607]: Trace[1870699897]: [32.914749792s] [32.914749792s] END
Jan 17 06:42:09 kind-control-plane kubelet[607]: E0117 06:42:09.709693     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/local-path-storage/configmaps?fieldSelector=metadata.name%3Dlocal-path-config&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:42:11 kind-control-plane kubelet[607]: I0117 06:42:11.081239     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:42:11 kind-control-plane kubelet[607]: E0117 06:42:11.124574     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"local-path-provisioner\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=local-path-provisioner pod=local-path-provisioner-547f784dff-78qdn_local-path-storage(ce7d1ef1-5350-4296-96a1-91e716d7d711)\"" pod="local-path-storage/local-path-provisioner-547f784dff-78qdn" podUID=ce7d1ef1-5350-4296-96a1-91e716d7d711
Jan 17 06:42:15 kind-control-plane kubelet[607]: E0117 06:42:15.278585     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:16 kind-control-plane kubelet[607]: I0117 06:42:16.634602     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:16 kind-control-plane kubelet[607]: E0117 06:42:16.634928     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:18 kind-control-plane kubelet[607]: E0117 06:42:18.599701     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:55436->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:42:18 kind-control-plane kubelet[607]: E0117 06:42:18.600120     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: TLS handshake timeout"
Jan 17 06:42:22 kind-control-plane kubelet[607]: I0117 06:42:22.678688     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:42:23 kind-control-plane containerd[197]: time="2023-01-17T06:42:23.033603246Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:10,}"
Jan 17 06:42:24 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount996353792.mount: Succeeded.
Jan 17 06:42:25 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount432822879.mount: Succeeded.
Jan 17 06:42:26 kind-control-plane containerd[197]: time="2023-01-17T06:42:26.042201155Z" level=info msg="CreateContainer within sandbox \"f0ca522a4f152334548e696e0a37776172a57185013d3f48415f69a14e995e85\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:10,} returns container id \"64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e\""
Jan 17 06:42:26 kind-control-plane containerd[197]: time="2023-01-17T06:42:26.168257220Z" level=info msg="StartContainer for \"64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e\""
Jan 17 06:42:28 kind-control-plane kubelet[607]: E0117 06:42:28.763619     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:29 kind-control-plane kubelet[607]: I0117 06:42:29.326024     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:30 kind-control-plane kubelet[607]: E0117 06:42:30.631626     607 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CrashLoopBackOff: \"back-off 40s restarting failed container=kindnet-cni pod=kindnet-msl5l_kube-system(e5ced440-70ff-4944-9756-a3d368c86a5d)\"" pod="kube-system/kindnet-msl5l" podUID=e5ced440-70ff-4944-9756-a3d368c86a5d
Jan 17 06:42:32 kind-control-plane kubelet[607]: E0117 06:42:32.348486     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:34 kind-control-plane kubelet[607]: W0117 06:42:34.537646     607 manager.go:1176] Failed to process watch event {EventType:0 Name:/system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e WatchSource:0}: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.601991     607 manager.go:1123] Failed to create existing container: /system.slice/docker-b6c81b00317174527c542e2ac1eb7555d9438c6b9d47f22fdf26b7bbd416ec1e.scope/kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.862443     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:56196->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.871938     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:42:38 kind-control-plane kubelet[607]: E0117 06:42:38.871977     607 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Jan 17 06:42:41 kind-control-plane kubelet[607]: E0117 06:42:41.510015     607 manager.go:1123] Failed to create existing container: /kubelet/kubepods/besteffort/podce7d1ef1-5350-4296-96a1-91e716d7d711/64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e: task 64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e not found: not found
Jan 17 06:42:43 kind-control-plane kubelet[607]: I0117 06:42:43.847656     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:42:44 kind-control-plane containerd[197]: time="2023-01-17T06:42:44.546275041Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:4,}"
Jan 17 06:42:47 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount366640131.mount: Succeeded.
Jan 17 06:42:48 kind-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount558967686.mount: Succeeded.
Jan 17 06:42:48 kind-control-plane containerd[197]: time="2023-01-17T06:42:48.677835709Z" level=info msg="CreateContainer within sandbox \"2487abe52fec3ccfdb1a80bef8f29b4694c79dea29ea2787878c50416da31eef\" for &ContainerMetadata{Name:kindnet-cni,Attempt:4,} returns container id \"08f00d796f782f8ba3362f901981c107eb43e629f037db03f90d819a785cb27f\""
Jan 17 06:42:48 kind-control-plane containerd[197]: time="2023-01-17T06:42:48.975012079Z" level=info msg="StartContainer for \"08f00d796f782f8ba3362f901981c107eb43e629f037db03f90d819a785cb27f\""
Jan 17 06:42:49 kind-control-plane kubelet[607]: E0117 06:42:49.518480     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:42:51 kind-control-plane kubelet[607]: I0117 06:42:51.902489     607 trace.go:205] Trace[1723405815]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:39.739) (total time: 11704ms):
Jan 17 06:42:51 kind-control-plane kubelet[607]: Trace[1723405815]: [11.70427325s] [11.70427325s] END
Jan 17 06:42:51 kind-control-plane kubelet[607]: E0117 06:42:51.902685     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-control-plane&resourceVersion=16362": net/http: TLS handshake timeout
Jan 17 06:42:52 kind-control-plane kubelet[607]: I0117 06:42:52.385728     607 trace.go:205] Trace[2073638128]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-root-ca.crt" (17-Jan-2023 06:42:41.230) (total time: 11155ms):
Jan 17 06:42:52 kind-control-plane kubelet[607]: Trace[2073638128]: [11.155032999s] [11.155032999s] END
Jan 17 06:42:52 kind-control-plane kubelet[607]: E0117 06:42:52.385764     607 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:55 kind-control-plane kubelet[607]: I0117 06:42:55.463292     607 status_manager.go:566] "Failed to get status for pod" podUID=41df3d8b-173f-407c-91cc-5b0da8567827 pod="kube-system/coredns-558bd4d5db-tsnk8" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/coredns-558bd4d5db-tsnk8\": net/http: TLS handshake timeout"
Jan 17 06:42:56 kind-control-plane kubelet[607]: I0117 06:42:56.955528     607 trace.go:205] Trace[231251389]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:36.647) (total time: 20307ms):
Jan 17 06:42:56 kind-control-plane kubelet[607]: Trace[231251389]: [20.307614114s] [20.307614114s] END
Jan 17 06:42:56 kind-control-plane kubelet[607]: E0117 06:42:56.955609     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:42:58 kind-control-plane kubelet[607]: E0117 06:42:58.963439     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?resourceVersion=0&timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:43:00 kind-control-plane kubelet[607]: E0117 06:43:00.272830     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": net/http: TLS handshake timeout'(may retry after sleeping)
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.211140     607 trace.go:205] Trace[985241519]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:39.824) (total time: 25386ms):
Jan 17 06:43:05 kind-control-plane kubelet[607]: Trace[985241519]: [25.386362091s] [25.386362091s] END
Jan 17 06:43:05 kind-control-plane kubelet[607]: E0117 06:43:05.211191     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=16360": net/http: TLS handshake timeout
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.288158     607 trace.go:205] Trace[1933422461]: "Reflector ListAndWatch" name:k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66 (17-Jan-2023 06:42:35.169) (total time: 30118ms):
Jan 17 06:43:05 kind-control-plane kubelet[607]: Trace[1933422461]: [30.118327269s] [30.118327269s] END
Jan 17 06:43:05 kind-control-plane kubelet[607]: E0117 06:43:05.288181     607 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-control-plane&resourceVersion=16374": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:05 kind-control-plane kubelet[607]: I0117 06:43:05.848914     607 scope.go:111] "RemoveContainer" containerID="d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80"
Jan 17 06:43:06 kind-control-plane containerd[197]: time="2023-01-17T06:43:06.410709137Z" level=info msg="RemoveContainer for \"d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80\""
Jan 17 06:43:06 kind-control-plane kubelet[607]: E0117 06:43:06.571019     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": net/http: TLS handshake timeout
Jan 17 06:43:06 kind-control-plane containerd[197]: time="2023-01-17T06:43:06.892393708Z" level=info msg="RemoveContainer for \"d9732076f380f097c9d8ef77c58036de4f1972aa05e3ae4d2280620703e4ef80\" returns successfully"
Jan 17 06:43:06 kind-control-plane kubelet[607]: I0117 06:43:06.892947     607 scope.go:111] "RemoveContainer" containerID="f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703"
Jan 17 06:43:06 kind-control-plane containerd[197]: time="2023-01-17T06:43:06.941938009Z" level=info msg="RemoveContainer for \"f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703\""
Jan 17 06:43:07 kind-control-plane containerd[197]: time="2023-01-17T06:43:07.495817531Z" level=info msg="RemoveContainer for \"f146253551a2e4f3a8c7387eaa0291b6351a7617ec64fa384961572cad3d1703\" returns successfully"
Jan 17 06:43:09 kind-control-plane kubelet[607]: E0117 06:43:09.842502     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": context deadline exceeded"
Jan 17 06:43:10 kind-control-plane kubelet[607]: I0117 06:43:10.282934     607 trace.go:205] Trace[1947214130]: "Reflector ListAndWatch" name:k8s.io/client-go/informers/factory.go:134 (17-Jan-2023 06:42:30.137) (total time: 40145ms):
Jan 17 06:43:10 kind-control-plane kubelet[607]: Trace[1947214130]: [40.145843334s] [40.145843334s] END
Jan 17 06:43:10 kind-control-plane kubelet[607]: E0117 06:43:10.282962     607 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:10 kind-control-plane kubelet[607]: I0117 06:43:10.297624     607 trace.go:205] Trace[189012397]: "Reflector ListAndWatch" name:object-"kube-system"/"coredns" (17-Jan-2023 06:42:32.173) (total time: 38124ms):
Jan 17 06:43:10 kind-control-plane kubelet[607]: Trace[189012397]: [38.124036981s] [38.124036981s] END
Jan 17 06:43:10 kind-control-plane kubelet[607]: E0117 06:43:10.297652     607 reflector.go:138] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcoredns&resourceVersion=16360": dial tcp 172.18.0.2:6443: i/o timeout
Jan 17 06:43:15 kind-control-plane containerd[197]: time="2023-01-17T06:43:15.020385811Z" level=info msg="StartContainer for \"08f00d796f782f8ba3362f901981c107eb43e629f037db03f90d819a785cb27f\" returns successfully"
Jan 17 06:43:19 kind-control-plane kubelet[607]: E0117 06:43:19.847256     607 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-control-plane\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-control-plane?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Jan 17 06:43:19 kind-control-plane kubelet[607]: E0117 06:43:19.879152     607 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-kind-control-plane.173b04fb6c039809", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-kind-control-plane", UID:"bd1c21fe1f0ef615e0b5e41299f1be61", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: Get \"https://172.18.0.2:6443/readyz\": unexpected EOF", Source:v1.EventSource{Component:"kubelet", Host:"kind-control-plane"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc0e9ae2317782009, ext:9978326972213, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Warning", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:57864->172.18.0.2:6443: use of closed network connection'(may retry after sleeping)
Jan 17 06:43:23 kind-control-plane kubelet[607]: E0117 06:43:23.843453     607 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-control-plane?timeout=10s": context deadline exceeded
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.388824     607 trace.go:205] Trace[603096479]: "Reflector ListAndWatch" name:object-"local-path-storage"/"kube-root-ca.crt" (17-Jan-2023 06:43:03.494) (total time: 20889ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[603096479]: [20.889147122s] [20.889147122s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.388867     607 reflector.go:138] object-"local-path-storage"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.395520     607 trace.go:205] Trace[206747533]: "Reflector ListAndWatch" name:object-"local-path-storage"/"local-path-config" (17-Jan-2023 06:43:00.852) (total time: 23543ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[206747533]: [23.543211798s] [23.543211798s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.395553     607 reflector.go:138] object-"local-path-storage"/"local-path-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "local-path-config" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "local-path-storage": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:43:24 kind-control-plane kubelet[607]: I0117 06:43:24.395616     607 trace.go:205] Trace[326951103]: "Reflector ListAndWatch" name:object-"kube-system"/"kube-proxy" (17-Jan-2023 06:43:06.421) (total time: 17973ms):
Jan 17 06:43:24 kind-control-plane kubelet[607]: Trace[326951103]: [17.97368279s] [17.97368279s] END
Jan 17 06:43:24 kind-control-plane kubelet[607]: E0117 06:43:24.395622     607 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:kind-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'kind-control-plane' and this object
Jan 17 06:43:28 kind-control-plane containerd[197]: time="2023-01-17T06:43:28.023315534Z" level=info msg="StartContainer for \"64ffe96e2e9833e6a339151d36de7597e50f8a0178ae184523dbf03715ea657e\" returns successfully"
